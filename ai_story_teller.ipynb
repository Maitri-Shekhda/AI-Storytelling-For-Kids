{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U71tFsu7fLII",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a42498-c4cb-40a0-8df4-ec7177d99326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q pandas numpy sentence-transformers faiss-cpu gradio groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YeJAQC7Gbavs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "rkleRuePfQxM",
        "outputId": "12adf372-312d-4456-cee7-a3ecc51f427f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload the FairytaleQA dataset ZIP file\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e7fad127-c0ff-44b8-b208-7ceab0129a01\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e7fad127-c0ff-44b8-b208-7ceab0129a01\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving FairytaleQAData-main.zip to FairytaleQAData-main.zip\n",
            "Extracted FairytaleQA dataset to FairytaleQAData-main\n",
            "\n",
            "Please upload the Age of Acquisition XLSX file\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c5389584-46ab-44b6-aa35-31e6711e764b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c5389584-46ab-44b6-aa35-31e6711e764b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving AoA_ratings_Kuperman_et_al_BRM.xlsx to AoA_ratings_Kuperman_et_al_BRM.xlsx\n",
            "\n",
            "Please upload the Morals CSV file\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b09a4384-ef58-4a1c-bdad-4a49a47b9b3d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b09a4384-ef58-4a1c-bdad-4a49a47b9b3d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving morals.csv to morals.csv\n",
            "\n",
            "All datasets uploaded successfully!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import zipfile\n",
        "import pickle\n",
        "\n",
        "# Create necessary directories\n",
        "!mkdir -p data/raw data/processed\n",
        "\n",
        "# Upload datasets\n",
        "print(\"Please upload the FairytaleQA dataset ZIP file\")\n",
        "uploaded = files.upload()  # Upload the FairytaleQA dataset ZIP file\n",
        "zip_filename = list(uploaded.keys())[0]\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "fairytale_dir = os.path.splitext(zip_filename)[0]  # Directory name without .zip extension\n",
        "print(f\"Extracted FairytaleQA dataset to {fairytale_dir}\")\n",
        "\n",
        "print(\"\\nPlease upload the Age of Acquisition XLSX file\")\n",
        "uploaded = files.upload()  # Upload the Age of Acquisition dataset\n",
        "aoa_filename = list(uploaded.keys())[0]\n",
        "!mv \"$aoa_filename\" data/raw/\n",
        "\n",
        "print(\"\\nPlease upload the Morals CSV file\")\n",
        "uploaded = files.upload()  # Upload the Morals dataset\n",
        "morals_filename = list(uploaded.keys())[0]\n",
        "!mv \"$morals_filename\" data/raw/\n",
        "\n",
        "print(\"\\nAll datasets uploaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nLMk4m7efwRR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5b25090-0935-47b4-cacc-a174dbb9b8f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing section-split stories...\n",
            "Looking for stories in FairytaleQAData-main/data-by-train-split/section-stories/all\n",
            "Found 278 story files\n",
            "Saved 4095 story sections from 278 stories\n",
            "Processed stories dataframe shape: (4095, 3)\n",
            "Columns: ['section', 'text', 'story_name']\n",
            "Sample stories:\n",
            "   section                                               text  \\\n",
            "0        1  At the time when the Tang dynasty reigned over...   \n",
            "1        2  Old Dragonbeard must have been a master swords...   \n",
            "2        3  When the young man reached home his thoughts w...   \n",
            "3        4  Said Molo: \"When she stretched out three finge...   \n",
            "4        5  \"Nothing easier,\" said Molo. \"On the fifteenth...   \n",
            "\n",
            "                           story_name  \n",
            "0  how-molo-stole-the-lovely-rose-red  \n",
            "1  how-molo-stole-the-lovely-rose-red  \n",
            "2  how-molo-stole-the-lovely-rose-red  \n",
            "3  how-molo-stole-the-lovely-rose-red  \n",
            "4  how-molo-stole-the-lovely-rose-red  \n"
          ]
        }
      ],
      "source": [
        "def process_fairytale_stories(fairytale_dir, output_dir=\"data/processed\"):\n",
        "    \"\"\"Process section-split stories from FairytaleQA dataset\"\"\"\n",
        "    print(\"Processing section-split stories...\")\n",
        "\n",
        "    # Path to section-split stories - using 'all' folder\n",
        "    section_path = os.path.join(fairytale_dir, \"data-by-train-split\", \"section-stories\", \"all\")\n",
        "\n",
        "    # Check if directory exists\n",
        "    if not os.path.exists(section_path):\n",
        "        # Try alternative path structure\n",
        "        section_path = glob.glob(os.path.join(fairytale_dir, \"*\", \"data-by-train-split\", \"section-stories\", \"all\"))\n",
        "        if section_path:\n",
        "            section_path = section_path[0]\n",
        "        else:\n",
        "            print(f\"Could not find section-stories directory in {fairytale_dir}\")\n",
        "            # Try a broader search\n",
        "            section_path = glob.glob(os.path.join(fairytale_dir, \"**\", \"section-stories\", \"all\"), recursive=True)\n",
        "            if section_path:\n",
        "                section_path = section_path[0]\n",
        "            else:\n",
        "                print(\"Could not find section-stories directory. Please check the dataset structure.\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "    print(f\"Looking for stories in {section_path}\")\n",
        "    story_files = glob.glob(os.path.join(section_path, \"*.csv\"))\n",
        "\n",
        "    if not story_files:\n",
        "        print(f\"No story files found in {section_path}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    print(f\"Found {len(story_files)} story files\")\n",
        "    all_stories = []\n",
        "\n",
        "    for file in story_files:\n",
        "        try:\n",
        "            # Read the story file\n",
        "            df = pd.read_csv(file)\n",
        "\n",
        "            # Extract story name from filename\n",
        "            story_name = os.path.basename(file).replace('-story.csv', '')\n",
        "\n",
        "            # Add story name to dataframe\n",
        "            df['story_name'] = story_name\n",
        "\n",
        "            # Add to collection\n",
        "            all_stories.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file}: {e}\")\n",
        "\n",
        "    if not all_stories:\n",
        "        print(\"No valid stories processed.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Combine all stories\n",
        "    stories_df = pd.concat(all_stories)\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save processed stories\n",
        "    stories_df.to_csv(os.path.join(output_dir, \"fairytale_stories.csv\"), index=False)\n",
        "    print(f\"Saved {len(stories_df)} story sections from {len(all_stories)} stories\")\n",
        "\n",
        "    return stories_df\n",
        "\n",
        "# Process the FairytaleQA dataset\n",
        "stories_df = process_fairytale_stories(fairytale_dir)\n",
        "print(f\"Processed stories dataframe shape: {stories_df.shape}\")\n",
        "print(f\"Columns: {stories_df.columns.tolist()}\")\n",
        "print(f\"Sample stories:\\n{stories_df.head()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4IPrPZ7FgHDG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0469700-f613-4d65-819b-f99dfe79d994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Age of Acquisition data from data/raw/AoA_ratings_Kuperman_et_al_BRM.xlsx\n",
            "AoA data columns: ['Word', 'OccurTotal', 'OccurNum', 'Freq_pm', 'Rating.Mean', 'Rating.SD', 'Dunno']\n",
            "Age range in dataset: 1 to 25\n",
            "Age 1: 3 appropriate words\n",
            "Age 2: 48 appropriate words\n",
            "Age 3: 338 appropriate words\n",
            "Age 4: 994 appropriate words\n",
            "Age 5: 2043 appropriate words\n",
            "Age 6: 3497 appropriate words\n",
            "Age 7: 5423 appropriate words\n",
            "Age 8: 8067 appropriate words\n",
            "Age 9: 11267 appropriate words\n",
            "Age 10: 14956 appropriate words\n",
            "Age 11: 18864 appropriate words\n",
            "Age 12: 22727 appropriate words\n",
            "Age 13: 26004 appropriate words\n",
            "Age 14: 28482 appropriate words\n",
            "Age 15: 29958 appropriate words\n",
            "Age 16: 30693 appropriate words\n",
            "Age 17: 30995 appropriate words\n",
            "Age 18: 31073 appropriate words\n",
            "Age 19: 31096 appropriate words\n",
            "Age 20: 31103 appropriate words\n",
            "Age 21: 31103 appropriate words\n",
            "Age 22: 31103 appropriate words\n",
            "Age 23: 31103 appropriate words\n",
            "Age 24: 31104 appropriate words\n",
            "Age 25: 31104 appropriate words\n",
            "Age vocabulary saved to data/processed/age_vocabulary.pkl\n",
            "Word-to-age mapping saved to data/processed/word_to_age.pkl\n",
            "Sample words for youngest age (1): ['bantling', 'mama', 'momma']\n"
          ]
        }
      ],
      "source": [
        "def process_age_vocabulary(aoa_file, output_dir=\"data/processed\"):\n",
        "    \"\"\"Process Age of Acquisition dataset for efficient word-age filtering\"\"\"\n",
        "    print(f\"Processing Age of Acquisition data from {aoa_file}\")\n",
        "\n",
        "    # Load AoA dataset\n",
        "    aoa_data = pd.read_excel(aoa_file)\n",
        "\n",
        "    # Print columns for debugging\n",
        "    print(f\"AoA data columns: {aoa_data.columns.tolist()}\")\n",
        "\n",
        "    # Verify \"Rating.Mean\" column exists (average age of acquisition)\n",
        "    if 'Rating.Mean' not in aoa_data.columns:\n",
        "        print(\"Warning: 'Rating.Mean' column not found!\")\n",
        "        # Try to find an alternative column\n",
        "        age_columns = [col for col in aoa_data.columns if any(term in col.lower() for term in ['age', 'rating', 'mean'])]\n",
        "        if age_columns:\n",
        "            rating_col = age_columns[0]\n",
        "            print(f\"Using '{rating_col}' instead\")\n",
        "        else:\n",
        "            print(\"No suitable age rating column found!\")\n",
        "            return None\n",
        "    else:\n",
        "        rating_col = 'Rating.Mean'\n",
        "\n",
        "    # Verify \"Word\" column exists\n",
        "    if 'Word' not in aoa_data.columns:\n",
        "        print(\"Warning: 'Word' column not found!\")\n",
        "        # Try first string column\n",
        "        string_cols = aoa_data.select_dtypes(include=['object']).columns\n",
        "        if len(string_cols) > 0:\n",
        "            word_col = string_cols[0]\n",
        "            print(f\"Using '{word_col}' as the word column\")\n",
        "        else:\n",
        "            print(\"No suitable word column found!\")\n",
        "            return None\n",
        "    else:\n",
        "        word_col = 'Word'\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Find the minimum and maximum ages in the dataset\n",
        "    min_age = int(aoa_data[rating_col].min())\n",
        "    max_age = int(aoa_data[rating_col].max())\n",
        "\n",
        "    print(f\"Age range in dataset: {min_age} to {max_age}\")\n",
        "\n",
        "    # Create age-appropriate vocabulary for all ages in the range\n",
        "    age_vocab = {}\n",
        "\n",
        "    for age in range(min_age, max_age + 1):\n",
        "        # Words that are acquired at or before this age\n",
        "        # (include slightly more advanced words to ensure sufficient vocabulary)\n",
        "        age_words = aoa_data[aoa_data[rating_col] <= age + 1]\n",
        "\n",
        "        # Get list of words appropriate for this age\n",
        "        age_vocab[age] = age_words[word_col].dropna().str.lower().tolist()\n",
        "        print(f\"Age {age}: {len(age_vocab[age])} appropriate words\")\n",
        "\n",
        "    # Save as pickle for easy loading\n",
        "    with open(os.path.join(output_dir, \"age_vocabulary.pkl\"), 'wb') as f:\n",
        "        pickle.dump(age_vocab, f)\n",
        "\n",
        "    # Create and save word-to-age mapping for more efficient lookups\n",
        "    word_to_age = {}\n",
        "    for age in range(min_age, max_age + 1):\n",
        "        for word in age_vocab[age]:\n",
        "            # Only add word if not already in dictionary\n",
        "            # This ensures we store the youngest age at which a word is appropriate\n",
        "            if word not in word_to_age:\n",
        "                word_to_age[word] = age\n",
        "\n",
        "    # Save word-to-age mapping\n",
        "    with open(os.path.join(output_dir, \"word_to_age.pkl\"), 'wb') as f:\n",
        "        pickle.dump(word_to_age, f)\n",
        "\n",
        "    print(f\"Age vocabulary saved to {output_dir}/age_vocabulary.pkl\")\n",
        "    print(f\"Word-to-age mapping saved to {output_dir}/word_to_age.pkl\")\n",
        "\n",
        "    return age_vocab\n",
        "\n",
        "# Process Age of Acquisition dataset\n",
        "age_vocab = process_age_vocabulary(os.path.join(\"data/raw\", aoa_filename))\n",
        "min_age = min(age_vocab.keys()) if age_vocab else 0\n",
        "print(f\"Sample words for youngest age ({min_age}): {list(age_vocab[min_age])[:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "w6PHKzuCgKIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbcfc368-7919-40c8-a542-9f564f90738e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing morals from data/raw/morals.csv\n",
            "Morals data columns: ['Lesson', 'Themes', 'Example Scenario']\n",
            "Processed 665 moral entries across 208 themes\n",
            "\n",
            "Top themes:\n",
            "theme\n",
            "respect           32\n",
            "responsibility    25\n",
            "kindness          24\n",
            "friendship        14\n",
            "understanding     14\n",
            "empathy           13\n",
            "consideration     13\n",
            "safety            12\n",
            "communication     12\n",
            "learning          11\n",
            "Name: count, dtype: int64\n",
            "Sample morals:\n",
            "                                     moral         theme  \\\n",
            "0               Being honest is important.       honesty   \n",
            "1               Being honest is important.  truthfulness   \n",
            "2               Being honest is important.         trust   \n",
            "3  Treat others with kindness and respect.      kindness   \n",
            "4  Treat others with kindness and respect.       respect   \n",
            "\n",
            "                                             example  \n",
            "0  A character chooses to tell the truth about a ...  \n",
            "1  A character chooses to tell the truth about a ...  \n",
            "2  A character chooses to tell the truth about a ...  \n",
            "3  A character realizes treating someone nicely m...  \n",
            "4  A character realizes treating someone nicely m...  \n"
          ]
        }
      ],
      "source": [
        "def process_morals_dataset(morals_file, output_dir=\"data/processed\"):\n",
        "    \"\"\"Process morals dataset for story endings\"\"\"\n",
        "    print(f\"Processing morals from {morals_file}\")\n",
        "\n",
        "    # Load morals dataset\n",
        "    morals_data = pd.read_csv(morals_file)\n",
        "\n",
        "    # Print columns for debugging\n",
        "    print(f\"Morals data columns: {morals_data.columns.tolist()}\")\n",
        "\n",
        "    # Check for required columns\n",
        "    lesson_col = 'Lesson' if 'Lesson' in morals_data.columns else None\n",
        "    themes_col = 'Themes' if 'Themes' in morals_data.columns else None\n",
        "    example_col = 'Example Scenario' if 'Example Scenario' in morals_data.columns else None\n",
        "\n",
        "    if not lesson_col or not themes_col:\n",
        "        print(\"Error: Required columns not found in morals dataset\")\n",
        "        print(\"Needed: 'Lesson' and 'Themes' columns\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Process morals data\n",
        "    processed_morals = []\n",
        "\n",
        "    for _, row in morals_data.iterrows():\n",
        "        lesson = row[lesson_col]\n",
        "        themes_str = row[themes_col]\n",
        "\n",
        "        # Skip rows with missing data\n",
        "        if pd.isna(lesson) or pd.isna(themes_str):\n",
        "            continue\n",
        "\n",
        "        # Extract example if available\n",
        "        example = row[example_col] if example_col and not pd.isna(row[example_col]) else \"\"\n",
        "\n",
        "        # Split themes (assuming comma-separated list)\n",
        "        themes = [theme.strip() for theme in str(themes_str).split(',')]\n",
        "\n",
        "        # Create an entry for each theme\n",
        "        for theme in themes:\n",
        "            if theme:  # Skip empty themes\n",
        "                processed_morals.append({\n",
        "                    'moral': lesson,\n",
        "                    'theme': theme.lower(),\n",
        "                    'example': example\n",
        "                })\n",
        "\n",
        "    # Create and save processed dataset\n",
        "    processed_df = pd.DataFrame(processed_morals)\n",
        "    processed_df.to_csv(os.path.join(output_dir, \"processed_morals.csv\"), index=False)\n",
        "\n",
        "    # Print summary\n",
        "    theme_counts = processed_df['theme'].value_counts()\n",
        "    print(f\"Processed {len(processed_df)} moral entries across {len(theme_counts)} themes\")\n",
        "    print(\"\\nTop themes:\")\n",
        "    print(theme_counts.head(10))\n",
        "\n",
        "    return processed_df\n",
        "\n",
        "# Process morals dataset\n",
        "morals_df = process_morals_dataset(os.path.join(\"data/raw\", morals_filename))\n",
        "print(f\"Sample morals:\\n{morals_df.head()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HDcsTjQdgPQZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713,
          "referenced_widgets": [
            "ac49a221a5e74a9cb4e3b9b348f02d38",
            "7a9387fa10f54daeba7a2fd5150fbdc3",
            "83e797bf73d048418d3fa32e81c9757d",
            "e6fd7d7a6ddc4110a99d0a7e00c20f82",
            "13ef3a2a4f5f4a77b75608a6fe0d81ef",
            "31ed1a99ac8a418ba94221e7b4cd15c1",
            "87b077ae759d47d0a404498fc4101354",
            "a2b91c5e02f34d9ebb46834511542356",
            "cd0e3221fe1c483a8a415537aa85a700",
            "494c29446a0a44799476b074f2735262",
            "03006103c30d4bf89145710dc3923f33",
            "a3bd745d85c748b9abfc8f2368d8de48",
            "6b51fad1df7d495ba0856e4ae8ece12e",
            "99e974daf6c844c798afe4eaca7d6362",
            "cbd6f33314614dfc960f9fd8fb54087f",
            "c6348de1a79c44fc96d674ce4d4d0c8e",
            "04d163af4c2c4f71bd6357d5bca7964a",
            "12713567368348afad0dec139c7b653e",
            "35d63f322cf14e73aed5f41e549ecd7b",
            "b09b69cd383d4a5087234241f94b254f",
            "75f940e77fb642ef9ce35972761911c4",
            "9da81c461cee4047b9ac0500e73cd9fe",
            "6b958f97061c4c6391ce603d25e94646",
            "1afa6ce3c09d49fab25e23ad1584b44f",
            "9e91495bc2df4c3a8350eadef4830f5d",
            "4d2f23db914a44419f5088cb4fafe2b8",
            "444bd13a851f40c0b750eacf059a9156",
            "5f122716850647b7b3683acb851af8eb",
            "39ac37658af3435190716b58e8a95434",
            "394b57b467514d77bf172dda56f0e044",
            "889a95b9dbff436c9afe4310c3b70fb8",
            "7d7917aa28664017aa1562c50b9c6f60",
            "05f0df7be3734eeeaf45591781711baf",
            "a8e22a19169f41559479fe35c903e129",
            "49b43bb044c642469f80623c605467dd",
            "249d21d1b12f4e16be3b231a4caf09e3",
            "da48ec8807614a0c9a6fd93d588a9917",
            "799cf6034e8e41a99ffb4d8624cccf9f",
            "15fd8798eadb4bf4843b2054b546dc0d",
            "79358e5d8e234c45bd6a22005d5cf08c",
            "6e46986340594978af47d11b07c199bf",
            "24aa5805f9144c179cb1099c0afa437e",
            "075ab3734a584c8397d207697926f196",
            "b64a23a93d7d492ea8dffd33f0026a38",
            "59975b2ce11b4742a953a2e16bd19499",
            "f8be928423b443a299458c4c435f256c",
            "ae40a93e0b7e4e1f8e14358294258267",
            "9b14985e7d5f46938d6587f50618224e",
            "b964e1ccd867400d9d24021782e4e28a",
            "d98a8f175bd84565957b30ac2731a435",
            "004f945849ca4f89a253fddc5e4e1ccb",
            "7ac9be9b047e4a5c8697ee46264e796f",
            "cd78d949763649579fb4263fd9714dfd",
            "78892ca2c42e43f5b2159f52ba71d54f",
            "f01a3456b7974bcabd56098e0870e745",
            "422f9721167043af875de535be9272f5",
            "b1d2f7f44415462390d17e838b1aa4ae",
            "8844c9cfe93748fc82f6630ca9836754",
            "4fad3bc985e04458ad9944775ed35618",
            "6de4a140214c4487a522b48e8255c29f",
            "eddb382ef4b1478bacd01baf432cf8d5",
            "d22cedc9bff8468da2adb90b2c966c85",
            "f4642c72671148959b93977763cab540",
            "d4804fdd26734fb48b81034b9b49ad2b",
            "6f6f6e73473d4272aa7da6ca83caeaea",
            "6a3e503f5cea48a38f9f5edcfe2694bf",
            "7e9ab2f9fd274d6da2154c55412979e5",
            "e59973e8d1214c7a95b7a6f9d0cb9846",
            "c94246e9671846f9b0dd38c0da276b25",
            "79c1d0b581ac4eaf92ff900940bfb3c1",
            "8265e06f8ae74b8c983c283da7209680",
            "bb9c3317ef314cc89184a87a13ec2830",
            "1add1aaa9fd44ac1a0709ed87c9d6181",
            "1038a691352440f29338905f4c411fe7",
            "0d2045a3c6774b0ca9effef27d5a82e7",
            "604b13ea22ec4fc0a1b57fbfc9e2e8be",
            "cf0a335fa850436eabeb7b5ba7ce9ed7",
            "8c29f44966984a178b74fda46327d3b6",
            "b8f39e62adc1423b9f92483a16d55d35",
            "54a28ba794e14847a8a0470e05629199",
            "2d5232e2937849e98f8e9d8c98e5b497",
            "ca4e3e1d52774bad8e839b77c965c4de",
            "d7446700e225477288a36efc2046a300",
            "f14014573a574344b8a59029b9c78bfc",
            "caccbd32adc442298038fcf9a4d8fc87",
            "e7eed0fcc9c84c6aab9fb605c0cd1362",
            "088ce609db11405183e7256aee02b0e1",
            "7aa6eab482ab40cf99b0762f73e15a0f",
            "1b02f6a02fad4ceaa96f614bffb86826",
            "e3e12dde75fa4fda8e79e7906ab79f2b",
            "506f76cbd713444c95a1402a0e8d5b07",
            "7802ec6e8f7c4fc082d53cd0203daee3",
            "feadb7d9a84f40a8a38b071e1e778944",
            "cca9d99fb011462c9d9d3f283d302260",
            "be0bf657e0d74035b97808b058b5ab77",
            "fef2348b1cef481e819e64b9ac80e19e",
            "180e97d0014e4126912181f0ccf9a78f",
            "394813e5c6e74f88bbd435efaba5fbb8",
            "237e59eda1294ab7809d6d8ff488a529",
            "2cbca838c3e746f0a2332a465f45ad9b",
            "142a380256c84c368a8ecb5d1905b37c",
            "3fd8b59ab81843848b306f8d34623ccb",
            "b6014b646dff4c8d8cd80eb3eeca28f4",
            "774e3eb27cd0434fbf21753b681196ed",
            "c8e2520616634830a4bfdf7afda635d8",
            "959d7def5bb847e2947ea1deedd2dfe6",
            "fba7deec704341ebae4623904f2a661f",
            "a1cf41ec1e3a45b5aed2256bd363275a",
            "6c217b2774b347788a8b744ccaa6f6c4",
            "6e8b0a840c7547cf8a8daafe885e7542",
            "c6c48ac4e0c5451c94fa3c8ec41a1e6e",
            "149bb04e1f444f94898b48f38167c9b5",
            "52161732f8d84164b4678e9ec6585653",
            "f3bb0a6153944692a2c26f040ae7458c",
            "74d864efb2404e47a077cc2d56c5f5f5",
            "5969fa5c5e794b948575e5d468d9b397",
            "68c6f3d4b5aa4f4caa5514f7d389df7c",
            "2b6bf8cf4f644b848f26c71f55cfc225",
            "d1f8064486544f62a7c315320caae3c5",
            "44cc8f363e704eb1a559a0ae8a06c317",
            "6009a533065d4a3bb48a9507f9a81082",
            "81b987227ed74014bca9536b85938af9",
            "7e8b8b72cc1c44168a7f462ede185687",
            "dc5582fb320b45f08413467b7675d5a0",
            "8e281757c5f748e2ba5f128195f485f5",
            "3aef0723206b4558837be3a010ba4887",
            "345e213f3ec94cf49611fca1ad04d8f7",
            "a0a16bfbab824622b229e151b3caadae",
            "b94fad9a3e014228997fb29de5cba26e",
            "f569e30338364cc5b026361cd21bb912",
            "40c8f34b3f1d4e24be527ca16ccfb2ab",
            "06e951e7f6db4628aa91f35249f50ad8",
            "5d961bde90b54480995c3b98304215a1",
            "878f693acb1d4f43b28193bc0aa65a01",
            "4da23039fbd4448b8f4e136f2f0715b7",
            "63cc15138d784ad7b594e2e460e85667",
            "9b39069a1bfe4d92b7a6ec20ca597e3d",
            "0ef7af453c424aeca85db3466c2df7de",
            "1852b0df60b741b2a70dd6d1f34bb1b0",
            "095c97d9f00f4bd39d1bfbfa58fe98a6",
            "4381d401f5a44660851ab8d7f27e6e75",
            "f2ef382713ce47d8af79f4d3f1ff8308",
            "7efaa07c08014df6aa2ecc0c62e6c916"
          ]
        },
        "outputId": "b4d58eb7-6591-46f8-d787-053eb54e2577"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating FAISS indexes for fast vector retrieval...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac49a221a5e74a9cb4e3b9b348f02d38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3bd745d85c748b9abfc8f2368d8de48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b958f97061c4c6391ce603d25e94646"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8e22a19169f41559479fe35c903e129"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59975b2ce11b4742a953a2e16bd19499"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "422f9721167043af875de535be9272f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e9ab2f9fd274d6da2154c55412979e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c29f44966984a178b74fda46327d3b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b02f6a02fad4ceaa96f614bffb86826"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cbca838c3e746f0a2332a465f45ad9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6c48ac4e0c5451c94fa3c8ec41a1e6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded SentenceTransformer model\n",
            "Creating story embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/128 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81b987227ed74014bca9536b85938af9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created FAISS index for 4095 stories\n",
            "Creating moral embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/21 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d961bde90b54480995c3b98304215a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created FAISS index for 665 morals\n",
            "FAISS indexes created successfully\n"
          ]
        }
      ],
      "source": [
        "def create_faiss_indexes(stories_df, morals_df, output_dir=\"data/processed\"):\n",
        "    \"\"\"Create FAISS indexes for fast vector retrieval\"\"\"\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    import faiss\n",
        "\n",
        "    print(\"Creating FAISS indexes for fast vector retrieval...\")\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Load embedding model\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    print(\"Loaded SentenceTransformer model\")\n",
        "\n",
        "    # Create FAISS index for stories\n",
        "    if not stories_df.empty and 'text' in stories_df.columns:\n",
        "        print(\"Creating story embeddings...\")\n",
        "        story_texts = stories_df['text'].fillna('').tolist()\n",
        "        story_embeddings = model.encode(story_texts, show_progress_bar=True)\n",
        "\n",
        "        # Normalize embeddings\n",
        "        faiss.normalize_L2(story_embeddings)\n",
        "\n",
        "        # Create FAISS index\n",
        "        story_index = faiss.IndexFlatIP(story_embeddings.shape[1])\n",
        "        story_index.add(story_embeddings)\n",
        "\n",
        "        # Save index\n",
        "        faiss.write_index(story_index, os.path.join(output_dir, \"stories.index\"))\n",
        "        print(f\"Created FAISS index for {len(story_texts)} stories\")\n",
        "    else:\n",
        "        print(\"No valid story data for FAISS index\")\n",
        "\n",
        "    # Create FAISS index for morals\n",
        "    if not morals_df.empty and 'moral' in morals_df.columns:\n",
        "        print(\"Creating moral embeddings...\")\n",
        "        moral_texts = morals_df['moral'].fillna('').tolist()\n",
        "        moral_embeddings = model.encode(moral_texts, show_progress_bar=True)\n",
        "\n",
        "        # Normalize embeddings\n",
        "        faiss.normalize_L2(moral_embeddings)\n",
        "\n",
        "        # Create FAISS index\n",
        "        moral_index = faiss.IndexFlatIP(moral_embeddings.shape[1])\n",
        "        moral_index.add(moral_embeddings)\n",
        "\n",
        "        # Save index\n",
        "        faiss.write_index(moral_index, os.path.join(output_dir, \"morals.index\"))\n",
        "        print(f\"Created FAISS index for {len(moral_texts)} morals\")\n",
        "    else:\n",
        "        print(\"No valid morals data for FAISS index\")\n",
        "\n",
        "    print(\"FAISS indexes created successfully\")\n",
        "\n",
        "# Create FAISS indexes\n",
        "create_faiss_indexes(stories_df, morals_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5A_tRvKrgSJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54db02ab-edc0-4028-d1a3-517c5488e234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating StoryRAG instance...\n",
            "Initializing StoryRAG with FAISS...\n",
            "Loaded 4095 story sections\n",
            "Loaded FAISS index with 4095 story vectors\n",
            "Loaded 665 morals\n",
            "Loaded FAISS index with 665 moral vectors\n",
            "Loaded vocabulary for ages [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
            "Loaded word-to-age mapping with 31104 words\n",
            "StoryRAG initialization complete!\n",
            "StoryRAG instance created successfully!\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "class StoryRAG:\n",
        "    \"\"\"\n",
        "    Retrieval-Augmented Generation system for dynamic children's stories.\n",
        "    Uses FAISS for efficient vector search to quickly retrieve relevant content.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_dir=\"data/processed\"):\n",
        "        \"\"\"Initialize with processed datasets and FAISS indexes\"\"\"\n",
        "        print(\"Initializing StoryRAG with FAISS...\")\n",
        "\n",
        "        # Load embedding model\n",
        "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "        # Load stories dataset\n",
        "        try:\n",
        "            self.stories_df = pd.read_csv(os.path.join(data_dir, \"fairytale_stories.csv\"))\n",
        "            print(f\"Loaded {len(self.stories_df)} story sections\")\n",
        "\n",
        "            # Load FAISS index for stories\n",
        "            index_path = os.path.join(data_dir, \"stories.index\")\n",
        "            if os.path.exists(index_path):\n",
        "                self.story_index = faiss.read_index(index_path)\n",
        "                print(f\"Loaded FAISS index with {self.story_index.ntotal} story vectors\")\n",
        "            else:\n",
        "                self.story_index = None\n",
        "                print(\"No story index found\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading stories: {e}\")\n",
        "            self.stories_df = pd.DataFrame(columns=['section', 'text', 'story_name'])\n",
        "            self.story_index = None\n",
        "\n",
        "        # Load morals dataset\n",
        "        try:\n",
        "            self.morals_df = pd.read_csv(os.path.join(data_dir, \"processed_morals.csv\"))\n",
        "            print(f\"Loaded {len(self.morals_df)} morals\")\n",
        "\n",
        "            # Load FAISS index for morals\n",
        "            index_path = os.path.join(data_dir, \"morals.index\")\n",
        "            if os.path.exists(index_path):\n",
        "                self.moral_index = faiss.read_index(index_path)\n",
        "                print(f\"Loaded FAISS index with {self.moral_index.ntotal} moral vectors\")\n",
        "            else:\n",
        "                self.moral_index = None\n",
        "                print(\"No morals index found\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading morals: {e}\")\n",
        "            self.morals_df = pd.DataFrame(columns=['moral', 'theme'])\n",
        "            self.moral_index = None\n",
        "\n",
        "        # Load age vocabulary\n",
        "        try:\n",
        "            with open(os.path.join(data_dir, \"age_vocabulary.pkl\"), 'rb') as f:\n",
        "                self.age_vocab = pickle.load(f)\n",
        "            print(f\"Loaded vocabulary for ages {list(self.age_vocab.keys())}\")\n",
        "\n",
        "            # Also load word-to-age mapping for faster lookups\n",
        "            with open(os.path.join(data_dir, \"word_to_age.pkl\"), 'rb') as f:\n",
        "                self.word_to_age = pickle.load(f)\n",
        "            print(f\"Loaded word-to-age mapping with {len(self.word_to_age)} words\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading age vocabulary: {e}\")\n",
        "            self.age_vocab = {}\n",
        "            self.word_to_age = {}\n",
        "\n",
        "        # Create fallback elements for reliability\n",
        "        self.default_stories = [\n",
        "            \"Once upon a time, a brave young girl made friends with animals in the forest.\",\n",
        "            \"Long ago, two children found a magical object that taught them about friendship.\",\n",
        "            \"In a small village, a child learned that helping others leads to true friendship.\"\n",
        "        ]\n",
        "\n",
        "        self.default_morals = [\n",
        "            \"True friendship means being there for others in both good and difficult times.\",\n",
        "            \"Kindness and honesty are the foundation of lasting friendships.\",\n",
        "            \"Sharing and cooperation make everyone happier than keeping things to yourself.\"\n",
        "        ]\n",
        "\n",
        "        print(\"StoryRAG initialization complete!\")\n",
        "\n",
        "    def get_story_by_theme(self, theme, top_k=3):\n",
        "        \"\"\"Retrieve stories relevant to the given theme using FAISS\"\"\"\n",
        "        if self.story_index is None or self.stories_df.empty:\n",
        "            # Return default stories if no index or data\n",
        "            return [{\"text\": [s], \"story_name\": f\"Default {i+1}\"} for i, s in enumerate(self.default_stories[:top_k])]\n",
        "\n",
        "        # Encode the theme\n",
        "        query_embedding = self.model.encode([theme])\n",
        "\n",
        "        # Normalize the query embedding\n",
        "        faiss.normalize_L2(query_embedding)\n",
        "\n",
        "        # Search the FAISS index\n",
        "        distances, indices = self.story_index.search(query_embedding, top_k*3)  # Get more results to find unique stories\n",
        "\n",
        "        # Get the unique story names from the top results\n",
        "        story_names = []\n",
        "        seen = set()\n",
        "        for i, idx in enumerate(indices[0]):\n",
        "            if idx < len(self.stories_df):\n",
        "                story_name = self.stories_df.iloc[idx]['story_name']\n",
        "                if story_name not in seen:\n",
        "                    seen.add(story_name)\n",
        "                    story_names.append((story_name, float(distances[0][i])))\n",
        "\n",
        "        # Return the full stories (up to top_k)\n",
        "        results = []\n",
        "        for i, (story_name, similarity) in enumerate(story_names[:top_k]):\n",
        "            story_sections = self.get_story_sections(story_name)\n",
        "            if story_sections:\n",
        "                results.append({\n",
        "                    \"story_name\": story_name,\n",
        "                    \"sections\": story_sections,\n",
        "                    \"similarity\": similarity\n",
        "                })\n",
        "\n",
        "        # If we didn't find enough stories, add defaults\n",
        "        while len(results) < top_k:\n",
        "            idx = len(results)\n",
        "            results.append({\n",
        "                \"story_name\": f\"Default {idx+1}\",\n",
        "                \"sections\": [self.default_stories[idx % len(self.default_stories)]],\n",
        "                \"similarity\": 0.5\n",
        "            })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def get_story_sections(self, story_name, max_sections=None):\n",
        "        \"\"\"Get sections of a specific story in order\"\"\"\n",
        "        if self.stories_df.empty:\n",
        "            return []\n",
        "\n",
        "        # Filter for the requested story\n",
        "        story_sections = self.stories_df[self.stories_df['story_name'] == story_name]\n",
        "\n",
        "        if story_sections.empty:\n",
        "            return []\n",
        "\n",
        "        # Sort by section number if available\n",
        "        if 'section' in story_sections.columns:\n",
        "            story_sections = story_sections.sort_values('section')\n",
        "\n",
        "        # Get the text for each section\n",
        "        sections = story_sections['text'].tolist()\n",
        "\n",
        "        # Limit to max_sections if specified\n",
        "        if max_sections is not None and max_sections > 0:\n",
        "            sections = sections[:max_sections]\n",
        "\n",
        "        return sections\n",
        "\n",
        "    def get_complete_story(self, story_name):\n",
        "        \"\"\"Get all sections of a specific story in order\"\"\"\n",
        "        return self.get_story_sections(story_name)\n",
        "\n",
        "    def get_moral_by_theme(self, theme, top_k=3):\n",
        "        \"\"\"Retrieve morals relevant to the given theme using FAISS\"\"\"\n",
        "        if self.moral_index is None or self.morals_df.empty:\n",
        "            # Return default morals if no index or data\n",
        "            return [{\"moral\": m, \"theme\": theme} for m in self.default_morals[:top_k]]\n",
        "\n",
        "        # Try exact theme match first\n",
        "        theme_matches = self.morals_df[self.morals_df['theme'].str.lower() == theme.lower()]\n",
        "\n",
        "        if not theme_matches.empty:\n",
        "            # Return exact theme matches\n",
        "            results = []\n",
        "            for _, row in theme_matches.iterrows():\n",
        "                results.append({\n",
        "                    \"moral\": row['moral'],\n",
        "                    \"theme\": row['theme'],\n",
        "                    \"example\": row.get('example', '')\n",
        "                })\n",
        "            return results[:top_k]\n",
        "\n",
        "        # If no exact matches, use FAISS\n",
        "        query_embedding = self.model.encode([theme])\n",
        "\n",
        "        # Normalize the query embedding\n",
        "        faiss.normalize_L2(query_embedding)\n",
        "\n",
        "        # Search the FAISS index\n",
        "        distances, indices = self.moral_index.search(query_embedding, top_k)\n",
        "\n",
        "        # Return relevant morals\n",
        "        results = []\n",
        "        for i, idx in enumerate(indices[0]):\n",
        "            if idx < len(self.morals_df):\n",
        "                row = self.morals_df.iloc[idx]\n",
        "                results.append({\n",
        "                    \"moral\": row['moral'],\n",
        "                    \"theme\": row['theme'],\n",
        "                    \"example\": row.get('example', ''),\n",
        "                    \"similarity\": float(distances[0][i])\n",
        "                })\n",
        "\n",
        "        return results\n",
        "\n",
        "    def get_story_materials(self, theme, age, length=\"5min\", character_name=None, character_traits=None):\n",
        "        \"\"\"\n",
        "        Get all necessary story materials based on theme and age.\n",
        "        Uses FAISS for fast retrieval of relevant content.\n",
        "        \"\"\"\n",
        "        print(f\"Getting story materials for theme: {theme}, age: {age}, length: {length}\")\n",
        "\n",
        "        # Set story parameters based on length\n",
        "        if length == \"5min\":\n",
        "            paragraphs = 4\n",
        "            decision_count = 1\n",
        "        else:  # 10min\n",
        "            paragraphs = 8\n",
        "            decision_count = 2\n",
        "\n",
        "        # Get relevant stories using FAISS\n",
        "        story_results = self.get_story_by_theme(theme)\n",
        "\n",
        "        # Get relevant morals using FAISS\n",
        "        moral_results = self.get_moral_by_theme(theme)\n",
        "\n",
        "        # Return all materials in a structured format\n",
        "        return {\n",
        "            \"theme\": theme,\n",
        "            \"age\": age,\n",
        "            \"length\": length,\n",
        "            \"paragraphs\": paragraphs,\n",
        "            \"decision_count\": decision_count,\n",
        "            \"character\": {\n",
        "                \"name\": character_name,\n",
        "                \"traits\": character_traits\n",
        "            },\n",
        "            \"story_references\": story_results,\n",
        "            \"morals\": moral_results\n",
        "        }\n",
        "\n",
        "    def filter_age_appropriate(self, text, age):\n",
        "        \"\"\"\n",
        "        Filter text to ensure age-appropriate vocabulary.\n",
        "        If words are not in the age vocabulary, keep the original words.\n",
        "        \"\"\"\n",
        "        if age > 10:\n",
        "            age = 10  # Cap at maximum age\n",
        "\n",
        "        if age not in self.age_vocab or not self.word_to_age:\n",
        "            return text  # Return original if no vocabulary data\n",
        "\n",
        "        # Get allowed words for this age\n",
        "        allowed_words = set(self.age_vocab[age])\n",
        "\n",
        "        # Process text word by word\n",
        "        words = text.split()\n",
        "        filtered = []\n",
        "\n",
        "        for word in words:\n",
        "            # Extract just the alphabetic characters for checking\n",
        "            clean_word = ''.join(c.lower() for c in word if c.isalpha())\n",
        "\n",
        "            # Keep short words, punctuation, and words in the age vocabulary\n",
        "            # If not in allowed words, keep the original word instead of marking it\n",
        "            filtered.append(word)\n",
        "\n",
        "        return ' '.join(filtered)\n",
        "\n",
        "# Initialize the StoryRAG system\n",
        "print(\"Creating StoryRAG instance...\")\n",
        "rag = StoryRAG()\n",
        "print(\"StoryRAG instance created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ufp13ziaiJo2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbfc1f1b-6459-46d6-f6eb-a04961e15c4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Testing StoryRAG System ===\n",
            "\n",
            "--- Testing theme: friendship ---\n",
            "Getting story materials for theme: friendship, age: 7, length: 5min\n",
            "Retrieved 3 story references\n",
            "\n",
            "Story 1: 'remarkable-rocket'\n",
            "\n",
            "Section 1:\n",
            "The King's son was going to be married, so there were general rejoicings.  He had waited a whole year for his bride, and at last she had arrived.  She was a Russian Princess, and had driven all the way from Finland in a sledge drawn by six reindeer.  The sledge was shaped like a great golden swan, and between the swan's wings lay the little Princess herself.  Her long ermine-cloak reached right down to her feet, on her head was a tiny cap of silver tissue, and she was as pale as the Snow Palace in which she had always lived.  So pale was she that as she drove through the streets all the people wondered.  \"She is like a white rose!\" they cried, and they threw down flowers on her from the balconies.\n",
            "\n",
            "Section 2:\n",
            "At the gate of the Castle the Prince was waiting to receive her.  He had dreamy violet eyes, and his hair was like fine gold.  When he saw her he sank upon one knee, and kissed her hand.\n",
            "\n",
            "\"Your picture was beautiful,\" he murmured, \"but you are more beautiful than your picture\"; and the little Princess blushed.\n",
            "\n",
            "\"She was like a white rose before,\" said a young Page to his neighbour, \"but she is like a red rose now\"; and the whole Court was delighted.\n",
            "\n",
            "... (29 more sections)\n",
            "\n",
            "Story 2: 'canonbie-dick-and-thomas-of-ercildoune'\n",
            "\n",
            "Section 1:\n",
            "It chanced, long years ago, that a certain horse-dealer lived in the\n",
            "South of Scotland, near the Border. It was not very far from Longtown. He was\n",
            "known as Canonbie Dick. As he went up and down the country, he\n",
            "almost always had a long string of horses behind him. He bought them at\n",
            "one fair and sold at another, generally managing to turn a good big\n",
            "penny by the transaction.\n",
            "\n",
            "He was a very fearless man, not easily daunted. The people who knew\n",
            "him used to say that if Canonbie Dick dare not attempt a thing, no one\n",
            "else need be asked to do it.\n",
            "\n",
            "One evening, he was returning from a fair at some distance from his\n",
            "home with a pair of horses which he had not succeeded in selling. He was\n",
            "riding over Bowden Moor, which lies to the west of the Eildon Hills.\n",
            "These hills are, as all men know, the scene of some of the most famous\n",
            "of Thomas the Rhymer's prophecies. Also, so men say, they are the\n",
            "sleeping-place of King Arthur and his Knights, who rest under the three\n",
            "high peaks, waiting for the mystic call that shall awake them.\n",
            "\n",
            "Section 2:\n",
            "But little recked the horse-dealer of Arthur and his Knights, nor yet of\n",
            "Thomas the Rhymer. He was riding along at a snail's pace, thinking over\n",
            "the bargains which he had made at the fair that day. He was wondering when\n",
            "he was likely to dispose of his two remaining horses.\n",
            "\n",
            "All at once he was startled by the approach of a venerable man, with\n",
            "white hair and an old-world dress, who seemed almost to start out of the\n",
            "ground, so suddenly did he make his appearance.\n",
            "\n",
            "When they met, the stranger stopped. To Canonbie Dick's great\n",
            "amazement, asked him for how much he would be willing to part with his\n",
            "horses.\n",
            "\n",
            "... (11 more sections)\n",
            "\n",
            "Story 3: 'which-was-the-foolishest'\n",
            "\n",
            "Section 1:\n",
            "In a little village that stood on a wide plain, where you could see\n",
            "the sun from the moment he rose to the moment he set, there lived two\n",
            "couples side by side. The men, who worked under the same master, were\n",
            "quite good friends, but the wives were always quarrelling, and the\n",
            "subject they quarrelled most about was--which of the two had the\n",
            "stupidest husband.\n",
            "\n",
            "Unlike most women--who think that anything that belongs to them must be\n",
            "better than what belongs to anyone else--each thought her husband the\n",
            "more foolish of the two.\n",
            "\n",
            "Section 2:\n",
            "'You should just see what he does!' one said to her neighbour. 'He puts\n",
            "on the baby's frock upside down, and, one day, I found him trying to\n",
            "feed her with boiling soup, and her mouth was scalded for days after.\n",
            "Then he picks up stones in the road and sows them instead of potatoes,\n",
            "and one day he wanted to go into the garden from the top window, because\n",
            "he declared it was a shorter way than through the door.'\n",
            "\n",
            "... (12 more sections)\n",
            "\n",
            "Retrieved 3 morals\n",
            "Sample moral: Sharing with others is kind.\n",
            "\n",
            "--- Testing theme: courage ---\n",
            "Getting story materials for theme: courage, age: 7, length: 5min\n",
            "Retrieved 3 story references\n",
            "\n",
            "Story 1: 'the-king-of-the-polar-bears'\n",
            "\n",
            "Section 1:\n",
            "The King of the Polar Bears lived among the icebergs in the far north country. He was old and monstrous big; he was wise and friendly to all who knew him. His body was thickly covered with long, white hair that glistened like silver under the rays of the midnight sun. His claws were strong and sharp, that he might walk safely over the smooth ice or grasp and tear the fishes and seals upon which he fed.\n",
            "\n",
            "The seals were afraid when he drew near, and tried to avoid him; but the gulls, both white and gray, loved him because he left the remnants of his feasts for them to devour.\n",
            "\n",
            "Often his subjects, the polar bears, came to him for advice when ill or in trouble; but they wisely kept away from his hunting grounds, lest they might interfere with his sport and arouse his anger.\n",
            "\n",
            "Section 2:\n",
            "The wolves, who sometimes came as far north as the icebergs, whispered among themselves that the King of the Polar Bears was either a magician or under the protection of a powerful fairy. For no earthly thing seemed able to harm him; he never failed to secure plenty of food, and he grew bigger and stronger day by day and year by year.\n",
            "\n",
            "Yet the time came when this monarch of the north met man, and his wisdom failed him.\n",
            "\n",
            "He came out of his cave among the icebergs one day and saw a boat moving through the strip of water which had been uncovered by the shifting of the summer ice. In the boat were men.\n",
            "\n",
            "... (14 more sections)\n",
            "\n",
            "Story 2: 'wunzh-the-father-of-indian-corn'\n",
            "\n",
            "Section 1:\n",
            "In time past--we can not tell exactly how many, many years ago--a poor\n",
            "Indian was living, with his wife and children, in a beautiful part of\n",
            "the country. He was not only poor, but he had the misfortune to be\n",
            "inexpert in procuring food for his family. His children were all too\n",
            "young to give him assistance.\n",
            "\n",
            "Although of a lowly condition and straitened in his circumstances, he\n",
            "was a man of kind and contented disposition. He was always thankful to\n",
            "the Great Spirit for every thing he received. He even stood in the door\n",
            "of his lodge to bless the birds that flew past in the summer evenings.\n",
            "Although, if he had been of a complaining temper, he might have repined\n",
            "that they were not rather spread upon the table for his evening meal.\n",
            "\n",
            "The same gracious and sweet disposition was inherited by his eldest son,\n",
            "who had now arrived at the proper age to undertake the ceremony of the\n",
            "fast. This was to learn what kind of a spirit would be his guide and guardian\n",
            "through life.\n",
            "\n",
            "Wunzh, for this was his name, had been an obedient boy from his\n",
            "infancy--pensive, thoughtful, and gentle--so that he was beloved by the\n",
            "whole family.\n",
            "\n",
            "Section 2:\n",
            "As soon as the first buds of spring appeared, and the delicious\n",
            "fragrance of the young year began to sweeten the air, his father, with\n",
            "the help of his younger brothers, built for Wunzh the customary little\n",
            "lodge. It was at a retired spot at some distance from their own, where he would\n",
            "not be disturbed during the solemn rite.\n",
            "\n",
            "To prepare himself, Wunzh sought to clear his heart of every evil\n",
            "thought, and to think of nothing that was not good, and beautiful, and\n",
            "kindly.\n",
            "\n",
            "That he might store his mind with pleasant ideas for his dreams, for the\n",
            "first few days he amused himself by walking in the woods and over the\n",
            "mountains, examining the early plants and flowers.\n",
            "\n",
            "As he rambled far and wide, through the wild country, he felt a strong\n",
            "desire to know how the plants and herbs and berries grew, without any\n",
            "aid from man. He wondered why it was that some kinds were good to eat, and that\n",
            "others were possessed of medicinal or poisonous power.\n",
            "\n",
            "After he had become too weak to walk about, and confined himself\n",
            "strictly to the lodge, he recalled these thoughts, and turning them in\n",
            "his mind, he wished he could dream of something that would prove a\n",
            "benefit to his father and family, and to all others of his\n",
            "fellow-creatures.\n",
            "\n",
            "... (8 more sections)\n",
            "\n",
            "Story 3: 'how-brave-walter-hunted-wolves'\n",
            "\n",
            "Section 1:\n",
            "A little back from the high road there stands a house which is called\n",
            "'Hemgard.' Perhaps you remember the two beautiful mountain ash trees by\n",
            "the reddish-brown palings, and the high gate. Or you remember the garden with the\n",
            "beautiful barberry bushes which are always the first to become grown\n",
            "in spring, and which in summer are weighed down with their beautiful\n",
            "berries.\n",
            "\n",
            "Behind the garden there is a hedge with tall aspens which rustle in the\n",
            "morning wind. Behind the hedge is a road, behind the road is a wood, and\n",
            "behind the wood the wide world.\n",
            "\n",
            "But on the other side of the garden there is a lake, and beyond the lake\n",
            "is a village, and all around stretch meadows and fields, now yellow, now\n",
            "green.\n",
            "\n",
            "In the pretty house, which has white window-frames, a neat porch and\n",
            "clean steps, which are always strewn with finely-cut juniper leaves,\n",
            "Walter's parents live. His brother Frederick, his sister Lotta, old\n",
            "Lena, Jonah, Caro and Bravo, Putte and Murre, and Kuckeliku.\n",
            "\n",
            "Caro lives in the dog house, Bravo in the stable, Putte with the\n",
            "stableman, Murre a little here and a little there, and Kuckeliku lives\n",
            "in the hen house, that is his kingdom.\n",
            "\n",
            "Section 2:\n",
            "Walter is six years old, and he must soon begin to go to school.\n",
            "He cannot read yet, but he can do many other things. He can turn\n",
            "cartwheels, stand on his head, ride see-saw, throw snowballs, play ball,\n",
            "crow like a cock, eat bread and butter and drink sour milk, and tear his\n",
            "trousers. He can wear holes in his elbows, break the crockery in pieces, throw\n",
            "balls through the windowpanes, draw old men on important papers, walk\n",
            "over the flower-beds, eat himself sick with gooseberries, and be well\n",
            "after a whipping. For the rest he has a good heart but a bad memory,\n",
            "and forgets his father's and his mother's admonitions. He so often gets\n",
            "into trouble and meets with adventures, as you shall hear, but first of\n",
            "all I must tell you how brave he was and how he hunted wolves.\n",
            "\n",
            "Once in the spring, a little before Midsummer, Walter heard that there\n",
            "were a great many wolves in the wood, and that pleased him. He was\n",
            "wonderfully brave when he was in the midst of his companions or at home\n",
            "with his brothers and sister, then he used often to say 'One wolf is\n",
            "nothing, there ought to be at least four.'\n",
            "\n",
            "When he wrestled with Klas Bogenstrom or Frithiof Waderfelt and struck\n",
            "them in the back, he would say 'That is what I shall do to a wolf!' When he shot arrows at Jonas and they rattled against his sheepskin coat\n",
            "he would say: 'That is how I should shoot you if you were a wolf!'\n",
            "\n",
            "... (10 more sections)\n",
            "\n",
            "Retrieved 3 morals\n",
            "Sample moral: Be brave when you feel scared.\n",
            "\n",
            "--- Testing theme: adventure ---\n",
            "Getting story materials for theme: adventure, age: 7, length: 5min\n",
            "Retrieved 3 story references\n",
            "\n",
            "Story 1: 'the-magic-bundle'\n",
            "\n",
            "Section 1:\n",
            "A poor man, called Iena, or the Wanderer, was in the habit of roaming\n",
            "about from place to place, forlorn, without relations, and almost\n",
            "helpless. He had often wished for a companion to share his solitude; but\n",
            "who would think of joining their fortunes with those of a poor wanderer,\n",
            "who had no shelter but such as his leather hunting-shirt provided, and\n",
            "no other household in the world than the bundle which he carried in his\n",
            "hand, and in which his hunting-shirt was laid away?\n",
            "\n",
            "One day as he went on a hunting excursion, to relieve himself of the\n",
            "burden of carrying it, Iena hung up his bundle on the branch of a tree,\n",
            "and then set out in quest of game.\n",
            "\n",
            "On returning to the spot in the evening, he was surprised to find a\n",
            "small but neat lodge built in the place where he had left his bundle;\n",
            "and on looking in he beheld a beautiful female, sitting on the further\n",
            "side of the lodge, with his bundle lying beside her.\n",
            "\n",
            "Section 2:\n",
            "During the day Iena had so far prospered in his sport as to kill a deer,\n",
            "which he now cast down at the lodge door.\n",
            "\n",
            "Without pausing to take the least notice, or to give a word of welcome\n",
            "to the hunter, the woman ran out and began to see whether it was a large\n",
            "deer that he had brought. In her haste she stumbled and fell at the\n",
            "threshold.\n",
            "\n",
            "Iena looked at her with astonishment, and thought to himself, \"I\n",
            "supposed I was blessed, but I find my mistake. Night-Hawk,\" said he,\n",
            "speaking aloud, \"I will leave my game with you that you may feast on\n",
            "it.\"\n",
            "\n",
            "He then took up his bundle and departed. After walking some time he came\n",
            "to another tree, on which he suspended his bundle as before, and went in\n",
            "search of game.\n",
            "\n",
            "... (2 more sections)\n",
            "\n",
            "Story 2: 'the-raspberry-worm'\n",
            "\n",
            "Section 1:\n",
            "'Phew!' cried Lisa.\n",
            "\n",
            "'Ugh!' cried Aina.\n",
            "\n",
            "'What now?' cried the big sister.\n",
            "\n",
            "'A worm!' cried Lisa.\n",
            "\n",
            "'On the raspberry!' cried Aina.\n",
            "\n",
            "'Kill it!' cried Otto.\n",
            "\n",
            "'What a fuss over a poor little worm!' said the big sister scornfully.\n",
            "\n",
            "'Yes, when we had cleaned the raspberries so carefully,' said Lisa.\n",
            "\n",
            "'It crept out from that very large one,' put in Aina.\n",
            "\n",
            "'And supposing someone had eaten the raspberry,' said Lisa.\n",
            "\n",
            "Section 2:\n",
            "'Then they would have eaten the worm, too,' said Aina.\n",
            "\n",
            "'Well, what harm?' said Otto.\n",
            "\n",
            "'Eat a worm!' cried Lisa.\n",
            "\n",
            "'And kill him with one bite!' murmured Aina.\n",
            "\n",
            "'Just think of it!' said Otto laughing.\n",
            "\n",
            "'Now it is crawling on the table,' cried Aina again.\n",
            "\n",
            "'Blow it away!' said the big sister.\n",
            "\n",
            "'Tramp on it!' laughed Otto.\n",
            "\n",
            "... (16 more sections)\n",
            "\n",
            "Story 3: 'princess-bella-flor'\n",
            "\n",
            "Section 1:\n",
            "Once upon a time there lived a man who had two sons. When they grew up the elder went to seek his fortune in a far country, and for many years no one heard anything about him. Meanwhile the younger son stayed at home with his father, who died at last in a good old age, leaving great riches behind him.\n",
            "\n",
            "For some time the son who stayed at home spent his father's wealth freely, believing that he alone remained to enjoy it. But, one day, as he was coming down stairs, he was surprised to see a stranger enter the hall, looking about as if the house belonged to him.\n",
            "\n",
            "Section 2:\n",
            "'Have you forgotten me?' asked the man.\n",
            "\n",
            "'I can't forget a person I have never known,' was the rude answer.\n",
            "\n",
            "'I am your brother,' replied the stranger, 'and I have returned home without the money I hoped to have made. And, what is worse, they tell me in the village that my father is dead. I would have counted my lost gold as nothing if I could have seen him once more.'\n",
            "\n",
            "'He died six months ago,' said the rich brother, 'and he left you, as your portion, the old wooden chest that stands in the loft. You had better go there and look for it; I have no more time to waste.' And he went his way.\n",
            "\n",
            "... (15 more sections)\n",
            "\n",
            "Retrieved 3 morals\n",
            "Sample moral: Learning is a lifelong adventure.\n",
            "\n",
            "--- Testing age filtering ---\n",
            "Age 5: The magnificent dragon soared through the tumultuous atmosphere, displaying extraordinary aeronautical capabilities.\n",
            "Age 7: The magnificent dragon soared through the tumultuous atmosphere, displaying extraordinary aeronautical capabilities.\n",
            "Age 9: The magnificent dragon soared through the tumultuous atmosphere, displaying extraordinary aeronautical capabilities.\n",
            "\n",
            "StoryRAG test complete!\n"
          ]
        }
      ],
      "source": [
        "def test_story_rag():\n",
        "    \"\"\"Test the StoryRAG system with sample inputs\"\"\"\n",
        "    print(\"\\n=== Testing StoryRAG System ===\")\n",
        "\n",
        "    # Test with different themes\n",
        "    themes = [\"friendship\", \"courage\", \"adventure\"]\n",
        "\n",
        "    for theme in themes:\n",
        "        print(f\"\\n--- Testing theme: {theme} ---\")\n",
        "\n",
        "        # Get story materials\n",
        "        materials = rag.get_story_materials(theme, age=7, length=\"5min\")\n",
        "\n",
        "        # Print retrieved stories\n",
        "        print(f\"Retrieved {len(materials['story_references'])} story references\")\n",
        "\n",
        "        # Print the first two sections of each story\n",
        "        for i, story in enumerate(materials['story_references']):\n",
        "            print(f\"\\nStory {i+1}: '{story['story_name']}'\")\n",
        "            sections = story['sections']\n",
        "\n",
        "            # Print first two sections or all if less than two\n",
        "            for j, section in enumerate(sections[:2]):\n",
        "                print(f\"\\nSection {j+1}:\")\n",
        "                print(section)\n",
        "\n",
        "            # If there are more sections, indicate this\n",
        "            if len(sections) > 2:\n",
        "                print(f\"\\n... ({len(sections) - 2} more sections)\")\n",
        "\n",
        "        # Print retrieved morals\n",
        "        print(f\"\\nRetrieved {len(materials['morals'])} morals\")\n",
        "        if materials['morals']:\n",
        "            print(f\"Sample moral: {materials['morals'][0]['moral']}\")\n",
        "\n",
        "    # Test age-appropriate filtering\n",
        "    print(\"\\n--- Testing age filtering ---\")\n",
        "    test_text = \"The magnificent dragon soared through the tumultuous atmosphere, displaying extraordinary aeronautical capabilities.\"\n",
        "\n",
        "    for age in [5, 7, 9]:\n",
        "        filtered = rag.filter_age_appropriate(test_text, age)\n",
        "        print(f\"Age {age}: {filtered}\")\n",
        "\n",
        "    print(\"\\nStoryRAG test complete!\")\n",
        "\n",
        "# Run the test\n",
        "test_story_rag()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Fj3dJZuFtcNG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de636a4-aa65-4a91-d6ba-c5ecd7f5919e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.22.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "M1DZiFjOiNhS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "382d4291-f227-424f-8d23-befbc6c2b02a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Luna and Maxs Big Share-a-Thon\n",
            "\n",
            "Segment 1:\n",
            "\"Luna the rabbit loved playing in the warm, sunny meadow near her home. She would hop and spin, her little pink nose twitching with joy. Her best friend Max the squirrel would often join her, his bushy tail wagging excitedly as he chattered happily. Together, they'd laugh and play until the sun began to set, casting a golden glow over the sparkling stream that flowed gently through the forest.\"\n",
            "\n",
            "Segment 2:\n",
            "One day, while Max was busy collecting more acorns, Luna snuck into his special treasure box and grabbed a handful of his shiny acorns. She thought it would be fun to add them to her own collection, but she didn't ask Max first. When Max came back and saw that his favorite acorns were gone, his eyes grew wide with sadness and anger. \"Those were my special acorns!\" Max shouted, his voice trembling with upset.\n",
            "\n",
            "Segment 3:\n",
            "Max was about to tell Luna how much he missed his special acorns. But then a sneaky raccoon named Rocky snuck into the forest. Rocky loved shiny things and stole all of Max's acorns, hiding them in his secret den deep in the trees. Luna saw Rocky running away with the acorns and knew she had to act fast! With a brave \"Hop to it!\" she chased after Rocky, determined to help Max get his favorite acorns back.\n",
            "\n",
            "Segment 4:\n",
            "Luna chased after Rocky until they reached his secret den, hidden behind a waterfall. Luna was so fast that she caught up to Rocky and shouted, \"Give back Max's acorns!\" Rocky was surprised and returned all of Max's shiny acorns. When Luna and Max were reunited with the acorns, they hugged each other tightly, and Max's sad face turned into a big smile. They decided to build an even bigger acorn collection together, where they would both be in charge of finding and adding new, shiny treasures. With every acorn that sparkled in the sunlight, their friendship grew stronger, and they knew that sharing and helping each other was the best treasure of all.\n",
            "\n",
            "Segment 5:\n",
            "\"As the sun shone brightly in the forest, the creatures gathered around Luna and Max, their faces beaming with joy. \"Hooray for friendship!\" they cheered, waving their paws and leaves in the air. Together, they built a beautiful acorn-shaped stage, and Luna and Max sat on top, surrounded by their sparkling treasures. The forest creatures danced and sang, their voices sounding happy together, celebrating the special friendship between Luna and Max, and the magic of sharing and being kind.\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Story Generation Module\n",
        "----------------------\n",
        "This module generates structured, age-appropriate children's stories using the Groq API\n",
        "with the Mixtral model. It leverages the processed datasets:\n",
        "- age_vocabulary.pkl / word_to_age.pkl: For vocabulary age-appropriateness\n",
        "- fairytale_stories.csv: For inspiration and structural patterns\n",
        "- stories.index: For semantic similarity lookup when needed\n",
        "\n",
        "Dependencies:\n",
        "- groq\n",
        "- numpy\n",
        "- typing\n",
        "- pickle\n",
        "- pandas\n",
        "- faiss\n",
        "\"\"\"\n",
        "\n",
        "import groq\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import faiss\n",
        "from typing import List, Dict, Optional, Tuple, Any\n",
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "class StoryGenerator:\n",
        "    \"\"\"\n",
        "    Generates age-appropriate, structured children's stories using the Groq API with LLaMA models.\n",
        "\n",
        "    Attributes:\n",
        "        groq_client: Initialized Groq client for API calls\n",
        "        word_to_age: Dictionary mapping words to age of acquisition scores\n",
        "        fairytale_df: DataFrame containing processed fairytale stories\n",
        "        stories_index: FAISS index for story similarity search (optional)\n",
        "        model_name: The Groq model to use for generation (default: llama-3.1-8b-instant)\n",
        "        max_tokens: Maximum tokens to generate per API call\n",
        "        temperature: Temperature for generation (controls creativity)\n",
        "        data_dir: Directory containing processed data files\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        api_key: str=\"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\",\n",
        "        data_dir: str = \"data/processed\",\n",
        "        model_name: str = \"llama-3.1-8b-instant\",  # Using LLaMA 3.1 8B Instant from list\n",
        "        max_tokens: int = 1024,\n",
        "        temperature: float = 0.7,\n",
        "        use_stories_index: bool = False\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize the StoryGenerator with Groq API access and configuration.\n",
        "\n",
        "        Args:\n",
        "            api_key: Groq API key\n",
        "            data_dir: Directory containing processed data files (default: \"data/processed\")\n",
        "            model_name: Groq model to use (default: llama-3.1-8b-instant)\n",
        "            max_tokens: Maximum tokens for generation (default: 1024)\n",
        "            temperature: Controls randomness in generation (default: 0.7)\n",
        "            use_stories_index: Whether to load the FAISS stories index (default: False)\n",
        "        \"\"\"\n",
        "        self.groq_client = groq.Client(api_key=api_key)\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.model_name = model_name\n",
        "        self.max_tokens = max_tokens\n",
        "        self.temperature = temperature\n",
        "\n",
        "        # Load Age of Acquisition vocabulary\n",
        "        try:\n",
        "            with open(self.data_dir / \"word_to_age.pkl\", \"rb\") as f:\n",
        "                self.word_to_age = pickle.load(f)\n",
        "        except FileNotFoundError:\n",
        "            try:\n",
        "                with open(self.data_dir / \"age_vocabulary.pkl\", \"rb\") as f:\n",
        "                    self.word_to_age = pickle.load(f)\n",
        "            except FileNotFoundError:\n",
        "                raise FileNotFoundError(\"Could not find Age of Acquisition vocabulary files.\")\n",
        "\n",
        "        # Load FairytaleQA dataset\n",
        "        try:\n",
        "            self.fairytale_df = pd.read_csv(self.data_dir / \"fairytale_stories.csv\")\n",
        "        except FileNotFoundError:\n",
        "            print(\"Warning: fairytale_stories.csv not found. Some functionality may be limited.\")\n",
        "            self.fairytale_df = None\n",
        "\n",
        "        # Optionally load stories index for semantic search\n",
        "        self.stories_index = None\n",
        "        if use_stories_index:\n",
        "            try:\n",
        "                self.stories_index = faiss.read_index(str(self.data_dir / \"stories.index\"))\n",
        "                print(\"Successfully loaded stories.index\")\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not load stories.index: {e}\")\n",
        "                print(\"Story similarity functionality will be disabled.\")\n",
        "\n",
        "    def generate_story(\n",
        "        self,\n",
        "        age: int,\n",
        "        theme: str,\n",
        "        length: str = \"medium\",\n",
        "        characters: Optional[List[str]] = None,\n",
        "        additional_context: Optional[str] = None\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Generate a complete, segmented children's story based on specified parameters.\n",
        "\n",
        "        Args:\n",
        "            age: Target audience age (used for vocabulary filtering)\n",
        "            theme: Main theme or topic of the story\n",
        "            length: Story length - \"short\", \"medium\", or \"long\"\n",
        "            characters: Optional list of character names to include\n",
        "            additional_context: Optional additional story context or requirements\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing:\n",
        "                - title: Story title\n",
        "                - segments: List of story segments (3-5 sentences each)\n",
        "                - metadata: Generation metadata\n",
        "        \"\"\"\n",
        "        # Configure story length parameters\n",
        "        segment_count = self._determine_segment_count(length)\n",
        "\n",
        "        # Generate story structure\n",
        "        story_structure = self._generate_story_structure(theme, age, characters, segment_count)\n",
        "\n",
        "        # Generate story title\n",
        "        title = self._generate_title(theme, characters)\n",
        "\n",
        "        # Generate segments based on structure\n",
        "        segments = self._generate_segments(story_structure, age)\n",
        "\n",
        "        # Filter vocabulary for age appropriateness\n",
        "        filtered_segments = [\n",
        "            self._filter_vocabulary_by_age(segment, age)\n",
        "            for segment in segments\n",
        "        ]\n",
        "\n",
        "        return {\n",
        "            \"title\": title,\n",
        "            \"segments\": filtered_segments,\n",
        "            \"metadata\": {\n",
        "                \"age\": age,\n",
        "                \"theme\": theme,\n",
        "                \"length\": length,\n",
        "                \"characters\": characters or [],\n",
        "                \"segments_count\": len(filtered_segments)\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _determine_segment_count(self, length: str) -> int:\n",
        "        \"\"\"\n",
        "        Determine number of story segments based on requested length.\n",
        "\n",
        "        Args:\n",
        "            length: \"short\", \"medium\", or \"long\"\n",
        "\n",
        "        Returns:\n",
        "            Number of segments to generate\n",
        "        \"\"\"\n",
        "        length_mapping = {\n",
        "            \"short\": (3, 5),\n",
        "            \"medium\": (5, 8),\n",
        "            \"long\": (8, 12)\n",
        "        }\n",
        "\n",
        "        min_segments, max_segments = length_mapping.get(length.lower(), (5, 8))\n",
        "        return np.random.randint(min_segments, max_segments + 1)\n",
        "\n",
        "    def _get_inspirational_fairytale_segments(self, theme: str, count: int = 3) -> List[str]:\n",
        "        \"\"\"\n",
        "        Retrieve relevant fairytale segments from the FairytaleQA dataset to use as inspiration.\n",
        "\n",
        "        Args:\n",
        "            theme: Theme to find relevant segments for\n",
        "            count: Number of segments to retrieve\n",
        "\n",
        "        Returns:\n",
        "            List of relevant fairytale segments\n",
        "        \"\"\"\n",
        "        if self.fairytale_df is None:\n",
        "            return []\n",
        "\n",
        "        # Simple keyword-based search in the fairytale dataset\n",
        "        # In a production system, would use embedding similarity\n",
        "        theme_keywords = theme.lower().split()\n",
        "        matches = []\n",
        "\n",
        "        for _, row in self.fairytale_df.iterrows():\n",
        "            # This assumes fairytale_df has 'text' column - adjust field name if different\n",
        "            if 'text' in self.fairytale_df.columns:\n",
        "                text = str(row['text']).lower()\n",
        "                if any(keyword in text for keyword in theme_keywords):\n",
        "                    matches.append(row['text'])\n",
        "                    if len(matches) >= count:\n",
        "                        break\n",
        "\n",
        "        return matches[:count]\n",
        "\n",
        "    def _generate_story_structure(\n",
        "        self,\n",
        "        theme: str,\n",
        "        age: int,\n",
        "        characters: Optional[List[str]] = None,\n",
        "        segment_count: int = 6\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Generate the high-level structure of the story with Mixtral, using FairytaleQA\n",
        "        dataset as inspiration.\n",
        "\n",
        "        Args:\n",
        "            theme: Main story theme\n",
        "            age: Target audience age\n",
        "            characters: Optional list of character names\n",
        "            segment_count: Number of segments to generate\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with story structure elements\n",
        "        \"\"\"\n",
        "        characters_text = \", \".join(characters) if characters else \"appropriate characters\"\n",
        "\n",
        "        # Create narrative arc prompt based on segment count\n",
        "        intro_segments = max(1, segment_count // 6)\n",
        "        buildup_segments = max(1, segment_count // 3)\n",
        "        climax_segments = max(1, segment_count // 3)\n",
        "        resolution_segments = segment_count - (intro_segments + buildup_segments + climax_segments)\n",
        "\n",
        "        # Get inspirational fairytale segments\n",
        "        inspiration_segments = self._get_inspirational_fairytale_segments(theme)\n",
        "        inspiration_text = \"\"\n",
        "        if inspiration_segments:\n",
        "            inspiration_text = \"Here are some examples from classic fairytales for inspiration:\\n\"\n",
        "            for i, segment in enumerate(inspiration_segments, 1):\n",
        "                inspiration_text += f\"Example {i}: {segment}\\n\\n\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        You are an expert children's storyteller. Create a detailed story structure for a {age}-year-old child\n",
        "        about the theme: \"{theme}\". The story will feature {characters_text}.\n",
        "\n",
        "        {inspiration_text}\n",
        "\n",
        "        Design a structured story outline with {segment_count} segments that follows this classic structure:\n",
        "        - Introduction: {intro_segments} segments to establish setting and characters\n",
        "        - Buildup/Complication: {buildup_segments} segments to develop the conflict\n",
        "        - Climax: {climax_segments} segments for the most exciting part\n",
        "        - Resolution: {resolution_segments} segments to provide a satisfying ending\n",
        "\n",
        "        For each segment, provide:\n",
        "        1. A brief description of what happens (2-3 sentences)\n",
        "        2. Key elements to include\n",
        "        3. The emotional tone\n",
        "\n",
        "        Format your response as a structured JSON without any additional explanation:\n",
        "\n",
        "        {{\n",
        "            \"introduction\": [\n",
        "                {{\n",
        "                    \"description\": \"Brief description of segment 1\",\n",
        "                    \"key_elements\": [\"element1\", \"element2\"],\n",
        "                    \"tone\": \"emotional tone\"\n",
        "                }},\n",
        "                ...\n",
        "            ],\n",
        "            \"buildup\": [...],\n",
        "            \"climax\": [...],\n",
        "            \"resolution\": [...]\n",
        "        }}\n",
        "        \"\"\"\n",
        "\n",
        "        response = self.groq_client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an expert children's storyteller who creates detailed, age-appropriate story structures.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=self.temperature,\n",
        "            max_tokens=self.max_tokens,\n",
        "            response_format={\"type\": \"json_object\"}\n",
        "        )\n",
        "\n",
        "        # Extract and parse the JSON response\n",
        "        try:\n",
        "            structure_text = response.choices[0].message.content\n",
        "            structure = eval(structure_text)  # Convert string to dictionary\n",
        "            return structure\n",
        "        except Exception as e:\n",
        "            # Fallback structure if parsing fails\n",
        "            print(f\"Error parsing story structure: {e}\")\n",
        "            return {\n",
        "                \"introduction\": [{\"description\": f\"A story about {theme}\", \"key_elements\": [theme], \"tone\": \"welcoming\"}],\n",
        "                \"buildup\": [{\"description\": \"The story develops\", \"key_elements\": [\"challenges\"], \"tone\": \"curious\"}],\n",
        "                \"climax\": [{\"description\": \"The main event happens\", \"key_elements\": [\"excitement\"], \"tone\": \"tense\"}],\n",
        "                \"resolution\": [{\"description\": \"Everything works out\", \"key_elements\": [\"lessons\"], \"tone\": \"satisfied\"}]\n",
        "            }\n",
        "\n",
        "    def _generate_title(self, theme: str, characters: Optional[List[str]] = None) -> str:\n",
        "        \"\"\"\n",
        "        Generate a catchy title for the story based on theme and characters.\n",
        "\n",
        "        Args:\n",
        "            theme: Main story theme\n",
        "            characters: Optional list of character names\n",
        "\n",
        "        Returns:\n",
        "            Story title\n",
        "        \"\"\"\n",
        "        character_text = f\" featuring {', '.join(characters)}\" if characters else \"\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Create a short, catchy, child-friendly title for a story about {theme}{character_text}.\n",
        "        The title should be memorable, appropriate for children, and capture the essence of the theme.\n",
        "        Return only the title with no quotation marks or additional text.\n",
        "        \"\"\"\n",
        "\n",
        "        response = self.groq_client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an expert at creating engaging titles for children's stories.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.8,  # Slightly higher temperature for creative titles\n",
        "            max_tokens=30  # Titles are short\n",
        "        )\n",
        "\n",
        "        title = response.choices[0].message.content.strip()\n",
        "        # Remove any quotes that might be in the response\n",
        "        title = title.replace('\"', '').replace(\"'\", \"\")\n",
        "        return title\n",
        "\n",
        "    def _generate_segments(self, story_structure: Dict[str, List[Dict]], age: int) -> List[str]:\n",
        "        \"\"\"\n",
        "        Generate the actual story segments based on the structure, maintaining coherence\n",
        "        between segments by providing context of previously generated content.\n",
        "\n",
        "        Args:\n",
        "            story_structure: The structured outline of the story\n",
        "            age: Target audience age for vocabulary appropriateness\n",
        "\n",
        "        Returns:\n",
        "            List of story segments (3-5 sentences each)\n",
        "        \"\"\"\n",
        "        segments = []\n",
        "\n",
        "        # Combine all structure sections\n",
        "        all_sections = []\n",
        "        for section_name in [\"introduction\", \"buildup\", \"climax\", \"resolution\"]:\n",
        "            all_sections.extend(story_structure.get(section_name, []))\n",
        "\n",
        "        # Generate text for each segment\n",
        "        for i, segment_structure in enumerate(all_sections):\n",
        "            description = segment_structure.get(\"description\", \"\")\n",
        "            key_elements = segment_structure.get(\"key_elements\", [])\n",
        "            tone = segment_structure.get(\"tone\", \"neutral\")\n",
        "\n",
        "            # Include previously generated segments as context\n",
        "            previous_context = \"\"\n",
        "            if segments:\n",
        "                # Include up to 3 previous segments to avoid overwhelming the context\n",
        "                context_segments = segments[-3:] if len(segments) > 3 else segments\n",
        "                previous_context = f\"\"\"\n",
        "                Previously in the story:\n",
        "                {' '.join(context_segments)}\n",
        "\n",
        "                Now, continuing from there, write the next segment where:\n",
        "                \"\"\"\n",
        "            else:\n",
        "                previous_context = \"Write the first segment of the story where:\"\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            You're writing a story segment for {age}-year-old children.\n",
        "\n",
        "            {previous_context}\n",
        "            This segment should cover: \"{description}\"\n",
        "            Key elements to include: {', '.join(key_elements)}\n",
        "            Emotional tone: {tone}\n",
        "\n",
        "            Write this segment in 3-5 simple, engaging sentences that a {age}-year-old would understand and enjoy.\n",
        "            Use simple language, active voice, and vivid imagery.\n",
        "            Focus ONLY on this segment, but ensure it flows smoothly from the previous content.\n",
        "            Make sure this segment connects naturally with what came before it.\n",
        "            Return only the story text with no additional commentary.\n",
        "            \"\"\"\n",
        "\n",
        "            response = self.groq_client.chat.completions.create(\n",
        "                model=self.model_name,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": f\"You're an expert children's author writing a story for {age}-year-olds.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=self.temperature,\n",
        "                max_tokens=200  # Each segment is fairly short\n",
        "            )\n",
        "\n",
        "            segment_text = response.choices[0].message.content.strip()\n",
        "            segments.append(segment_text)\n",
        "\n",
        "        return segments\n",
        "\n",
        "    def _filter_vocabulary_by_age(self, text: str, age: int) -> str:\n",
        "        \"\"\"\n",
        "        Filter and replace advanced vocabulary words with age-appropriate alternatives\n",
        "        using the Age of Acquisition dataset.\n",
        "\n",
        "        Args:\n",
        "            text: Original text to filter\n",
        "            age: Target audience age\n",
        "\n",
        "        Returns:\n",
        "            Age-appropriate text with advanced words replaced\n",
        "        \"\"\"\n",
        "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "        complex_words = []\n",
        "\n",
        "        # Find complex words based on Age of Acquisition\n",
        "        for word in words:\n",
        "            if word in self.word_to_age:\n",
        "                word_age = self.word_to_age[word]\n",
        "                if word_age > age + 1:  # Allow slightly advanced vocabulary\n",
        "                    complex_words.append(word)\n",
        "\n",
        "        # If no complex words, return original text\n",
        "        if not complex_words:\n",
        "            return text\n",
        "\n",
        "        # If complex words found, simplify text\n",
        "        complex_words_str = \", \".join(complex_words)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Rewrite this text to be appropriate for a {age}-year-old child:\n",
        "        \"{text}\"\n",
        "\n",
        "        These words might be too advanced: {complex_words_str}\n",
        "        Replace them with simpler alternatives that maintain the same meaning.\n",
        "        Return only the simplified text, with no additional commentary.\n",
        "        \"\"\"\n",
        "\n",
        "        response = self.groq_client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You simplify text for young children while maintaining meaning.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.3,  # Lower temperature for more reliable simplifications\n",
        "            max_tokens=200\n",
        "        )\n",
        "\n",
        "        simplified_text = response.choices[0].message.content.strip()\n",
        "        return simplified_text\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize the story generator\n",
        "    generator = StoryGenerator(\n",
        "        api_key=os.environ.get(\"GROQ_API_KEY\", \"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\"),\n",
        "        data_dir=\"data/processed\",  # Path to your processed data files\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    # Generate a story\n",
        "    story = generator.generate_story(\n",
        "        age=6,\n",
        "        theme=\"friendship and sharing\",\n",
        "        length=\"short\",\n",
        "        characters=[\"Luna the rabbit\", \"Max the squirrel\"]\n",
        "    )\n",
        "\n",
        "    # Print the generated story\n",
        "    print(f\"Title: {story['title']}\\n\")\n",
        "    for i, segment in enumerate(story['segments']):\n",
        "        print(f\"Segment {i+1}:\")\n",
        "        print(segment)\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9ZbGena9vLJM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afa3cccf-aaca-40fb-fa8f-313bef49fe92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full story so far:\n",
            "Once upon a time, there was a brave little rabbit named Luna who lived at the edge of the Whispering Forest.\n",
            "\n",
            "Luna decided to be brave and explore deeper into the Whispering Forest. She hopped past tall trees and colorful flowers she had never seen before. The forest seemed to come alive around her with strange sounds and movements.\n",
            "\n",
            "Luna decided it was safer to take a different path. She turned away from the mysterious bush and followed a winding dirt trail instead. The trail led her to a small bubbling stream with stepping stones.\n",
            "\n",
            "JSON representation:\n",
            "{\n",
            "  \"nodes\": {\n",
            "    \"a8fb11bf-b4a5-4c04-85ed-d07c961440f0\": {\n",
            "      \"node_id\": \"a8fb11bf-b4a5-4c04-85ed-d07c961440f0\",\n",
            "      \"segment\": \"Once upon a time, there was a brave little rabbit named Luna who lived at the edge of the Whispering Forest.\",\n",
            "      \"decisions\": {\n",
            "        \"decision_prompt\": \"What should Luna do on this bright morning?\",\n",
            "        \"options\": [\n",
            "          {\n",
            "            \"choice_text\": \"Explore deeper into the forest\",\n",
            "            \"consequence_summary\": \"Luna might discover something amazing but could face dangers.\"\n",
            "          },\n",
            "          {\n",
            "            \"choice_text\": \"Visit her friend in the meadow\",\n",
            "            \"consequence_summary\": \"Luna will have a safer day but might miss an adventure.\"\n",
            "          }\n",
            "        ]\n",
            "      },\n",
            "      \"parent_id\": null,\n",
            "      \"children\": {\n",
            "        \"0\": \"bba4c726-d789-47d8-954a-d6e15b7737e9\"\n",
            "      },\n",
            "      \"metadata\": {}\n",
            "    },\n",
            "    \"bba4c726-d789-47d8-954a-d6e15b7737e9\": {\n",
            "      \"node_id\": \"bba4c726-d789-47d8-954a-d6e15b7737e9\",\n",
            "      \"segment\": \"Luna decided to be brave and explore deeper into the Whispering Forest. She hopped past tall trees and colorful flowers she had never seen before. The forest seemed to come alive around her with strange sounds and movements.\",\n",
            "      \"decisions\": {\n",
            "        \"decision_prompt\": \"Luna hears a strange noise coming from behind a large bush. What should she do?\",\n",
            "        \"options\": [\n",
            "          {\n",
            "            \"choice_text\": \"Investigate the noise\",\n",
            "            \"consequence_summary\": \"Luna might discover something interesting or dangerous.\"\n",
            "          },\n",
            "          {\n",
            "            \"choice_text\": \"Take a different path\",\n",
            "            \"consequence_summary\": \"Luna will avoid potential danger but miss a discovery.\"\n",
            "          }\n",
            "        ]\n",
            "      },\n",
            "      \"parent_id\": \"a8fb11bf-b4a5-4c04-85ed-d07c961440f0\",\n",
            "      \"children\": {\n",
            "        \"1\": \"eeb0a264-c8a0-47c6-b5d1-fec9b3c84e1f\"\n",
            "      },\n",
            "      \"metadata\": {}\n",
            "    },\n",
            "    \"eeb0a264-c8a0-47c6-b5d1-fec9b3c84e1f\": {\n",
            "      \"node_id\": \"eeb0a264-c8a0-47c6-b5d1-fec9b3c84e1f\",\n",
            "      \"segment\": \"Luna decided it was safer to take a different path. She turned away from the mysterious bush and followed a winding dirt trail instead. The trail led her to a small bubbling stream with stepping stones.\",\n",
            "      \"decisions\": null,\n",
            "      \"parent_id\": \"bba4c726-d789-47d8-954a-d6e15b7737e9\",\n",
            "      \"children\": {},\n",
            "      \"metadata\": {}\n",
            "    }\n",
            "  },\n",
            "  \"root_node_id\": \"a8fb11bf-b4a5-4c04-85ed-d07c961440f0\",\n",
            "  \"current_node_id\": \"eeb0a264-c8a0-47c6-b5d1-fec9b3c84e1f\",\n",
            "  \"path_history\": [\n",
            "    \"a8fb11bf-b4a5-4c04-85ed-d07c961440f0\",\n",
            "    \"bba4c726-d789-47d8-954a-d6e15b7737e9\",\n",
            "    \"eeb0a264-c8a0-47c6-b5d1-fec9b3c84e1f\"\n",
            "  ],\n",
            "  \"choice_history\": [\n",
            "    {\n",
            "      \"from_node\": \"a8fb11bf-b4a5-4c04-85ed-d07c961440f0\",\n",
            "      \"choice_index\": 0,\n",
            "      \"to_node\": \"bba4c726-d789-47d8-954a-d6e15b7737e9\"\n",
            "    },\n",
            "    {\n",
            "      \"from_node\": \"bba4c726-d789-47d8-954a-d6e15b7737e9\",\n",
            "      \"choice_index\": 1,\n",
            "      \"to_node\": \"eeb0a264-c8a0-47c6-b5d1-fec9b3c84e1f\"\n",
            "    }\n",
            "  ],\n",
            "  \"story_metadata\": {\n",
            "    \"title\": \"Luna's Forest Adventure\",\n",
            "    \"protagonist\": \"Luna\",\n",
            "    \"theme\": \"bravery\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Verifying loaded story:\n",
            "Root node ID matches: True\n",
            "Current node ID matches: True\n",
            "Number of nodes matches: True\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Branching Logic Engine\n",
        "---------------------\n",
        "This module tracks story evolution based on user choices, implementing a tree/graph\n",
        "structure to represent the branching narrative. It handles dynamic updates as the\n",
        "user progresses through the story and maintains the history of choices.\n",
        "\n",
        "Dependencies:\n",
        "- typing\n",
        "- json\n",
        "- uuid\n",
        "\"\"\"\n",
        "\n",
        "from typing import Dict, List, Optional, Any, Set, Tuple\n",
        "import json\n",
        "import uuid\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "class StoryNode:\n",
        "    \"\"\"\n",
        "    Represents a single node in the story graph, containing a segment of the story\n",
        "    and potential decision points.\n",
        "\n",
        "    Attributes:\n",
        "        node_id: Unique identifier for the node\n",
        "        segment: Text content of this story segment\n",
        "        decisions: Decision point information if this node has choices\n",
        "        parent_id: ID of the parent node\n",
        "        children: Dictionary mapping choice indices to child node IDs\n",
        "        metadata: Additional information about this node\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        segment: str,\n",
        "        node_id: Optional[str] = None,\n",
        "        parent_id: Optional[str] = None,\n",
        "        decisions: Optional[Dict[str, Any]] = None,\n",
        "        metadata: Optional[Dict[str, Any]] = None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize a story node.\n",
        "\n",
        "        Args:\n",
        "            segment: Text content of this story segment\n",
        "            node_id: Unique identifier (generated if not provided)\n",
        "            parent_id: ID of the parent node (None for root)\n",
        "            decisions: Decision point information if this node has choices\n",
        "            metadata: Additional information about this node\n",
        "        \"\"\"\n",
        "        self.node_id = node_id if node_id else str(uuid.uuid4())\n",
        "        self.segment = segment\n",
        "        self.decisions = decisions\n",
        "        self.parent_id = parent_id\n",
        "        self.children = {}  # Maps choice indices to child node IDs\n",
        "        self.metadata = metadata if metadata else {}\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Convert the node to a dictionary representation.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary representation of the node\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"node_id\": self.node_id,\n",
        "            \"segment\": self.segment,\n",
        "            \"decisions\": self.decisions,\n",
        "            \"parent_id\": self.parent_id,\n",
        "            \"children\": self.children,\n",
        "            \"metadata\": self.metadata\n",
        "        }\n",
        "\n",
        "    @classmethod\n",
        "    def from_dict(cls, data: Dict[str, Any]) -> 'StoryNode':\n",
        "        \"\"\"\n",
        "        Create a StoryNode from a dictionary representation.\n",
        "\n",
        "        Args:\n",
        "            data: Dictionary containing node data\n",
        "\n",
        "        Returns:\n",
        "            StoryNode instance\n",
        "        \"\"\"\n",
        "        node = cls(\n",
        "            segment=data[\"segment\"],\n",
        "            node_id=data[\"node_id\"],\n",
        "            parent_id=data[\"parent_id\"],\n",
        "            decisions=data.get(\"decisions\"),\n",
        "            metadata=data.get(\"metadata\", {})\n",
        "        )\n",
        "        node.children = data.get(\"children\", {})\n",
        "        return node\n",
        "\n",
        "    def add_child(self, choice_index: int, child_id: str) -> None:\n",
        "        \"\"\"\n",
        "        Add a child node for a specific choice.\n",
        "\n",
        "        Args:\n",
        "            choice_index: Index of the choice that leads to this child\n",
        "            child_id: ID of the child node\n",
        "        \"\"\"\n",
        "        self.children[str(choice_index)] = child_id\n",
        "\n",
        "    def has_decisions(self) -> bool:\n",
        "        \"\"\"\n",
        "        Check if this node has decisions/choices.\n",
        "\n",
        "        Returns:\n",
        "            Boolean indicating if node has decisions\n",
        "        \"\"\"\n",
        "        return self.decisions is not None and len(self.decisions) > 0\n",
        "\n",
        "\n",
        "class BranchingLogicEngine:\n",
        "    \"\"\"\n",
        "    Manages the branching narrative structure, tracking story evolution based on user choices.\n",
        "\n",
        "    Attributes:\n",
        "        nodes: Dictionary mapping node IDs to StoryNode objects\n",
        "        current_node_id: ID of the current active node\n",
        "        root_node_id: ID of the root/starting node\n",
        "        story_metadata: Metadata about the overall story\n",
        "        path_history: Ordered list of node IDs in the current path\n",
        "        choice_history: List of choices made by the user\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        initial_segment: Optional[str] = None,\n",
        "        story_metadata: Optional[Dict[str, Any]] = None,\n",
        "        api_key: Optional[str] = \"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\" # api_key for summarization\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize the branching logic engine.\n",
        "\n",
        "        Args:\n",
        "            initial_segment: Text of the first story segment (optional)\n",
        "            story_metadata: Metadata about the overall story (optional)\n",
        "        \"\"\"\n",
        "        self.nodes = {}\n",
        "        self.current_node_id = None\n",
        "        self.root_node_id = None\n",
        "        self.story_metadata = story_metadata if story_metadata else {}\n",
        "        self.path_history = []\n",
        "        self.choice_history = []\n",
        "        self.api_key = api_key or os.environ.get(\"GROQ_API_KEY\")\n",
        "        self.groq_client = groq.Client(api_key=self.api_key) if self.api_key else None\n",
        "        self.summarization_model = \"llama-3.1-8b-instant\" # Or choose another model\n",
        "        self.max_context_length_words = 400 # Example threshold before summarizing\n",
        "        self.summary_cache = {} # Cache summaries to avoid repeated API calls\n",
        "\n",
        "        # Create initial node if provided\n",
        "        if initial_segment:\n",
        "            self.initialize_story(initial_segment)\n",
        "\n",
        "    def initialize_story(self, initial_segment: str, metadata: Optional[Dict[str, Any]] = None) -> str:\n",
        "        \"\"\"\n",
        "        Initialize the story with the first segment.\n",
        "\n",
        "        Args:\n",
        "            initial_segment: Text of the first story segment\n",
        "            metadata: Metadata for the root node\n",
        "\n",
        "        Returns:\n",
        "            ID of the created root node\n",
        "        \"\"\"\n",
        "        # Create root node\n",
        "        root_node = StoryNode(\n",
        "            segment=initial_segment,\n",
        "            metadata=metadata\n",
        "        )\n",
        "\n",
        "        # Store node\n",
        "        self.nodes[root_node.node_id] = root_node\n",
        "        self.root_node_id = root_node.node_id\n",
        "        self.current_node_id = root_node.node_id\n",
        "        self.path_history = [root_node.node_id]\n",
        "\n",
        "        return root_node.node_id\n",
        "\n",
        "    def add_decision_point(\n",
        "        self,\n",
        "        node_id: str,\n",
        "        decision_data: Dict[str, Any]\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Add a decision point to an existing node.\n",
        "\n",
        "        Args:\n",
        "            node_id: ID of the node to add decisions to\n",
        "            decision_data: Decision point data (prompt and options)\n",
        "        \"\"\"\n",
        "        if node_id not in self.nodes:\n",
        "            raise ValueError(f\"Node with ID {node_id} not found\")\n",
        "\n",
        "        self.nodes[node_id].decisions = decision_data\n",
        "\n",
        "    def add_decision_to_current_node(self, decision_data: Dict[str, Any]) -> None:\n",
        "        \"\"\"\n",
        "        Add a decision point to the current node.\n",
        "\n",
        "        Args:\n",
        "            decision_data: Decision point data (prompt and options)\n",
        "        \"\"\"\n",
        "        if not self.current_node_id:\n",
        "            raise ValueError(\"No current node exists\")\n",
        "\n",
        "        self.add_decision_point(self.current_node_id, decision_data)\n",
        "\n",
        "    def add_story_continuation(\n",
        "        self,\n",
        "        choice_index: int,\n",
        "        continuation_text: str,\n",
        "        metadata: Optional[Dict[str, Any]] = None,\n",
        "        log_choice: bool = True\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Add a continuation to the story based on a selected choice.\n",
        "\n",
        "        Args:\n",
        "            choice_index: Index of the selected choice (0 or 1)\n",
        "            continuation_text: Text for the next story segment\n",
        "            metadata: Metadata for the new node\n",
        "\n",
        "        Returns:\n",
        "            ID of the newly created node\n",
        "        \"\"\"\n",
        "        if not self.current_node_id:\n",
        "            raise ValueError(\"No current node exists\")\n",
        "\n",
        "        current_node = self.nodes[self.current_node_id]\n",
        "\n",
        "        # Create new node for continuation\n",
        "        new_node = StoryNode(\n",
        "            segment=continuation_text,\n",
        "            parent_id=self.current_node_id,\n",
        "            metadata=metadata\n",
        "        )\n",
        "\n",
        "        # Store the new node\n",
        "        self.nodes[new_node.node_id] = new_node\n",
        "\n",
        "        # Link current node to new node through the choice\n",
        "        current_node.add_child(choice_index, new_node.node_id)\n",
        "\n",
        "        # Update current node and path history\n",
        "        self.current_node_id = new_node.node_id\n",
        "        self.path_history.append(new_node.node_id)\n",
        "        if log_choice:\n",
        "          self.choice_history.append({\n",
        "              \"from_node\": current_node.node_id,\n",
        "              \"choice_index\": choice_index,\n",
        "              \"to_node\": new_node.node_id\n",
        "          })\n",
        "\n",
        "        return new_node.node_id\n",
        "\n",
        "    def get_current_node(self) -> StoryNode:\n",
        "        \"\"\"\n",
        "        Get the current active node.\n",
        "\n",
        "        Returns:\n",
        "            Current StoryNode\n",
        "        \"\"\"\n",
        "        if not self.current_node_id or self.current_node_id not in self.nodes:\n",
        "            raise ValueError(\"Current node is not valid\")\n",
        "\n",
        "        return self.nodes[self.current_node_id]\n",
        "\n",
        "    def get_current_segment(self) -> str:\n",
        "        \"\"\"\n",
        "        Get the text of the current story segment.\n",
        "\n",
        "        Returns:\n",
        "            Text of the current segment\n",
        "        \"\"\"\n",
        "        return self.get_current_node().segment\n",
        "\n",
        "    def get_current_decisions(self) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Get the decision point at the current node, if any.\n",
        "\n",
        "        Returns:\n",
        "            Decision data or None if no decisions exist\n",
        "        \"\"\"\n",
        "        return self.get_current_node().decisions\n",
        "\n",
        "    def get_path_to_current_node(self) -> List[StoryNode]:\n",
        "        \"\"\"\n",
        "        Get the list of nodes from root to current node.\n",
        "\n",
        "        Returns:\n",
        "            List of StoryNode objects in path order\n",
        "        \"\"\"\n",
        "        return [self.nodes[node_id] for node_id in self.path_history]\n",
        "\n",
        "    def get_full_story_text(self) -> str:\n",
        "        \"\"\"\n",
        "        Get the full text of the story along the current path.\n",
        "\n",
        "        Returns:\n",
        "            Combined text of all segments in the current path\n",
        "        \"\"\"\n",
        "        path_nodes = self.get_path_to_current_node()\n",
        "        return \"\\n\\n\".join([node.segment for node in path_nodes])\n",
        "    def get_story_context_for_llm(self) -> str:\n",
        "        \"\"\"\n",
        "        Gets the story context, summarizing if it exceeds the threshold.\n",
        "        \"\"\"\n",
        "        full_text = self.get_full_story_text()\n",
        "        word_count = len(full_text.split())\n",
        "\n",
        "        # Use cache key based on the current node ID (representing story state)\n",
        "        cache_key = self.current_node_id\n",
        "\n",
        "        if word_count <= self.max_context_length_words:\n",
        "            return full_text # Return full text if short enough\n",
        "        elif cache_key in self.summary_cache:\n",
        "             return self.summary_cache[cache_key] # Return cached summary\n",
        "        elif not self.groq_client:\n",
        "             print(\"Warning: No Groq client available for summarization. Returning full text.\")\n",
        "             return full_text # Fallback if no client\n",
        "        else:\n",
        "            # Generate summary\n",
        "            print(f\"Context length ({word_count} words) exceeds threshold ({self.max_context_length_words}). Summarizing...\")\n",
        "            prompt = f\"\"\"\n",
        "            Summarize the following children's story progress concisely, capturing the key plot points, character actions, and the current situation. Keep the summary under 300 words.\n",
        "\n",
        "            STORY SO FAR:\n",
        "            {full_text}\n",
        "\n",
        "            CONCISE SUMMARY:\n",
        "            \"\"\"\n",
        "            try:\n",
        "                response = self.groq_client.chat.completions.create(\n",
        "                    model=self.summarization_model,\n",
        "                    messages=[\n",
        "                        {\"role\": \"system\", \"content\": \"You are an expert at summarizing children's stories.\"},\n",
        "                        {\"role\": \"user\", \"content\": prompt}\n",
        "                    ],\n",
        "                    temperature=0.5,\n",
        "                    max_tokens=400\n",
        "                )\n",
        "                summary = response.choices[0].message.content.strip()\n",
        "                self.summary_cache[cache_key] = summary # Cache the new summary\n",
        "                return summary\n",
        "            except Exception as e:\n",
        "                print(f\"Error during summarization: {e}. Returning full text.\")\n",
        "                return full_text\n",
        "\n",
        "    def can_make_choice(self) -> bool:\n",
        "        \"\"\"\n",
        "        Check if the current node has choices available.\n",
        "\n",
        "        Returns:\n",
        "            Boolean indicating if choices can be made\n",
        "        \"\"\"\n",
        "        return self.get_current_node().has_decisions()\n",
        "\n",
        "    def reset_to_node(self, node_id: str) -> None:\n",
        "        \"\"\"\n",
        "        Reset the current position to a specific node.\n",
        "\n",
        "        Args:\n",
        "            node_id: ID of the node to reset to\n",
        "        \"\"\"\n",
        "        if node_id not in self.nodes:\n",
        "            raise ValueError(f\"Node with ID {node_id} not found\")\n",
        "\n",
        "        # Find the path from root to this node\n",
        "        new_path = self._find_path_to_node(node_id)\n",
        "        if not new_path:\n",
        "            raise ValueError(f\"No valid path found to node {node_id}\")\n",
        "\n",
        "        self.current_node_id = node_id\n",
        "        self.path_history = new_path\n",
        "\n",
        "        # Update choice history to match the new path\n",
        "        self._update_choice_history()\n",
        "\n",
        "    def _find_path_to_node(self, target_node_id: str) -> Optional[List[str]]:\n",
        "        \"\"\"\n",
        "        Find a path from the root node to the target node.\n",
        "\n",
        "        Args:\n",
        "            target_node_id: ID of the target node\n",
        "\n",
        "        Returns:\n",
        "            List of node IDs forming the path, or None if no path exists\n",
        "        \"\"\"\n",
        "        if target_node_id == self.root_node_id:\n",
        "            return [self.root_node_id]\n",
        "\n",
        "        # Keep track of visited nodes during BFS\n",
        "        visited = set()\n",
        "        queue = [(self.root_node_id, [self.root_node_id])]\n",
        "\n",
        "        while queue:\n",
        "            node_id, path = queue.pop(0)\n",
        "\n",
        "            if node_id == target_node_id:\n",
        "                return path\n",
        "\n",
        "            if node_id in visited:\n",
        "                continue\n",
        "\n",
        "            visited.add(node_id)\n",
        "\n",
        "            # Check all children\n",
        "            node = self.nodes[node_id]\n",
        "            for child_id in node.children.values():\n",
        "                if child_id not in visited:\n",
        "                    queue.append((child_id, path + [child_id]))\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _update_choice_history(self) -> None:\n",
        "        \"\"\"\n",
        "        Update the choice history to match the current path.\n",
        "        \"\"\"\n",
        "        self.choice_history = []\n",
        "\n",
        "        for i in range(1, len(self.path_history)):\n",
        "            parent_id = self.path_history[i-1]\n",
        "            child_id = self.path_history[i]\n",
        "            parent_node = self.nodes[parent_id]\n",
        "\n",
        "            # Find which choice leads to this child\n",
        "            choice_index = None\n",
        "            for idx, cid in parent_node.children.items():\n",
        "                if cid == child_id:\n",
        "                    choice_index = int(idx)\n",
        "                    break\n",
        "\n",
        "            if choice_index is not None:\n",
        "                self.choice_history.append({\n",
        "                    \"from_node\": parent_id,\n",
        "                    \"choice_index\": choice_index,\n",
        "                    \"to_node\": child_id\n",
        "                })\n",
        "\n",
        "    def export_to_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Export the entire story structure to a dictionary.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary representation of the story structure\n",
        "        \"\"\"\n",
        "        nodes_dict = {node_id: node.to_dict() for node_id, node in self.nodes.items()}\n",
        "\n",
        "        return {\n",
        "            \"nodes\": nodes_dict,\n",
        "            \"root_node_id\": self.root_node_id,\n",
        "            \"current_node_id\": self.current_node_id,\n",
        "            \"path_history\": self.path_history,\n",
        "            \"choice_history\": self.choice_history,\n",
        "            \"story_metadata\": self.story_metadata\n",
        "        }\n",
        "\n",
        "    def export_to_json(self, pretty: bool = True) -> str:\n",
        "        \"\"\"\n",
        "        Export the entire story structure to a JSON string.\n",
        "\n",
        "        Args:\n",
        "            pretty: Whether to format the JSON for readability\n",
        "\n",
        "        Returns:\n",
        "            JSON string representation of the story structure\n",
        "        \"\"\"\n",
        "        data = self.export_to_dict()\n",
        "\n",
        "        if pretty:\n",
        "            return json.dumps(data, indent=2)\n",
        "        else:\n",
        "            return json.dumps(data)\n",
        "\n",
        "    def save_to_file(self, filepath: str) -> None:\n",
        "        \"\"\"\n",
        "        Save the story structure to a JSON file.\n",
        "\n",
        "        Args:\n",
        "            filepath: Path to save the file\n",
        "        \"\"\"\n",
        "        data = self.export_to_dict()\n",
        "\n",
        "        with open(filepath, 'w') as f:\n",
        "            json.dump(data, f, indent=2)\n",
        "\n",
        "    @classmethod\n",
        "    def load_from_dict(cls, data: Dict[str, Any]) -> 'BranchingLogicEngine':\n",
        "        \"\"\"\n",
        "        Create a BranchingLogicEngine from a dictionary representation.\n",
        "\n",
        "        Args:\n",
        "            data: Dictionary containing engine data\n",
        "\n",
        "        Returns:\n",
        "            BranchingLogicEngine instance\n",
        "        \"\"\"\n",
        "        engine = cls(api_key=data.get(\"story_metadata\", {}).get(\"api_key\"))\n",
        "\n",
        "        # Load nodes\n",
        "        for node_id, node_data in data.get(\"nodes\", {}).items():\n",
        "            engine.nodes[node_id] = StoryNode.from_dict(node_data)\n",
        "\n",
        "        # Load other attributes\n",
        "        engine.root_node_id = data.get(\"root_node_id\")\n",
        "        engine.current_node_id = data.get(\"current_node_id\")\n",
        "        engine.path_history = data.get(\"path_history\", [])\n",
        "        engine.choice_history = data.get(\"choice_history\", [])\n",
        "        engine.story_metadata = data.get(\"story_metadata\", {})\n",
        "\n",
        "        return engine\n",
        "\n",
        "    @classmethod\n",
        "    def load_from_json(cls, json_str: str) -> 'BranchingLogicEngine':\n",
        "        \"\"\"\n",
        "        Create a BranchingLogicEngine from a JSON string.\n",
        "\n",
        "        Args:\n",
        "            json_str: JSON string containing engine data\n",
        "\n",
        "        Returns:\n",
        "            BranchingLogicEngine instance\n",
        "        \"\"\"\n",
        "        data = json.loads(json_str)\n",
        "        return cls.load_from_dict(data)\n",
        "\n",
        "    @classmethod\n",
        "    def load_from_file(cls, filepath: str) -> 'BranchingLogicEngine':\n",
        "        \"\"\"\n",
        "        Create a BranchingLogicEngine from a JSON file.\n",
        "\n",
        "        Args:\n",
        "            filepath: Path to the JSON file\n",
        "\n",
        "        Returns:\n",
        "            BranchingLogicEngine instance\n",
        "        \"\"\"\n",
        "        with open(filepath, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        return cls.load_from_dict(data)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a new branching story\n",
        "    engine = BranchingLogicEngine(\n",
        "        initial_segment=\"Once upon a time, there was a brave little rabbit named Luna who lived at the edge of the Whispering Forest.\",\n",
        "        story_metadata={\"title\": \"Luna's Forest Adventure\", \"protagonist\": \"Luna\", \"theme\": \"bravery\"}\n",
        "    )\n",
        "\n",
        "    # Add a decision point to the first segment\n",
        "    engine.add_decision_to_current_node({\n",
        "        \"decision_prompt\": \"What should Luna do on this bright morning?\",\n",
        "        \"options\": [\n",
        "            {\n",
        "                \"choice_text\": \"Explore deeper into the forest\",\n",
        "                \"consequence_summary\": \"Luna might discover something amazing but could face dangers.\"\n",
        "            },\n",
        "            {\n",
        "                \"choice_text\": \"Visit her friend in the meadow\",\n",
        "                \"consequence_summary\": \"Luna will have a safer day but might miss an adventure.\"\n",
        "            }\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    # User chooses option 0 (explore the forest)\n",
        "    engine.add_story_continuation(\n",
        "        choice_index=0,\n",
        "        continuation_text=\"Luna decided to be brave and explore deeper into the Whispering Forest. She hopped past tall trees and colorful flowers she had never seen before. The forest seemed to come alive around her with strange sounds and movements.\"\n",
        "    )\n",
        "\n",
        "    # Add another decision\n",
        "    engine.add_decision_to_current_node({\n",
        "        \"decision_prompt\": \"Luna hears a strange noise coming from behind a large bush. What should she do?\",\n",
        "        \"options\": [\n",
        "            {\n",
        "                \"choice_text\": \"Investigate the noise\",\n",
        "                \"consequence_summary\": \"Luna might discover something interesting or dangerous.\"\n",
        "            },\n",
        "            {\n",
        "                \"choice_text\": \"Take a different path\",\n",
        "                \"consequence_summary\": \"Luna will avoid potential danger but miss a discovery.\"\n",
        "            }\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    # User chooses option 1 (take different path)\n",
        "    engine.add_story_continuation(\n",
        "        choice_index=1,\n",
        "        continuation_text=\"Luna decided it was safer to take a different path. She turned away from the mysterious bush and followed a winding dirt trail instead. The trail led her to a small bubbling stream with stepping stones.\"\n",
        "    )\n",
        "\n",
        "    # Print the full story so far\n",
        "    print(\"Full story so far:\")\n",
        "    print(engine.get_full_story_text())\n",
        "\n",
        "    # Export to JSON\n",
        "    story_json = engine.export_to_json()\n",
        "    print(\"\\nJSON representation:\")\n",
        "    print(story_json)\n",
        "\n",
        "    # Example of saving and loading\n",
        "    temp_file = \"temp_story.json\"\n",
        "    engine.save_to_file(temp_file)\n",
        "\n",
        "    # Load the story back\n",
        "    loaded_engine = BranchingLogicEngine.load_from_file(temp_file)\n",
        "\n",
        "    # Verify it loaded correctly\n",
        "    print(\"\\nVerifying loaded story:\")\n",
        "    print(f\"Root node ID matches: {loaded_engine.root_node_id == engine.root_node_id}\")\n",
        "    print(f\"Current node ID matches: {loaded_engine.current_node_id == engine.current_node_id}\")\n",
        "    print(f\"Number of nodes matches: {len(loaded_engine.nodes) == len(engine.nodes)}\")\n",
        "\n",
        "    # Clean up temp file\n",
        "    if os.path.exists(temp_file):\n",
        "        os.remove(temp_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PPa-o4RDtkEF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c132bd03-0de8-49c1-9c48-359b102fe3b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Prompt: What should Luna do with the shiny red apple?\n",
            "\n",
            "Options:\n",
            "1. Take a small bite to see if it's good\n",
            "    Luna might learn it's a special forest treat, and her curiosity grows\n",
            "2. Leave the apple behind because it's not from her garden\n",
            "    Luna shows she trusts her mother's advice and is willing to make responsible choices\n",
            "\n",
            "Continuation based on first choice:\n",
            "Luna took a small nibble of the shiny red apple. Mmm... it was the most delicious thing she had ever tasted! The sweetness exploded in her mouth and the crunch of the apple was so satisfying. Luna's eyes grew wide with excitement and she couldn't help but take another bite, and another, until the apple was almost gone.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Decision Point Generation Module (Prompt-Based)\n",
        "----------------------------------------------\n",
        "This module creates meaningful decision points after each story segment,\n",
        "generating two distinct branching options that influence story direction.\n",
        "It uses LLaMA 3 via Groq API with a pure prompting approach that doesn't\n",
        "depend on external datasets.\n",
        "\n",
        "Dependencies:\n",
        "- groq\n",
        "- typing\n",
        "\"\"\"\n",
        "\n",
        "import groq\n",
        "from typing import List, Dict, Optional, Any\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "import groq\n",
        "from typing import List, Dict, Optional, Any, Set, Tuple\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Make sure BranchingLogicEngine is defined or imported before this class\n",
        "# from your_branching_logic_module import BranchingLogicEngine # Assuming it's in another file/cell\n",
        "\n",
        "class DecisionPointGenerator:\n",
        "    \"\"\"\n",
        "    Generates meaningful, coherent decision points for interactive storytelling using LLaMA 3\n",
        "    with a template-based prompting approach. Incorporates moral guidance and recovery paths.\n",
        "\n",
        "    Attributes:\n",
        "        groq_client: Initialized Groq client for API calls\n",
        "        model_name: The Groq model to use for generation (default: llama3-8b-8192)\n",
        "        temperature: Temperature for generation (controls creativity)\n",
        "        decision_templates: Pre-defined templates for different decision types\n",
        "        narrative_arc_templates: Templates for different stages of the narrative arc including moral flags\n",
        "        needs_recovery: Flag to indicate if the story needs a recovery path after a wrong moral choice\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        api_key: str,\n",
        "        model_name: str = \"llama3-8b-8192\", # Changed default to llama3\n",
        "        temperature: float = 0.75\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize the DecisionPointGenerator with Groq API access and configuration.\n",
        "\n",
        "        Args:\n",
        "            api_key: Groq API key\n",
        "            model_name: Groq model to use (default: llama3-8b-8192)\n",
        "            temperature: Controls randomness in generation (default: 0.75)\n",
        "        \"\"\"\n",
        "        self.groq_client = groq.Client(api_key=api_key)\n",
        "        self.model_name = model_name\n",
        "        self.temperature = temperature\n",
        "\n",
        "        # Templates for different types of decisions (Unchanged from original)\n",
        "        self.decision_templates = {\n",
        "            \"action\": [\n",
        "                \"What should {character} do next?\",\n",
        "                \"How should {character} respond to this situation?\",\n",
        "                \"Which path should {character} choose?\",\n",
        "                \"What action should {character} take?\",\n",
        "                \"Should {character} go left or right?\"\n",
        "            ],\n",
        "            \"social\": [\n",
        "                \"Who should {character} ask for help?\",\n",
        "                \"How should {character} approach the other character?\",\n",
        "                \"Should {character} share what they know with others?\",\n",
        "                \"Should {character} trust the stranger?\",\n",
        "                \"How should {character} make new friends?\"\n",
        "            ],\n",
        "            \"problem_solving\": [\n",
        "                \"How should {character} solve this problem?\",\n",
        "                \"What tool should {character} use?\",\n",
        "                \"Should {character} try to fix it alone or seek help?\",\n",
        "                \"What approach should {character} take to overcome this obstacle?\",\n",
        "                \"How can {character} find what they're looking for?\"\n",
        "            ],\n",
        "            \"emotional\": [\n",
        "                \"Should {character} be brave or cautious?\",\n",
        "                \"Should {character} follow their heart or their head?\",\n",
        "                \"Should {character} express their feelings or keep them hidden?\",\n",
        "                \"Should {character} forgive or hold a grudge?\",\n",
        "                \"How should {character} deal with their fear?\"\n",
        "            ],\n",
        "            \"moral\": [\n",
        "                \"Should {character} tell the truth or keep a secret?\",\n",
        "                \"Should {character} follow the rules or break them for a good reason?\",\n",
        "                \"Should {character} put others first or take care of themselves?\",\n",
        "                \"Should {character} keep a promise even if it's difficult?\",\n",
        "                \"Is it better for {character} to be kind or to be right?\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Templates for different stages of the narrative arc (Merged)\n",
        "        self.narrative_arc_templates = {\n",
        "             \"introduction\": {\n",
        "                 \"decision_types\": [\"action\", \"social\"],\n",
        "                 \"importance\": \"establishing character traits and motivations\",\n",
        "                 \"consequence_scope\": \"affect how the character approaches future events\",\n",
        "                 \"moral_guidance_required\": False # Added\n",
        "             },\n",
        "             \"rising_action\": {\n",
        "                 \"decision_types\": [\"action\", \"problem_solving\", \"social\"],\n",
        "                 \"importance\": \"developing the central conflict\",\n",
        "                 \"consequence_scope\": \"complicate the story and raise the stakes\",\n",
        "                 \"moral_guidance_required\": False # Added\n",
        "             },\n",
        "             \"climax\": {\n",
        "                 \"decision_types\": [\"problem_solving\", \"emotional\", \"moral\"],\n",
        "                 \"importance\": \"determining how the main conflict will be resolved\",\n",
        "                 \"consequence_scope\": \"dramatically affect the story outcome\",\n",
        "                 \"moral_guidance_required\": True, # Added\n",
        "                 \"moral_choice_index\": 0,  # Added: Index of the morally correct choice\n",
        "                 \"recovery_required\": True  # Added: Requires a recovery path if wrong choice selected\n",
        "             },\n",
        "             \"resolution\": {\n",
        "                 \"decision_types\": [\"moral\", \"emotional\", \"social\"],\n",
        "                 \"importance\": \"reflecting the story's theme or moral\",\n",
        "                 \"consequence_scope\": \"conclude character arcs and reinforce the story's message\",\n",
        "                 \"moral_guidance_required\": True, # Added\n",
        "                 \"moral_choice_index\": 0,  # Added: Index of the morally correct choice\n",
        "                 \"recovery_required\": False # Added: No recovery needed in resolution\n",
        "             }\n",
        "         }\n",
        "\n",
        "        # Track if we need a recovery path (Added)\n",
        "        self.needs_recovery = False\n",
        "\n",
        "    # Added method from new code\n",
        "    def get_decision_point_count(self, length: str) -> int:\n",
        "        \"\"\"\n",
        "        Determine the minimum required decision points based on story length.\n",
        "\n",
        "        Args:\n",
        "            length: \"short\", \"medium\", or \"long\"\n",
        "\n",
        "        Returns:\n",
        "            Minimum number of decision points required\n",
        "        \"\"\"\n",
        "        if length.lower() == \"short\":\n",
        "            return 2  # Minimum 2 decisions for short stories\n",
        "        elif length.lower() == \"medium\":\n",
        "            return 3  # Minimum 3 decisions for medium stories (Adjusted from 3-4)\n",
        "        else:  # \"long\"\n",
        "            return 5  # Minimum 5 decisions for long stories\n",
        "\n",
        "    # Unchanged method from original\n",
        "    def _get_narrative_stage(self, segment_index: int, total_segments: int) -> str:\n",
        "        \"\"\"\n",
        "        Determine the current narrative stage based on segment index.\n",
        "\n",
        "        Args:\n",
        "            segment_index: Current segment index\n",
        "            total_segments: Total number of segments in the story\n",
        "\n",
        "        Returns:\n",
        "            String indicating the narrative stage\n",
        "        \"\"\"\n",
        "        progress = segment_index / total_segments if total_segments > 0 else 0.5\n",
        "\n",
        "        if progress < 0.25:\n",
        "            return \"introduction\"\n",
        "        elif progress < 0.6:\n",
        "            return \"rising_action\"\n",
        "        elif progress < 0.85:\n",
        "            return \"climax\"\n",
        "        else:\n",
        "            return \"resolution\"\n",
        "\n",
        "    # Merged method\n",
        "    def generate_decision_points(\n",
        "        self,\n",
        "        story_segment: str,\n",
        "        branching_engine: 'BranchingLogicEngine', # Use BranchingLogicEngine instance\n",
        "        character_names: List[str],\n",
        "        age: int,\n",
        "        segment_index: int = 0,\n",
        "        total_segments: int = 1,\n",
        "        story_length: str = \"medium\", # Keep story_length parameter\n",
        "        is_recovery_point: bool = False # Added parameter\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Generate two coherent branching options based on the current story segment.\n",
        "\n",
        "        Args:\n",
        "            story_segment: The current segment of the story\n",
        "            branching_engine: Instance of the BranchingLogicEngine to get context\n",
        "            character_names: List of character names in the story\n",
        "            age: Target audience age for appropriate decisions\n",
        "            segment_index: Current segment index (used for narrative progression)\n",
        "            total_segments: Total number of segments in the story\n",
        "            story_length: Length of the story (\"short\", \"medium\", or \"long\")\n",
        "            is_recovery_point: Whether this is a recovery point after a moral choice\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing decision prompt, options, and metadata\n",
        "        \"\"\"\n",
        "        # Get potentially summarized context from the engine\n",
        "        story_context_for_llm = branching_engine.get_story_context_for_llm()\n",
        "\n",
        "        # Determine narrative stage\n",
        "        narrative_stage = self._get_narrative_stage(segment_index, total_segments)\n",
        "        stage_info = self.narrative_arc_templates[narrative_stage]\n",
        "\n",
        "        # Extract main character from list or use generic\n",
        "        main_character = character_names[0] if character_names else \"the main character\"\n",
        "\n",
        "        # Select appropriate decision types for this narrative stage\n",
        "        decision_types = stage_info[\"decision_types\"]\n",
        "        selected_type = random.choice(decision_types)\n",
        "\n",
        "        # Get templates for selected decision type\n",
        "        templates = self.decision_templates[selected_type]\n",
        "\n",
        "        # Select a random template and format with character name\n",
        "        template_examples = \"\\n\".join([t.format(character=main_character) for t in templates[:3]])\n",
        "\n",
        "        # Check if this is a moral decision point (Added logic)\n",
        "        is_moral_decision = stage_info.get(\"moral_guidance_required\", False)\n",
        "        moral_choice_index = stage_info.get(\"moral_choice_index\", 0) if is_moral_decision else 0\n",
        "        needs_recovery_flag = stage_info.get(\"recovery_required\", False) if is_moral_decision else False\n",
        "\n",
        "        # For recovery points, adjust the decision to guide back (Added logic)\n",
        "        if is_recovery_point:\n",
        "             selected_type = \"moral\"\n",
        "             templates = self.decision_templates[\"moral\"]\n",
        "             template_examples = \"\\n\".join([t.format(character=main_character) for t in templates[:3]])\n",
        "             is_moral_decision = True\n",
        "             moral_choice_index = 0\n",
        "             needs_recovery_flag = False # Recovery point itself doesn't require another recovery\n",
        "\n",
        "        # Customize age-appropriate language (Unchanged from original)\n",
        "        if age <= 5:\n",
        "            complexity = \"very simple with clear choices that a 4-5 year old would understand\"\n",
        "        elif age <= 8:\n",
        "            complexity = \"simple but slightly more nuanced that a 6-8 year old would understand\"\n",
        "        else:\n",
        "            complexity = \"moderately complex with some nuance that a 9-12 year old would understand\"\n",
        "\n",
        "        # Additional context for moral decisions (Added logic)\n",
        "        moral_guidance = \"\"\n",
        "        if is_moral_decision:\n",
        "            moral_guidance = f\"\"\"\n",
        "            IMPORTANT: This is a moral decision point that teaches the child a lesson.\n",
        "\n",
        "            Option {moral_choice_index + 1} should represent the morally correct choice that teaches the intended lesson.\n",
        "            Option {2 - moral_choice_index} should represent an incorrect choice that goes against the moral.\n",
        "\n",
        "            The consequence_summary for the correct choice should show a positive outcome.\n",
        "            The consequence_summary for the incorrect choice should show why it's not the best decision,\n",
        "            but avoid being too negative or scary.\n",
        "            \"\"\"\n",
        "\n",
        "        # Use story_context_for_llm from engine instead of passed context\n",
        "        prompt = f\"\"\"\n",
        "        Create a decision point for a children's interactive story that is {complexity}.\n",
        "\n",
        "        STORY CONTEXT:\n",
        "        {story_context_for_llm}\n",
        "\n",
        "        CURRENT SEGMENT:\n",
        "        {story_segment}\n",
        "\n",
        "        We are at the {narrative_stage.replace('_', ' ')} stage of the story.\n",
        "        The decisions here should focus on {stage_info[\"importance\"]}.\n",
        "        The consequences should {stage_info[\"consequence_scope\"]}.\n",
        "\n",
        "        Here are some example decision patterns you could adapt:\n",
        "        {template_examples}\n",
        "\n",
        "        The decision should involve the character \"{main_character}\" and present TWO clearly different paths.\n",
        "        {moral_guidance}\n",
        "\n",
        "        FORMAT YOUR RESPONSE AS JSON:\n",
        "        {{\n",
        "            \"decision_prompt\": \"An engaging question like 'What should {main_character} do?'\",\n",
        "            \"options\": [\n",
        "                {{\n",
        "                    \"choice_text\": \"First option (5-10 words)\",\n",
        "                    \"consequence_summary\": \"Brief hint about outcome (1 sentence)\"\n",
        "                }},\n",
        "                {{\n",
        "                    \"choice_text\": \"Second contrasting option (5-10 words)\",\n",
        "                    \"consequence_summary\": \"Different outcome hint (1 sentence)\"\n",
        "                }}\n",
        "            ]\n",
        "        }}\n",
        "\n",
        "        IMPORTANT:\n",
        "        1. Make sure both options are age-appropriate for a {age}-year-old\n",
        "        2. The options should be genuinely different paths, not slight variations\n",
        "        3. Each option should lead to meaningfully different story directions\n",
        "        4. Use language a {age}-year-old would understand\n",
        "        \"\"\"\n",
        "\n",
        "        response = self.groq_client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": f\"You create engaging, age-appropriate decision points for interactive children's stories targeted at {age}-year-olds.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=self.temperature,\n",
        "            max_tokens=512,\n",
        "            response_format={\"type\": \"json_object\"}\n",
        "        )\n",
        "\n",
        "        # Extract and parse the JSON response\n",
        "        try:\n",
        "            decision_point_text = response.choices[0].message.content\n",
        "            # Use json.loads for safer parsing than eval\n",
        "            import json\n",
        "            decision_point = json.loads(decision_point_text)\n",
        "\n",
        "            # Add metadata including moral/recovery info (Updated metadata)\n",
        "            decision_point[\"metadata\"] = {\n",
        "                \"segment_index\": segment_index,\n",
        "                \"narrative_stage\": narrative_stage,\n",
        "                \"decision_type\": selected_type,\n",
        "                \"model_used\": self.model_name,\n",
        "                \"is_moral_decision\": is_moral_decision,\n",
        "                \"moral_choice_index\": moral_choice_index if is_moral_decision else None,\n",
        "                \"needs_recovery\": needs_recovery_flag, # Use the flag determined earlier\n",
        "                \"is_recovery_point\": is_recovery_point\n",
        "            }\n",
        "\n",
        "            return decision_point\n",
        "\n",
        "        except Exception as e:\n",
        "            # Fallback response if parsing fails (Updated metadata)\n",
        "            print(f\"Error parsing decision point: {e}\")\n",
        "            # Determine fallback needs_recovery based on stage\n",
        "            fallback_needs_recovery = stage_info.get(\"recovery_required\", False) if stage_info.get(\"moral_guidance_required\", False) else False\n",
        "            return {\n",
        "                \"decision_prompt\": f\"What should {main_character} do next?\",\n",
        "                \"options\": [\n",
        "                    {\n",
        "                        \"choice_text\": \"Take the safe path\",\n",
        "                        \"consequence_summary\": \"This might be easier but less exciting.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"choice_text\": \"Try something risky\",\n",
        "                        \"consequence_summary\": \"This could lead to adventure or trouble.\"\n",
        "                    }\n",
        "                ],\n",
        "                \"metadata\": {\n",
        "                    \"segment_index\": segment_index,\n",
        "                    \"narrative_stage\": narrative_stage,\n",
        "                    \"decision_type\": \"action\",\n",
        "                    \"model_used\": self.model_name,\n",
        "                    \"is_moral_decision\": False, # Fallback assumes not moral\n",
        "                    \"moral_choice_index\": None,\n",
        "                    \"needs_recovery\": fallback_needs_recovery, # Use fallback value\n",
        "                    \"is_recovery_point\": is_recovery_point,\n",
        "                    \"error\": str(e)\n",
        "                }\n",
        "            }\n",
        "\n",
        "    # Merged method\n",
        "    def generate_continuation_from_choice(\n",
        "        self,\n",
        "        branching_engine: 'BranchingLogicEngine', # Use BranchingLogicEngine instance\n",
        "        decision_prompt: str,\n",
        "        selected_choice: Dict[str, str],\n",
        "        unselected_choice: Dict[str, str],\n",
        "        character_names: List[str],\n",
        "        age: int,\n",
        "        next_segment_length: int = 4,  # Number of sentences\n",
        "        is_recovery_path: bool = False # Added parameter\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Generate a continuation of the story based on the user's selected choice.\n",
        "\n",
        "        Args:\n",
        "            branching_engine: Instance of the BranchingLogicEngine to get context\n",
        "            decision_prompt: The question that was asked\n",
        "            selected_choice: Dict with choice_text and consequence_summary that user selected\n",
        "            unselected_choice: Dict with choice_text and consequence_summary that user did not select\n",
        "            character_names: List of character names\n",
        "            age: Target audience age\n",
        "            next_segment_length: Approximate length of next segment in sentences\n",
        "            is_recovery_path: Whether this is a continuation after a wrong moral choice\n",
        "\n",
        "        Returns:\n",
        "            String containing the next story segment\n",
        "        \"\"\"\n",
        "        # Get potentially summarized context from the engine\n",
        "        story_context_for_llm = branching_engine.get_story_context_for_llm()\n",
        "\n",
        "        # Ensure appropriate segment length based on age (Unchanged from original)\n",
        "        if age <= 5:\n",
        "            actual_segment_length = min(next_segment_length, 3)\n",
        "        elif age <= 8:\n",
        "            actual_segment_length = min(next_segment_length, 4)\n",
        "        else:\n",
        "            actual_segment_length = next_segment_length\n",
        "\n",
        "        # Add more guidance for younger children (Unchanged from original)\n",
        "        if age <= 5:\n",
        "            tone_guidance = \"Use very simple vocabulary and short sentences. Focus on clear cause and effect.\"\n",
        "        elif age <= 8:\n",
        "            tone_guidance = \"Use straightforward language with some descriptive elements. Include character emotions.\"\n",
        "        else:\n",
        "            tone_guidance = \"Use more complex vocabulary and sentence structure. Include character thoughts and feelings.\"\n",
        "\n",
        "        # Add special guidance for recovery paths (Added logic)\n",
        "        recovery_guidance = \"\"\n",
        "        if is_recovery_path:\n",
        "             # Set the internal flag for the next decision point generation\n",
        "             self.needs_recovery = True\n",
        "             recovery_guidance = \"\"\"\n",
        "             IMPORTANT: This is a recovery segment after the reader made a choice that didn't align with the moral lesson.\n",
        "\n",
        "             Show the consequences of the choice, but create a situation where the character realizes they should\n",
        "             reconsider their approach. Don't be judgmental or heavy-handed, but subtly guide the story back\n",
        "             toward a positive lesson.\n",
        "\n",
        "             End the segment in a way that naturally leads to another decision point where the character can\n",
        "             make a better choice aligned with the story's moral.\n",
        "             \"\"\"\n",
        "        else:\n",
        "            # Reset recovery flag if not on a recovery path\n",
        "            self.needs_recovery = False\n",
        "\n",
        "\n",
        "        # Use story_context_for_llm from engine instead of passed context\n",
        "        prompt = f\"\"\"\n",
        "        Continue this children's story for {age}-year-olds.\n",
        "\n",
        "        STORY SO FAR:\n",
        "        {story_context_for_llm}\n",
        "\n",
        "        DECISION POINT:\n",
        "        {decision_prompt}\n",
        "\n",
        "        THE READER CHOSE:\n",
        "        \"{selected_choice['choice_text']}\"\n",
        "        Expected consequence: {selected_choice['consequence_summary']}\n",
        "\n",
        "        {recovery_guidance}\n",
        "\n",
        "        Write the next segment of the story (about {actual_segment_length} sentences) that:\n",
        "        1. Directly shows the outcome of the chosen option\n",
        "        2. Is age-appropriate for {age}-year-olds\n",
        "        3. {tone_guidance}\n",
        "        4. Advances the story in a meaningful way that follows from the choice\n",
        "        5. Is engaging and visual\n",
        "\n",
        "        Return only the story text with no additional explanation or commentary.\n",
        "        \"\"\"\n",
        "\n",
        "        response = self.groq_client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": f\"You are an expert children's storyteller writing for {age}-year-olds.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=self.temperature,\n",
        "            max_tokens=400\n",
        "        )\n",
        "\n",
        "        next_segment = response.choices[0].message.content.strip()\n",
        "        return next_segment\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize the decision point generator\n",
        "    generator = DecisionPointGenerator(\n",
        "        api_key=os.environ.get(\"GROQ_API_KEY\", \"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\")\n",
        "    )\n",
        "\n",
        "    branching_engine_instance = BranchingLogicEngine(\n",
        "         initial_segment=\"Luna is a young rabbit exploring the forest for the first time.\", # Provide some initial data\n",
        "         story_metadata={\"theme\": \"curiosity\"}, # Add some metadata\n",
        "         api_key=os.environ.get(\"GROQ_API_KEY\", \"YOUR_FALLBACK_API_KEY\") # Pass API key\n",
        "    )\n",
        "\n",
        "    # Example story segment and context\n",
        "    sample_segment = \"Luna the rabbit hopped excitedly through the forest. She found a shiny red apple under a tall oak tree. The apple looked delicious, but Luna remembered her mother told her not to eat strange food from the forest.\"\n",
        "\n",
        "    sample_context = \"Luna is a young rabbit exploring the forest for the first time. Her parents warned her about forest dangers, but she's curious and adventurous.\"\n",
        "\n",
        "    decision = generator.generate_decision_points(\n",
        "        story_segment=sample_segment,\n",
        "        branching_engine=branching_engine_instance, # Pass the actual engine instance\n",
        "        character_names=[\"Luna\", \"Mother Rabbit\"],\n",
        "        age=6,\n",
        "        segment_index=1, # Example index\n",
        "        total_segments=5, # Example total\n",
        "        story_length=\"short\" # Example length\n",
        "    )\n",
        "\n",
        "    if decision and \"options\" in decision: # Check if decision and options exist\n",
        "        print(\"Decision Prompt:\", decision.get(\"decision_prompt\", \"N/A\"))\n",
        "        print(\"\\nOptions:\")\n",
        "        options = decision.get(\"options\", [])\n",
        "        if len(options) > 0:\n",
        "            print(\"1.\", options[0].get(\"choice_text\", \"N/A\"))\n",
        "            print(\"   \", options[0].get(\"consequence_summary\", \"\"))\n",
        "        if len(options) > 1:\n",
        "            print(\"2.\", options[1].get(\"choice_text\", \"N/A\"))\n",
        "            print(\"   \", options[1].get(\"consequence_summary\", \"\"))\n",
        "\n",
        "        # Example: Generate continuation from selected choice - Pass the engine instance\n",
        "        if len(options) > 0:\n",
        "            # Ensure the branching_engine_instance has the current segment added if needed for context\n",
        "            # (In a real scenario, the engine state would be updated before this call)\n",
        "            # For this standalone example, the context comes from the engine's initial state + get_full_story_text logic\n",
        "\n",
        "            next_segment = generator.generate_continuation_from_choice(\n",
        "                branching_engine=branching_engine_instance, # Pass the engine instance\n",
        "                decision_prompt=decision.get(\"decision_prompt\", \"N/A\"),\n",
        "                selected_choice=options[0],\n",
        "                unselected_choice=options[1] if len(options) > 1 else options[0],\n",
        "                character_names=[\"Luna\", \"Mother Rabbit\"],\n",
        "                age=6\n",
        "            )\n",
        "\n",
        "            print(\"\\nContinuation based on first choice:\")\n",
        "            print(next_segment)\n",
        "        else:\n",
        "            print(\"\\nCould not generate continuation example: No options found.\")\n",
        "    else:\n",
        "        print(\"\\nError: Failed to generate decision point or options in example.\")\n",
        "        print(\"Received decision data:\", decision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "v4b8LS7Oyw-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65925fd0-44c8-40f3-ab3c-161ad373cde5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded morals dataset with 665 entries\n",
            "Themes identified: here are the main themes present in the story:, **courage, kindness, friendship, overcoming prejudice, helping others**, let me explain how these themes are reflected in the story:, * **courage:** luna chooses to explore the unknown forest despite being scared, and she helps the fox cub even though foxes are predators., * **kindness:** luna's actions towards the lost fox cub demonstrate her compassion and willingness to help despite their differences., * **friendship:** luna and the\n",
            "\n",
            "Generated moral: Helping someone in need can build a strong friendship, even if they are different from you.\n",
            "\n",
            "Similar morals that were referenced:\n",
            "1. Kindness to others brings joy to everyone.\n",
            "2. Small acts of kindness can make a big difference.\n",
            "3. Being kind is more important than being right.\n",
            "\n",
            "Moral explanation for children:\n",
            "Being kind to someone who needs help can make a great friend, even if they are different from you! It takes courage to reach out, just like Luna did for the fox cub. Imagine you see a new kid at school who looks sad. Offering a smile or sharing your toys can make them feel welcome and start a beautiful friendship!\n",
            "\n",
            "Discussion questions:\n",
            "Here are three discussion questions about helping someone in need, suitable for 7-year-olds:\n",
            "\n",
            "1. **Can you think of a time when you helped someone who was different from you? How did it make you feel?**  (This encourages them to share personal experiences and connect the moral to their own lives.) \n",
            "\n",
            "2. **What do you think Luna was feeling when she saw the fox cub?  Was she scared?  Was she kind? How did she show her courage?** (This helps them understand Luna's emotions and actions in the story.)\n",
            "\n",
            "3. **If you saw someone who looked lost or sad, what would you do?  How could you show them kindness, even if they were different from you?** (This prompts them to think about how they could apply the moral in their own lives.)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Moral Generation System\n",
        "----------------------\n",
        "This module extracts and generates a moral based on the story and decisions.\n",
        "It leverages the existing StoryRAG class to retrieve similar morals and uses\n",
        "the Gemma model via Groq API for moral synthesis and reflection.\n",
        "\n",
        "Dependencies:\n",
        "- groq\n",
        "- typing\n",
        "- existing StoryRAG infrastructure\n",
        "\"\"\"\n",
        "\n",
        "import groq\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "\n",
        "class MoralGenerator:\n",
        "    \"\"\"\n",
        "    Generates age-appropriate morals for interactive children's stories\n",
        "    using the StoryRAG retrieval system and Gemma model via Groq.\n",
        "\n",
        "    Attributes:\n",
        "        groq_client: Initialized Groq client for API calls\n",
        "        story_rag: StoryRAG instance for retrieval of similar morals\n",
        "        morals_df: DataFrame containing processed morals (if direct access needed)\n",
        "        model_name: The Groq model to use for generation (default: gemma2-9b-it)\n",
        "        temperature: Temperature for generation (controls creativity)\n",
        "        data_dir: Directory containing processed data files\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        api_key: str = \"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\",\n",
        "        story_rag = None,  # StoryRAG instance\n",
        "        processed_data_dir: str = \"data/processed\",\n",
        "        model_name: str = \"gemma2-9b-it\",\n",
        "        temperature: float = 0.6\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize the MoralGenerator with Groq API access and configuration.\n",
        "\n",
        "        Args:\n",
        "            api_key: Groq API key\n",
        "            story_rag: Instance of the StoryRAG class for retrieval\n",
        "            processed_data_dir: Directory containing processed data files (default: \"data/processed\")\n",
        "            model_name: Groq model to use (default: gemma2-9b-it)\n",
        "            temperature: Controls randomness in generation (default: 0.6)\n",
        "        \"\"\"\n",
        "        self.groq_client = groq.Client(api_key=api_key)\n",
        "        self.story_rag = story_rag\n",
        "        self.data_dir = Path(processed_data_dir)\n",
        "        self.model_name = model_name\n",
        "        self.temperature = temperature\n",
        "\n",
        "        # Optionally load the morals dataframe directly for reference\n",
        "        try:\n",
        "            self.morals_df = pd.read_csv(self.data_dir / \"processed_morals.csv\")\n",
        "            print(f\"Successfully loaded morals dataset with {len(self.morals_df)} entries\")\n",
        "        except FileNotFoundError:\n",
        "            print(\"Warning: processed_morals.csv not found. Will rely on StoryRAG for retrievals.\")\n",
        "            self.morals_df = None\n",
        "\n",
        "    def extract_themes(self, story_text: str, choices_made: List[Dict[str, Any]]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Extract the central themes from the story and choices made.\n",
        "\n",
        "        Args:\n",
        "            story_text: The full text of the story\n",
        "            choices_made: List of decision choices that were selected\n",
        "\n",
        "        Returns:\n",
        "            List of identified themes\n",
        "        \"\"\"\n",
        "        # Prepare a summary of choices made to help with theme identification\n",
        "        choices_summary = \"\"\n",
        "        if choices_made:\n",
        "            choices_summary = \"The reader made these choices during the story:\\n\"\n",
        "            for i, choice in enumerate(choices_made, 1):\n",
        "                choices_summary += f\"{i}. {choice.get('choice_text', '')}\\n\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Analyze this children's story and identify the 3-5 central themes.\n",
        "\n",
        "        STORY TEXT:\n",
        "        {story_text}\n",
        "\n",
        "        {choices_summary}\n",
        "\n",
        "        Identify the main themes that are present in this story (like courage, friendship, honesty, etc.).\n",
        "        Consider both the events in the story and the choices the reader made.\n",
        "\n",
        "        Return your response as a comma-separated list of themes, for example:\n",
        "        bravery, kindness, perseverance, trust\n",
        "\n",
        "        THEMES:\n",
        "        \"\"\"\n",
        "\n",
        "        response = self.groq_client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an expert at analyzing children's stories and extracting their central themes.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.4,  # Lower temperature for consistent theme extraction\n",
        "            max_tokens=100\n",
        "        )\n",
        "\n",
        "        # Process the response to extract themes\n",
        "        themes_text = response.choices[0].message.content.strip()\n",
        "\n",
        "        # Clean up the response and split into individual themes\n",
        "        themes = [\n",
        "            theme.strip().lower()\n",
        "            for theme in re.split(r',|\\n', themes_text)\n",
        "            if theme.strip()\n",
        "        ]\n",
        "\n",
        "        return themes\n",
        "\n",
        "    def retrieve_similar_morals(self, themes: List[str], top_k: int = 3) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Use StoryRAG to retrieve morals similar to the identified themes.\n",
        "\n",
        "        Args:\n",
        "            themes: List of themes extracted from the story\n",
        "            top_k: Number of similar morals to retrieve\n",
        "\n",
        "        Returns:\n",
        "            List of retrieved morals with metadata\n",
        "        \"\"\"\n",
        "        # Check if StoryRAG is available\n",
        "        if not self.story_rag:\n",
        "            print(\"Warning: No StoryRAG instance provided, returning default morals\")\n",
        "            return [\n",
        "                {\"moral\": \"It's important to be brave and face your fears.\", \"theme\": \"courage\"},\n",
        "                {\"moral\": \"True friendship means being there for others when they need help.\", \"theme\": \"friendship\"},\n",
        "                {\"moral\": \"Kindness to others brings joy to everyone.\", \"theme\": \"kindness\"}\n",
        "            ]\n",
        "\n",
        "        # Use the primary theme to retrieve relevant morals\n",
        "        similar_morals = []\n",
        "\n",
        "        # Try each theme until we get enough morals\n",
        "        for theme in themes:\n",
        "            # Use StoryRAG's get_moral_by_theme method to find matching morals\n",
        "            theme_morals = self.story_rag.get_moral_by_theme(theme, top_k=top_k)\n",
        "\n",
        "            if theme_morals:\n",
        "                similar_morals.extend(theme_morals)\n",
        "\n",
        "            # If we have enough morals, stop\n",
        "            if len(similar_morals) >= top_k:\n",
        "                break\n",
        "\n",
        "        # If we still don't have enough morals, try a more general search\n",
        "        if len(similar_morals) < top_k:\n",
        "            # Use a more general theme like \"life lessons\"\n",
        "            more_morals = self.story_rag.get_moral_by_theme(\"life lessons\", top_k=top_k-len(similar_morals))\n",
        "            if more_morals:\n",
        "                similar_morals.extend(more_morals)\n",
        "\n",
        "        # Ensure we don't return duplicates and limit to top_k\n",
        "        unique_morals = []\n",
        "        moral_texts = set()\n",
        "\n",
        "        for moral in similar_morals:\n",
        "            moral_text = moral.get(\"moral\", \"\")\n",
        "            if moral_text and moral_text not in moral_texts:\n",
        "                moral_texts.add(moral_text)\n",
        "                unique_morals.append(moral)\n",
        "                if len(unique_morals) >= top_k:\n",
        "                    break\n",
        "\n",
        "        return unique_morals\n",
        "\n",
        "    def generate_moral(\n",
        "        self,\n",
        "        story_text: str,\n",
        "        choices_made: List[Dict[str, Any]],\n",
        "        age: int,\n",
        "        theme: str = None,\n",
        "        story_title: str = None\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Generate a single, clean age-appropriate moral for the story.\n",
        "\n",
        "        Args:\n",
        "            story_text: The full text of the story\n",
        "            choices_made: List of decision choices that were selected\n",
        "            age: Target audience age for appropriate moral complexity\n",
        "            theme: Optional main theme to focus on\n",
        "            story_title: Optional title of the story\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing the generated moral and metadata\n",
        "        \"\"\"\n",
        "        # First, extract themes if not provided\n",
        "        story_themes = [theme.lower()] if theme else []\n",
        "        extracted_themes = self.extract_themes(story_text, choices_made)\n",
        "\n",
        "        # Combine provided theme with extracted themes, prioritizing the provided theme\n",
        "        if theme and theme.lower() not in extracted_themes:\n",
        "            story_themes.extend(extracted_themes)\n",
        "        else:\n",
        "            story_themes = extracted_themes\n",
        "\n",
        "        # Create a brief summary of the story for context\n",
        "        summary_prompt = f\"\"\"\n",
        "        Summarize this children's story in a few sentences:\n",
        "\n",
        "        {story_text}\n",
        "\n",
        "        Summary:\n",
        "        \"\"\"\n",
        "\n",
        "        summary_response = self.groq_client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You summarize children's stories concisely.\"},\n",
        "                {\"role\": \"user\", \"content\": summary_prompt}\n",
        "            ],\n",
        "            temperature=0.4,\n",
        "            max_tokens=150\n",
        "        )\n",
        "\n",
        "        story_summary = summary_response.choices[0].message.content.strip()\n",
        "\n",
        "        # Retrieve similar morals using StoryRAG\n",
        "        similar_morals = self.retrieve_similar_morals(story_themes)\n",
        "\n",
        "        # Extract the text of the retrieved morals\n",
        "        moral_examples = []\n",
        "        for moral in similar_morals:\n",
        "            if 'moral' in moral:\n",
        "                moral_examples.append(moral['moral'])\n",
        "            else:\n",
        "                for key, value in moral.items():\n",
        "                    if isinstance(value, str) and len(value) > 10:\n",
        "                        moral_examples.append(value)\n",
        "                        break\n",
        "\n",
        "        # Format the moral examples for the prompt\n",
        "        moral_examples_text = \"\"\n",
        "        if moral_examples:\n",
        "            moral_examples_text = \"Here are some example morals from similar stories:\\n\"\n",
        "            for i, example in enumerate(moral_examples[:3], 1):\n",
        "                moral_examples_text += f\"Example {i}: {example}\\n\\n\"\n",
        "\n",
        "        # Adjust complexity based on age\n",
        "        if age <= 5:\n",
        "            complexity = \"very simple, using basic vocabulary for very young children (ages 3-5)\"\n",
        "        elif age <= 8:\n",
        "            complexity = \"straightforward but meaningful for early elementary children (ages 6-8)\"\n",
        "        else:\n",
        "            complexity = \"more nuanced with a deeper message for older elementary children (ages 9-12)\"\n",
        "\n",
        "        title_info = f\"titled '{story_title}'\" if story_title else \"\"\n",
        "\n",
        "        # Modified prompt to request a single, clear moral\n",
        "        prompt = f\"\"\"\n",
        "        Create a single moral lesson for a children's story {title_info}.\n",
        "\n",
        "        STORY SUMMARY:\n",
        "        {story_summary}\n",
        "\n",
        "        MAIN THEMES:\n",
        "        {', '.join(story_themes)}\n",
        "\n",
        "        {moral_examples_text}\n",
        "\n",
        "        Provide ONE clear moral statement that is:\n",
        "        1. {complexity}\n",
        "        2. Directly connected to the story's themes and events\n",
        "        3. Positive and encouraging\n",
        "        4. Brief (1-2 sentences)\n",
        "        5. Relatable to children's everyday experiences\n",
        "\n",
        "        Do NOT provide multiple options or numbered alternatives.\n",
        "        Do NOT use formatting like asterisks or bullet points.\n",
        "        Respond with ONLY the moral statement itself.\n",
        "\n",
        "        MORAL:\n",
        "        \"\"\"\n",
        "\n",
        "        response = self.groq_client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": f\"You create meaningful, age-appropriate morals for children's stories targeted at {age}-year-olds.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=self.temperature,\n",
        "            max_tokens=200\n",
        "        )\n",
        "\n",
        "        moral_text = response.choices[0].message.content.strip()\n",
        "\n",
        "        # Clean the moral to remove any remaining formatting\n",
        "        moral_text = re.sub(r'Option \\d+.*?:', '', moral_text)\n",
        "        moral_text = re.sub(r'Here are.*?options!', '', moral_text)\n",
        "        moral_text = moral_text.replace('*', '').strip()\n",
        "\n",
        "        # Return the generated moral with metadata\n",
        "        return {\n",
        "            \"moral\": moral_text,\n",
        "            \"themes\": story_themes,\n",
        "            \"similar_morals_used\": moral_examples[:3] if moral_examples else [],\n",
        "            \"metadata\": {\n",
        "                \"age\": age,\n",
        "                \"model_used\": self.model_name,\n",
        "                \"story_summary\": story_summary\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def generate_expanded_moral_content(\n",
        "        self,\n",
        "        moral: str,\n",
        "        themes: List[str],\n",
        "        age: int,\n",
        "        format_type: str = \"explanation\"\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Generate expanded content based on the moral for different use cases.\n",
        "\n",
        "        Args:\n",
        "            moral: The main moral text\n",
        "            themes: List of story themes\n",
        "            age: Target audience age\n",
        "            format_type: Type of expanded content (\"explanation\", \"discussion_questions\", \"activity\")\n",
        "\n",
        "        Returns:\n",
        "            Expanded content text\n",
        "        \"\"\"\n",
        "        if format_type == \"explanation\":\n",
        "            prompt_focus = f\"\"\"\n",
        "            Create a child-friendly explanation of this moral suitable for {age}-year-olds.\n",
        "            Explain what the moral means in simple terms and provide a real-life example that children can relate to.\n",
        "            Keep it concise (3-5 sentences total).\n",
        "            \"\"\"\n",
        "\n",
        "        elif format_type == \"discussion_questions\":\n",
        "            prompt_focus = f\"\"\"\n",
        "            Create 3 discussion questions about this moral suitable for {age}-year-olds.\n",
        "            The questions should help children reflect on the moral and connect it to their own experiences.\n",
        "            Make the questions open-ended and thought-provoking but simple enough for the age group.\n",
        "            \"\"\"\n",
        "\n",
        "        elif format_type == \"activity\":\n",
        "            prompt_focus = f\"\"\"\n",
        "            Create a simple activity related to this moral suitable for {age}-year-olds.\n",
        "            The activity should help reinforce the moral through creative expression or roleplay.\n",
        "            Describe the activity in 3-5 sentences, including any simple materials needed.\n",
        "            \"\"\"\n",
        "\n",
        "        else:\n",
        "            prompt_focus = f\"\"\"\n",
        "            Provide additional insight into this moral suitable for {age}-year-olds.\n",
        "            Explain the importance of the moral in children's development and growth.\n",
        "            Keep it concise (3-5 sentences).\n",
        "            \"\"\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        MORAL:\n",
        "        {moral}\n",
        "\n",
        "        THEMES:\n",
        "        {', '.join(themes)}\n",
        "\n",
        "        TASK:\n",
        "        {prompt_focus}\n",
        "\n",
        "        Ensure your response is:\n",
        "        1. Age-appropriate for {age}-year-olds\n",
        "        2. Positive and encouraging\n",
        "        3. Clear and simple to understand\n",
        "        \"\"\"\n",
        "\n",
        "        response = self.groq_client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": f\"You create educational content for children aged {age}.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=self.temperature,\n",
        "            max_tokens=300\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # This is a simplified version of the StoryRAG class for testing\n",
        "    class SimpleStoryRAG:\n",
        "        def get_moral_by_theme(self, theme, top_k=3):\n",
        "            # Simple mocked implementation\n",
        "            morals_by_theme = {\n",
        "                \"friendship\": [\n",
        "                    {\"moral\": \"True friendship means being there for others when they need help.\", \"theme\": \"friendship\"},\n",
        "                    {\"moral\": \"Friends accept each other's differences.\", \"theme\": \"friendship\"},\n",
        "                    {\"moral\": \"Friendship can grow in unlikely places.\", \"theme\": \"friendship\"}\n",
        "                ],\n",
        "                \"courage\": [\n",
        "                    {\"moral\": \"It's important to be brave and face your fears.\", \"theme\": \"courage\"},\n",
        "                    {\"moral\": \"Courage means doing what's right even when it's hard.\", \"theme\": \"courage\"},\n",
        "                    {\"moral\": \"Being brave doesn't mean you're never scared.\", \"theme\": \"courage\"}\n",
        "                ],\n",
        "                \"kindness\": [\n",
        "                    {\"moral\": \"Kindness to others brings joy to everyone.\", \"theme\": \"kindness\"},\n",
        "                    {\"moral\": \"Small acts of kindness can make a big difference.\", \"theme\": \"kindness\"},\n",
        "                    {\"moral\": \"Being kind is more important than being right.\", \"theme\": \"kindness\"}\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            # Return morals for the requested theme or empty list if not found\n",
        "            return morals_by_theme.get(theme.lower(), [])[:top_k]\n",
        "\n",
        "    # Create a mock story\n",
        "    sample_story = \"\"\"\n",
        "    Once upon a time, there was a rabbit named Luna who lived at the edge of the Whispering Forest.\n",
        "    One morning, Luna decided to explore deeper into the forest even though she was a little scared.\n",
        "    As she ventured in, she found a beautiful clearing with a stream. There, she met a lost fox cub who was crying.\n",
        "    Even though rabbits and foxes weren't usually friends, Luna decided to help the fox cub find its way home.\n",
        "    Together, they faced challenges and helped each other overcome obstacles.\n",
        "    When they finally found the fox family, they were so grateful to Luna that they promised never to hunt rabbits again.\n",
        "    Luna and the fox cub became unlikely friends, showing everyone in the forest that kindness and courage can bring different animals together.\n",
        "    \"\"\"\n",
        "\n",
        "    sample_choices = [\n",
        "        {\"choice_text\": \"Explore deeper into the forest\"},\n",
        "        {\"choice_text\": \"Help the fox cub\"},\n",
        "        {\"choice_text\": \"Cross the dangerous stream\"}\n",
        "    ]\n",
        "\n",
        "    # Initialize the moral generator with the mock StoryRAG\n",
        "    moral_gen = MoralGenerator(\n",
        "        api_key=\"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\",\n",
        "        story_rag=SimpleStoryRAG(),\n",
        "        processed_data_dir=\"data/processed\"\n",
        "    )\n",
        "\n",
        "    # Generate a moral for the sample story\n",
        "    result = moral_gen.generate_moral(\n",
        "        story_text=sample_story,\n",
        "        choices_made=sample_choices,\n",
        "        age=7,\n",
        "        story_title=\"Luna and the Lost Fox Cub\"\n",
        "    )\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Themes identified: {', '.join(result['themes'])}\")\n",
        "    print(f\"\\nGenerated moral: {result['moral']}\")\n",
        "\n",
        "    print(\"\\nSimilar morals that were referenced:\")\n",
        "    for i, moral in enumerate(result['similar_morals_used'], 1):\n",
        "        print(f\"{i}. {moral}\")\n",
        "\n",
        "    # Generate expanded content\n",
        "    explanation = moral_gen.generate_expanded_moral_content(\n",
        "        moral=result['moral'],\n",
        "        themes=result['themes'],\n",
        "        age=7,\n",
        "        format_type=\"explanation\"\n",
        "    )\n",
        "\n",
        "    discussion_questions = moral_gen.generate_expanded_moral_content(\n",
        "        moral=result['moral'],\n",
        "        themes=result['themes'],\n",
        "        age=7,\n",
        "        format_type=\"discussion_questions\"\n",
        "    )\n",
        "\n",
        "    print(\"\\nMoral explanation for children:\")\n",
        "    print(explanation)\n",
        "\n",
        "    print(\"\\nDiscussion questions:\")\n",
        "    print(discussion_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "elcbI-MNVMSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bef4354-03b2-4f7e-bbbd-33757a0cd40a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gTTS\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gTTS) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gTTS) (8.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2025.1.31)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip install gTTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wjvE3d1ggZxy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80deea72-c572-46df-c6e7-42bbc35b7176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://542330c3cefd4898a0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://542330c3cefd4898a0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing StoryRAG...\n",
            "Initializing StoryRAG with FAISS...\n",
            "Loaded 4095 story sections\n",
            "Loaded FAISS index with 4095 story vectors\n",
            "Loaded 665 morals\n",
            "Loaded FAISS index with 665 moral vectors\n",
            "Loaded vocabulary for ages [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
            "Loaded word-to-age mapping with 31104 words\n",
            "StoryRAG initialization complete!\n",
            "Initializing StoryGenerator...\n",
            "Initializing DecisionPointGenerator...\n",
            "Initializing MoralGenerator...\n",
            "Successfully loaded morals dataset with 665 entries\n",
            "Generating long story about 'patience and trust' for age 12...\n",
            "Context length (1322 words) exceeds threshold (400). Summarizing...\n",
            "min dec 5\n",
            "1\n",
            "Context length (1456 words) exceeds threshold (400). Summarizing...\n",
            "min dec 5\n",
            "2\n",
            "Context length (1546 words) exceeds threshold (400). Summarizing...\n",
            "min dec 5\n",
            "3\n",
            "Context length (1635 words) exceeds threshold (400). Summarizing...\n",
            "min dec 5\n",
            "4\n",
            "Context length (1721 words) exceeds threshold (400). Summarizing...\n",
            "min dec 5\n",
            "5\n",
            "Initializing StoryRAG...\n",
            "Initializing StoryRAG with FAISS...\n",
            "Loaded 4095 story sections\n",
            "Loaded FAISS index with 4095 story vectors\n",
            "Loaded 665 morals\n",
            "Loaded FAISS index with 665 moral vectors\n",
            "Loaded vocabulary for ages [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
            "Loaded word-to-age mapping with 31104 words\n",
            "StoryRAG initialization complete!\n",
            "Initializing StoryGenerator...\n",
            "Initializing DecisionPointGenerator...\n",
            "Initializing MoralGenerator...\n",
            "Successfully loaded morals dataset with 665 entries\n",
            "Generating medium story about 'friendship and honesty' for age 7...\n",
            "Context length (461 words) exceeds threshold (400). Summarizing...\n",
            "min dec 3\n",
            "1\n",
            "Context length (541 words) exceeds threshold (400). Summarizing...\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://542330c3cefd4898a0.gradio.live\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import base64\n",
        "import tempfile\n",
        "from typing import List, Dict, Any, Optional\n",
        "import gradio as gr\n",
        "from gtts import gTTS\n",
        "import io\n",
        "\n",
        "\n",
        "GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\")\n",
        "\n",
        "# Check if required classes exist in the notebook scope\n",
        "def check_required_classes():\n",
        "    \"\"\"Check if the required classes exist in the current notebook scope\"\"\"\n",
        "    missing_classes = []\n",
        "    required_classes = [\n",
        "        (\"StoryGenerator\", \"story generation module\"),\n",
        "        (\"DecisionPointGenerator\", \"decision point module\"),\n",
        "        (\"BranchingLogicEngine\", \"branching logic engine\"),\n",
        "        (\"MoralGenerator\", \"moral generation system\"),\n",
        "        (\"StoryRAG\", \"story retrieval augmented generation\")\n",
        "    ]\n",
        "\n",
        "    for class_name, module_desc in required_classes:\n",
        "        if class_name not in globals():\n",
        "            missing_classes.append(f\"'{class_name}' from {module_desc}\")\n",
        "\n",
        "    if missing_classes:\n",
        "        error_message = \"The following classes are missing from the notebook environment:\\n\"\n",
        "        error_message += \"\\n\".join(missing_classes)\n",
        "        error_message += \"\\n\\nPlease make sure you've run all cells that define these classes.\"\n",
        "        raise NameError(error_message)\n",
        "\n",
        "    return \"✅ All required classes are available in the notebook environment.\"\n",
        "\n",
        "\n",
        "class InteractiveStorytellingSystem:\n",
        "    \"\"\"\n",
        "    Main class to integrate all components of the interactive storytelling system.\n",
        "\n",
        "    This integrates StoryGenerator, DecisionPointGenerator, BranchingLogicEngine,\n",
        "    and MoralGenerator using a real StoryRAG instance for retrieval.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str = GROQ_API_KEY, data_dir: str = \"data/processed\"):\n",
        "        \"\"\"\n",
        "        Initialize the complete storytelling system.\n",
        "\n",
        "        Args:\n",
        "            api_key: Groq API key for LLM access\n",
        "            data_dir: Directory containing processed data files\n",
        "        \"\"\"\n",
        "        self.api_key = api_key\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "        # Initialize the StoryRAG component for retrieval\n",
        "        print(\"Initializing StoryRAG...\")\n",
        "        self.story_rag = StoryRAG(data_dir=data_dir)\n",
        "\n",
        "        # Initialize the StoryGenerator\n",
        "        print(\"Initializing StoryGenerator...\")\n",
        "        self.story_generator = StoryGenerator(\n",
        "            api_key=api_key,\n",
        "            data_dir=data_dir\n",
        "        )\n",
        "\n",
        "        # Initialize the DecisionPointGenerator\n",
        "        print(\"Initializing DecisionPointGenerator...\")\n",
        "        self.decision_generator = DecisionPointGenerator(\n",
        "            api_key=api_key\n",
        "        )\n",
        "\n",
        "        # Initialize the MoralGenerator with the StoryRAG\n",
        "        print(\"Initializing MoralGenerator...\")\n",
        "        self.moral_generator = MoralGenerator(\n",
        "            api_key=api_key,\n",
        "            story_rag=self.story_rag,\n",
        "            processed_data_dir=data_dir\n",
        "        )\n",
        "\n",
        "        # This will be initialized when generating a story\n",
        "        self.branching_engine = None\n",
        "\n",
        "    def generate_story(\n",
        "        self,\n",
        "        age: int,\n",
        "        theme: str,\n",
        "        length: str = \"medium\",\n",
        "        characters: Optional[List[str]] = None\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Generate the initial story structure.\n",
        "\n",
        "        Args:\n",
        "            age: Target audience age\n",
        "            theme: Main story theme\n",
        "            length: \"short\", \"medium\", or \"long\"\n",
        "            characters: Optional list of character names\n",
        "\n",
        "        Returns:\n",
        "            Generated story data\n",
        "        \"\"\"\n",
        "        print(f\"Generating {length} story about '{theme}' for age {age}...\")\n",
        "\n",
        "        # Generate the initial story\n",
        "        story_data = self.story_generator.generate_story(\n",
        "            age=age,\n",
        "            theme=theme,\n",
        "            length=length,\n",
        "            characters=characters\n",
        "        )\n",
        "\n",
        "        return story_data\n",
        "\n",
        "    def initialize_story_engine(self, story_data: Dict[str, Any]) -> None:\n",
        "        # Initialize the branching engine, passing the API key\n",
        "        self.branching_engine = BranchingLogicEngine(\n",
        "            initial_segment=story_data[\"segments\"][0],\n",
        "            story_metadata={\n",
        "                \"title\": story_data[\"title\"],\n",
        "                \"age\": story_data[\"metadata\"][\"age\"],\n",
        "                \"theme\": story_data[\"metadata\"][\"theme\"],\n",
        "                \"length\": story_data[\"metadata\"][\"length\"],\n",
        "                \"characters\": story_data[\"metadata\"][\"characters\"],\n",
        "                \"api_key\": self.api_key # Pass API key\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Add remaining initial segments to the engine\n",
        "        current_node_id = self.branching_engine.root_node_id\n",
        "\n",
        "        for segment in story_data[\"segments\"][1:]:\n",
        "            # Add each segment as a continuation without choices\n",
        "            new_node_id = self.branching_engine.add_story_continuation(\n",
        "                choice_index=0,  # Default path\n",
        "                continuation_text=segment,\n",
        "                log_choice=False\n",
        "            )\n",
        "            current_node_id = new_node_id\n",
        "\n",
        "    def generate_decision_point(self, is_recovery_point: bool = False) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Generate a decision point for the current story node.\n",
        "\n",
        "        Returns:\n",
        "            Decision point data\n",
        "        \"\"\"\n",
        "        # Get the current story state\n",
        "        current_node = self.branching_engine.get_current_node()\n",
        "        story_context = self.branching_engine.get_full_story_text()\n",
        "        current_segment = current_node.segment\n",
        "\n",
        "        # Get metadata\n",
        "        metadata = self.branching_engine.story_metadata\n",
        "        story_length = metadata.get(\"length\", \"medium\")\n",
        "        age = metadata.get(\"age\", 8)\n",
        "        characters = metadata.get(\"characters\", [])\n",
        "\n",
        "        # Get position in story\n",
        "        path = self.branching_engine.path_history\n",
        "        segment_index = len(path) - 1\n",
        "        total_segments = max(10, int(len(path) * 1.5))  # Estimate total segments\n",
        "\n",
        "        # Generate decision point\n",
        "        decision_point = self.decision_generator.generate_decision_points(\n",
        "            story_segment=current_segment,\n",
        "            # story_context=story_context, # Remove this\n",
        "            branching_engine=self.branching_engine, # Pass the engine\n",
        "            character_names=characters,\n",
        "            age=age,\n",
        "            segment_index=segment_index,\n",
        "            total_segments=total_segments,\n",
        "            story_length=story_length,\n",
        "            is_recovery_point=is_recovery_point\n",
        "        )\n",
        "\n",
        "        # Add decision to current node\n",
        "        self.branching_engine.add_decision_to_current_node(decision_point)\n",
        "\n",
        "        return decision_point\n",
        "\n",
        "    def select_choice(self, choice_index: int) -> str:\n",
        "        \"\"\"\n",
        "        Process the user's choice and generate the next story segment.\n",
        "\n",
        "        Args:\n",
        "            choice_index: Index of the selected choice (0 or 1)\n",
        "\n",
        "        Returns:\n",
        "            The text of the next story segment\n",
        "        \"\"\"\n",
        "        # Get current state\n",
        "        current_node = self.branching_engine.get_current_node()\n",
        "        decision = current_node.decisions\n",
        "        # story_so_far = self.branching_engine.get_full_story_text() # Context now handled by engine\n",
        "\n",
        "        # Get metadata\n",
        "        metadata = self.branching_engine.story_metadata\n",
        "        age = metadata.get(\"age\", 8)\n",
        "        characters = metadata.get(\"characters\", [])\n",
        "\n",
        "        # Selected and unselected choices\n",
        "        selected_choice = decision[\"options\"][choice_index]\n",
        "        unselected_choice = decision[\"options\"][1 - choice_index]  # The other choice\n",
        "\n",
        "        # --- START FIX ---\n",
        "        # Determine if the selected path is a recovery path\n",
        "        # Check the metadata stored within the decision itself\n",
        "        decision_metadata = decision.get(\"metadata\", {})\n",
        "        needs_recovery = decision_metadata.get(\"needs_recovery\", False)\n",
        "        moral_choice_index = decision_metadata.get(\"moral_choice_index\", None)\n",
        "\n",
        "        # The path is a recovery path IF it was marked as needing recovery\n",
        "        # AND the user chose the *incorrect* moral option.\n",
        "        is_recovery_path = False\n",
        "        if needs_recovery and moral_choice_index is not None:\n",
        "             if choice_index != moral_choice_index:\n",
        "                 is_recovery_path = True\n",
        "        # --- END FIX ---\n",
        "\n",
        "\n",
        "        # Generate continuation based on choice\n",
        "        next_segment = self.decision_generator.generate_continuation_from_choice(\n",
        "            # story_so_far=story_so_far, # Remove this\n",
        "            branching_engine=self.branching_engine, # Pass the engine\n",
        "            decision_prompt=decision[\"decision_prompt\"],\n",
        "            selected_choice=selected_choice,\n",
        "            unselected_choice=unselected_choice,\n",
        "            character_names=characters,\n",
        "            age=age,\n",
        "            is_recovery_path=is_recovery_path # Pass the argument here\n",
        "        )\n",
        "\n",
        "        # Add continuation to the branching engine\n",
        "        self.branching_engine.add_story_continuation(\n",
        "            choice_index=choice_index,\n",
        "            continuation_text=next_segment,\n",
        "            metadata={\"selected_choice\": selected_choice}\n",
        "        )\n",
        "\n",
        "        return next_segment\n",
        "\n",
        "    def generate_story_moral(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Generate a moral for the complete story.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with the moral and related information\n",
        "        \"\"\"\n",
        "        # Get the full story text\n",
        "        story_text = self.branching_engine.get_full_story_text()\n",
        "\n",
        "        # Get metadata\n",
        "        metadata = self.branching_engine.story_metadata\n",
        "        age = metadata.get(\"age\", 8)\n",
        "        theme = metadata.get(\"theme\", \"\")\n",
        "        title = metadata.get(\"title\", \"\")\n",
        "\n",
        "        # Get choices made\n",
        "        choices_made = []\n",
        "        for choice in self.branching_engine.choice_history:\n",
        "            node_id = choice[\"from_node\"]\n",
        "            choice_index = choice[\"choice_index\"]\n",
        "\n",
        "            if node_id in self.branching_engine.nodes:\n",
        "                node = self.branching_engine.nodes[node_id]\n",
        "                if node.decisions and \"options\" in node.decisions:\n",
        "                    choices_made.append(node.decisions[\"options\"][choice_index])\n",
        "\n",
        "        # Generate moral\n",
        "        moral_data = self.moral_generator.generate_moral(\n",
        "            story_text=story_text,\n",
        "            choices_made=choices_made,\n",
        "            age=age,\n",
        "            theme=theme,\n",
        "            story_title=title\n",
        "        )\n",
        "\n",
        "        # Generate expanded content\n",
        "        explanation = self.moral_generator.generate_expanded_moral_content(\n",
        "            moral=moral_data[\"moral\"],\n",
        "            themes=moral_data[\"themes\"],\n",
        "            age=age,\n",
        "            format_type=\"explanation\"\n",
        "        )\n",
        "\n",
        "        discussion = self.moral_generator.generate_expanded_moral_content(\n",
        "            moral=moral_data[\"moral\"],\n",
        "            themes=moral_data[\"themes\"],\n",
        "            age=age,\n",
        "            format_type=\"discussion_questions\"\n",
        "        )\n",
        "\n",
        "        # Add to the result\n",
        "        moral_data[\"explanation\"] = explanation\n",
        "        moral_data[\"discussion_questions\"] = discussion\n",
        "\n",
        "        return moral_data\n",
        "\n",
        "\n",
        "# Text-to-Speech helper functions\n",
        "def generate_speech(text, lang='en', slow=False):\n",
        "    \"\"\"\n",
        "    Generate speech audio from text using gTTS\n",
        "\n",
        "    Args:\n",
        "        text: Text to convert to speech\n",
        "        lang: Language code (default: 'en')\n",
        "        slow: Whether to read the text slowly (default: False)\n",
        "\n",
        "    Returns:\n",
        "        Audio data as bytes\n",
        "    \"\"\"\n",
        "    try:\n",
        "        tts = gTTS(text=text, lang=lang, slow=slow)\n",
        "        audio_data = io.BytesIO()\n",
        "        tts.write_to_fp(audio_data)\n",
        "        audio_data.seek(0)\n",
        "        return audio_data.read()\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating speech: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_audio_html(audio_data, segment_id):\n",
        "    \"\"\"\n",
        "    Convert audio data to HTML audio element\n",
        "\n",
        "    Args:\n",
        "        audio_data: Audio data as bytes\n",
        "        segment_id: Unique identifier for the audio element\n",
        "\n",
        "    Returns:\n",
        "        HTML audio element as string\n",
        "    \"\"\"\n",
        "    if audio_data is None:\n",
        "        return \"\"\n",
        "\n",
        "    # Convert audio data to base64\n",
        "    audio_b64 = base64.b64encode(audio_data).decode(\"utf-8\")\n",
        "\n",
        "    # Create HTML audio element\n",
        "    audio_html = f\"\"\"\n",
        "    <div class=\"audio-player\" style=\"margin: 5px 0;\">\n",
        "        <audio id=\"audio-{segment_id}\" controls>\n",
        "            <source src=\"data:audio/mp3;base64,{audio_b64}\" type=\"audio/mp3\">\n",
        "            Your browser does not support the audio element.\n",
        "        </audio>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    return audio_html\n",
        "\n",
        "\n",
        "# Helper functions for formatting HTML\n",
        "def format_title(title):\n",
        "    \"\"\"Format story title as HTML\"\"\"\n",
        "    # Generate speech for title\n",
        "    audio_data = generate_speech(title)\n",
        "    audio_html = get_audio_html(audio_data, \"title\")\n",
        "\n",
        "    return f\"\"\"\n",
        "    <h1 style='color: #2E86C1; text-align: center'>{title}</h1>\n",
        "    <div style='text-align: center;'>{audio_html}</div>\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "def format_segment(segment, index=None):\n",
        "    \"\"\"Format story segment as HTML with audio player\"\"\"\n",
        "    # Generate unique ID for this segment\n",
        "    segment_id = f\"segment-{index}\" if index is not None else f\"segment-{random.randint(1000, 9999)}\"\n",
        "\n",
        "    # Generate speech for segment\n",
        "    audio_data = generate_speech(segment)\n",
        "    audio_html = get_audio_html(audio_data, segment_id)\n",
        "\n",
        "    if index is not None:\n",
        "        return f\"\"\"\n",
        "        <div style='background-color: #EBF5FB; border-left: 4px solid #3498DB; padding: 10px; margin: 10px 0;'>\n",
        "            <h3>Part {index}</h3>\n",
        "            <p>{segment}</p>\n",
        "            {audio_html}\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    else:\n",
        "        return f\"\"\"\n",
        "        <div style='background-color: #EBF5FB; border-left: 4px solid #3498DB; padding: 10px; margin: 10px 0;'>\n",
        "            <p>{segment}</p>\n",
        "            {audio_html}\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "def format_decision(decision_prompt, options):\n",
        "    \"\"\"Format decision prompt as HTML with audio\"\"\"\n",
        "    # Generate speech for decision prompt\n",
        "    audio_data = generate_speech(decision_prompt)\n",
        "    audio_html = get_audio_html(audio_data, f\"decision-{random.randint(1000, 9999)}\")\n",
        "\n",
        "    html = f\"\"\"\n",
        "    <div style='background-color: #FEF9E7; border-left: 4px solid #F1C40F; padding: 10px; margin: 10px 0;'>\n",
        "        <h3>Decision Time!</h3>\n",
        "        <p>{decision_prompt}</p>\n",
        "        {audio_html}\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    for i, option in enumerate(options):\n",
        "        option_text = f\"Option {i+1}: {option['choice_text']}. {option['consequence_summary']}\"\n",
        "        option_audio = get_audio_html(generate_speech(option_text), f\"option-{i+1}-{random.randint(1000, 9999)}\")\n",
        "\n",
        "        html += f\"\"\"\n",
        "        <div style='margin: 10px 0;'>\n",
        "            <b>Option {i+1}:</b> {option['choice_text']}<br>\n",
        "            <i>{option['consequence_summary']}</i>\n",
        "            {option_audio}\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "    return html\n",
        "\n",
        "def format_moral(moral_data):\n",
        "    \"\"\"Format moral and related content as HTML with audio\"\"\"\n",
        "    # Get the clean, single moral text\n",
        "    moral_text = moral_data['moral']\n",
        "\n",
        "    # Generate speech for moral and supporting content\n",
        "    moral_audio = get_audio_html(generate_speech(moral_text), \"moral\")\n",
        "    explanation_audio = get_audio_html(generate_speech(moral_data['explanation']), \"explanation\")\n",
        "\n",
        "    # Format the discussion questions with line breaks\n",
        "    formatted_discussion = moral_data['discussion_questions']\n",
        "    formatted_discussion = formatted_discussion.replace('*', '')\n",
        "    formatted_discussion = formatted_discussion.replace(\"1. \", \"<br>1. \")\n",
        "    formatted_discussion = formatted_discussion.replace(\"2. \", \"<br>2. \")\n",
        "    formatted_discussion = formatted_discussion.replace(\"3. \", \"<br>3. \")\n",
        "    if formatted_discussion.startswith(\"<br>\"):\n",
        "        formatted_discussion = formatted_discussion[4:]\n",
        "\n",
        "    discussion_audio = get_audio_html(generate_speech(moral_data['discussion_questions']), \"discussion\")\n",
        "\n",
        "    html = f\"\"\"\n",
        "    <div style='background-color: #EAFAF1; border-left: 4px solid #27AE60; padding: 15px; margin: 15px 0;'>\n",
        "        <h2 style='color: #27AE60;'>The Moral of the Story</h2>\n",
        "        <p style='font-size: 1.2em; font-style: italic;'>{moral_text}</p>\n",
        "        {moral_audio}\n",
        "    </div>\n",
        "\n",
        "    <div style='background-color: #F4F6F6; padding: 10px; margin: 10px 0;'>\n",
        "        <h3>Explanation for Children</h3>\n",
        "        <p>{moral_data['explanation']}</p>\n",
        "        {explanation_audio}\n",
        "    </div>\n",
        "\n",
        "    <div style='background-color: #F4F6F6; padding: 10px; margin: 10px 0;'>\n",
        "        <h3>Discussion Questions</h3>\n",
        "        <p>{formatted_discussion}</p>\n",
        "        {discussion_audio}\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    return html\n",
        "\n",
        "\n",
        "# Main Gradio interface for the interactive storytelling system\n",
        "def create_gradio_interface():\n",
        "    # Check if required classes exist\n",
        "    try:\n",
        "        check_message = check_required_classes()\n",
        "    except NameError as e:\n",
        "        check_message = str(e)\n",
        "\n",
        "    # Initialize story state dictionary\n",
        "    state = {\n",
        "        'system': None,\n",
        "        'story_data': None,\n",
        "        'story_html': '',\n",
        "        'current_segment_index': 0,\n",
        "        'segments_shown': 0,\n",
        "        'decision_shown': False,\n",
        "        'story_finished': False,\n",
        "        'error_message': check_message if 'missing' in check_message else None\n",
        "    }\n",
        "\n",
        "    # Generate story function\n",
        "    def generate_story(age, theme, length, characters):\n",
        "        # Check for errors\n",
        "        if state['error_message']:\n",
        "            return state['error_message'], gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "        try:\n",
        "            # Reset state\n",
        "            state['story_html'] = ''\n",
        "            state['current_segment_index'] = 0\n",
        "            state['segments_shown'] = 0\n",
        "            state['decision_shown'] = False\n",
        "            state['story_finished'] = False\n",
        "\n",
        "            # Process characters\n",
        "            character_list = [char.strip() for char in characters.split(',') if char.strip()]\n",
        "\n",
        "            # Create system (no more mock objects)\n",
        "            system = InteractiveStorytellingSystem(api_key=GROQ_API_KEY)\n",
        "            state['system'] = system\n",
        "\n",
        "            # Generate story\n",
        "            story_data = system.generate_story(\n",
        "                age=age,\n",
        "                theme=theme,\n",
        "                length=length,\n",
        "                characters=character_list\n",
        "            )\n",
        "            state['story_data'] = story_data\n",
        "\n",
        "            # Initialize story engine\n",
        "            system.initialize_story_engine(story_data)\n",
        "\n",
        "            # Start with title and first segment\n",
        "            state['story_html'] = format_title(story_data['title'])\n",
        "            state['story_html'] += format_segment(story_data['segments'][0], 1)\n",
        "            state['segments_shown'] = 1\n",
        "            state['current_segment_index'] = 1\n",
        "\n",
        "            # Show continue button\n",
        "            return state['story_html'], gr.update(visible=True), gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error generating story: {str(e)}\", gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "    # Continue story function\n",
        "    def continue_story():\n",
        "        system = state['system']\n",
        "        story_data = state['story_data']\n",
        "\n",
        "        try:\n",
        "            # If we're still showing initial segments\n",
        "            if state['segments_shown'] < len(story_data['segments']):\n",
        "                # Show next segment\n",
        "                next_index = state['segments_shown']\n",
        "                state['story_html'] += format_segment(story_data['segments'][next_index], next_index + 1)\n",
        "                state['segments_shown'] += 1\n",
        "                state['current_segment_index'] += 1\n",
        "\n",
        "                # If we've shown all segments, create first decision point\n",
        "                if state['segments_shown'] >= len(story_data['segments']) and not state['decision_shown']:\n",
        "                    # Generate first decision point\n",
        "                    decision = system.generate_decision_point()\n",
        "                    state['story_html'] += format_decision(decision['decision_prompt'], decision['options'])\n",
        "                    state['decision_shown'] = True\n",
        "\n",
        "                    # Show choice buttons\n",
        "                    return state['story_html'], gr.update(visible=False), gr.update(visible=True), gr.update(visible=False)\n",
        "                else:\n",
        "                    # Still showing segments\n",
        "                    return state['story_html'], gr.update(visible=True), gr.update(visible=False), gr.update(visible=False)\n",
        "            else:\n",
        "                # Check if we need to show another decision point\n",
        "                if not state['decision_shown'] and not state['story_finished']:\n",
        "                    # Generate decision point\n",
        "                    decision = system.generate_decision_point()\n",
        "                    state['story_html'] += format_decision(decision['decision_prompt'], decision['options'])\n",
        "                    state['decision_shown'] = True\n",
        "\n",
        "                    # Show choice buttons\n",
        "                    return state['story_html'], gr.update(visible=False), gr.update(visible=True), gr.update(visible=False)\n",
        "                else:\n",
        "                    # Continue button was clicked but nothing to do\n",
        "                    return state['story_html'], gr.update(visible=True), gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"{state['story_html']}<div style='color: red;'>Error continuing story: {str(e)}</div>\", gr.update(visible=True), gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "    # Make choice function\n",
        "    def make_choice(choice_num):\n",
        "        system = state['system']\n",
        "        choice_index = choice_num - 1  # Convert to 0-indexed\n",
        "        metadata = system.branching_engine.story_metadata\n",
        "        story_length = metadata.get(\"length\", \"medium\")\n",
        "\n",
        "        # Get minimum required decisions based on story length\n",
        "        min_decisions = system.decision_generator.get_decision_point_count(story_length)\n",
        "        print(\"min dec\", min_decisions)\n",
        "\n",
        "        try:\n",
        "            # Generate continuation based on choice\n",
        "            next_segment = system.select_choice(choice_index)\n",
        "\n",
        "            # Display the continuation\n",
        "            state['current_segment_index'] += 1\n",
        "            state['story_html'] += format_segment(next_segment, state['current_segment_index'])\n",
        "\n",
        "            # Reset decision state\n",
        "            state['decision_shown'] = False\n",
        "\n",
        "            # Determine if story should end\n",
        "            decision_count = len(system.branching_engine.choice_history)\n",
        "            print(decision_count)\n",
        "\n",
        "            # --- MODIFIED ENDING LOGIC ---\n",
        "            should_end = False\n",
        "            if decision_count < min_decisions:\n",
        "                # Cannot end yet, minimum decisions not met\n",
        "                should_end = False\n",
        "            else:\n",
        "                # Minimum decisions met, apply other ending conditions\n",
        "                # End if not in recovery and segment count is high OR randomly based on length\n",
        "                should_end = (\n",
        "                    not system.decision_generator.needs_recovery and # <--- CORRECTED LINE\n",
        "                    (state['current_segment_index'] >= 10) or # Adjusted threshold example\n",
        "                     (state['current_segment_index'] > min_decisions*2) # Adjusted randomness\n",
        "                )\n",
        "            # --- END OF MODIFIED LOGIC ---\n",
        "\n",
        "\n",
        "            if should_end:\n",
        "                # End the story\n",
        "                state['story_finished'] = True\n",
        "                state['story_html'] += \"<h3>The End</h3>\"\n",
        "\n",
        "                # Show finish button\n",
        "                return state['story_html'], gr.update(visible=False), gr.update(visible=False), gr.update(visible=True)\n",
        "            else:\n",
        "                # Continue the story (needs another decision point)\n",
        "                # Show the continue button to trigger the next decision point generation\n",
        "                return state['story_html'], gr.update(visible=True), gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"{state['story_html']}<div style='color: red;'>Error processing choice: {str(e)}</div>\", gr.update(visible=True), gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "    # Finish story function\n",
        "    def finish_story():\n",
        "        system = state['system']\n",
        "\n",
        "        try:\n",
        "            # Generate and display moral\n",
        "            moral_data = system.generate_story_moral()\n",
        "            state['story_html'] += format_moral(moral_data)\n",
        "\n",
        "            # Show create new story button (create a refresh button)\n",
        "            return state['story_html'], gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"{state['story_html']}<div style='color: red;'>Error generating moral: {str(e)}</div>\", gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "    # Create Gradio interface\n",
        "    with gr.Blocks(title=\"Interactive Storytelling System with Text-to-Speech\") as demo:\n",
        "        gr.Markdown(\"# Interactive Storytelling System with Text-to-Speech\")\n",
        "        gr.Markdown(\"This system generates interactive stories with choices, morals, and audio narration for children.\")\n",
        "\n",
        "        # Check for required classes\n",
        "        if 'error_message' in state and state['error_message']:\n",
        "            gr.Markdown(f\"⚠ {state['error_message']}\", elem_id=\"error-message\")\n",
        "\n",
        "        # Story generation form\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                age = gr.Slider(minimum=4, maximum=12, value=8, step=1, label=\"Age\")\n",
        "                length = gr.Dropdown(choices=[\"short\", \"medium\", \"long\"], value=\"medium\", label=\"Story Length\")\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                theme = gr.Textbox(label=\"Theme\", placeholder=\"e.g., friendship and adventure\", value=\"friendship and adventure\")\n",
        "                characters = gr.Textbox(label=\"Characters (comma separated)\", placeholder=\"e.g., Luna the rabbit, Max the squirrel\", value=\"Luna the rabbit, Max the squirrel\")\n",
        "\n",
        "        generate_btn = gr.Button(\"Generate Story\", variant=\"primary\")\n",
        "\n",
        "        # Story display and interaction\n",
        "        story_display = gr.HTML(label=\"Story\")\n",
        "        continue_btn = gr.Button(\"Continue\", visible=False)\n",
        "\n",
        "        with gr.Row(visible=False) as choice_row:\n",
        "            choice1_btn = gr.Button(\"Choose Option 1\", variant=\"secondary\")\n",
        "            choice2_btn = gr.Button(\"Choose Option 2\", variant=\"secondary\")\n",
        "\n",
        "        finish_btn = gr.Button(\"See the Moral of the Story\", visible=False, variant=\"primary\")\n",
        "\n",
        "        # Add a restart button for creating a new story after finishing\n",
        "        restart_btn = gr.Button(\"Create New Story\", visible=False, variant=\"primary\")\n",
        "\n",
        "        # Connect components\n",
        "        generate_btn.click(\n",
        "            generate_story,\n",
        "            inputs=[age, theme, length, characters],\n",
        "            outputs=[story_display, continue_btn, choice_row, finish_btn]\n",
        "        )\n",
        "\n",
        "        continue_btn.click(\n",
        "            continue_story,\n",
        "            outputs=[story_display, continue_btn, choice_row, finish_btn]\n",
        "        )\n",
        "\n",
        "        choice1_btn.click(\n",
        "            lambda: make_choice(1),\n",
        "            outputs=[story_display, continue_btn, choice_row, finish_btn]\n",
        "        )\n",
        "\n",
        "        choice2_btn.click(\n",
        "            lambda: make_choice(2),\n",
        "            outputs=[story_display, continue_btn, choice_row, finish_btn]\n",
        "        )\n",
        "\n",
        "        finish_btn.click(\n",
        "            finish_story,\n",
        "            outputs=[story_display, continue_btn, choice_row, finish_btn]\n",
        "        )\n",
        "\n",
        "        # Restart button reloads the page to start fresh\n",
        "        restart_btn.click(\n",
        "            fn=lambda: None,\n",
        "            inputs=None,\n",
        "            outputs=None,\n",
        "            js=\"window.location.reload()\"\n",
        "        )\n",
        "\n",
        "        # After finish_story is called, show the restart button\n",
        "        finish_btn.click(\n",
        "            lambda: gr.update(visible=True),\n",
        "            None,\n",
        "            restart_btn\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "\n",
        "# Run this in Google Colab\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Make sure gTTS is installed\n",
        "        try:\n",
        "            import gtts\n",
        "        except ImportError:\n",
        "            print(\"Installing gTTS...\")\n",
        "            import pip\n",
        "            pip.main(['install', 'gtts'])\n",
        "            import gtts\n",
        "\n",
        "        # Launch the interface\n",
        "        demo = create_gradio_interface()\n",
        "        demo.launch(debug=True, share=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting up Gradio interface: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xba0av0Ejy5S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUu_jOvIUntx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ac49a221a5e74a9cb4e3b9b348f02d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a9387fa10f54daeba7a2fd5150fbdc3",
              "IPY_MODEL_83e797bf73d048418d3fa32e81c9757d",
              "IPY_MODEL_e6fd7d7a6ddc4110a99d0a7e00c20f82"
            ],
            "layout": "IPY_MODEL_13ef3a2a4f5f4a77b75608a6fe0d81ef"
          }
        },
        "7a9387fa10f54daeba7a2fd5150fbdc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31ed1a99ac8a418ba94221e7b4cd15c1",
            "placeholder": "​",
            "style": "IPY_MODEL_87b077ae759d47d0a404498fc4101354",
            "value": "modules.json: 100%"
          }
        },
        "83e797bf73d048418d3fa32e81c9757d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2b91c5e02f34d9ebb46834511542356",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd0e3221fe1c483a8a415537aa85a700",
            "value": 349
          }
        },
        "e6fd7d7a6ddc4110a99d0a7e00c20f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_494c29446a0a44799476b074f2735262",
            "placeholder": "​",
            "style": "IPY_MODEL_03006103c30d4bf89145710dc3923f33",
            "value": " 349/349 [00:00&lt;00:00, 21.9kB/s]"
          }
        },
        "13ef3a2a4f5f4a77b75608a6fe0d81ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31ed1a99ac8a418ba94221e7b4cd15c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87b077ae759d47d0a404498fc4101354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2b91c5e02f34d9ebb46834511542356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd0e3221fe1c483a8a415537aa85a700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "494c29446a0a44799476b074f2735262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03006103c30d4bf89145710dc3923f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3bd745d85c748b9abfc8f2368d8de48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b51fad1df7d495ba0856e4ae8ece12e",
              "IPY_MODEL_99e974daf6c844c798afe4eaca7d6362",
              "IPY_MODEL_cbd6f33314614dfc960f9fd8fb54087f"
            ],
            "layout": "IPY_MODEL_c6348de1a79c44fc96d674ce4d4d0c8e"
          }
        },
        "6b51fad1df7d495ba0856e4ae8ece12e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04d163af4c2c4f71bd6357d5bca7964a",
            "placeholder": "​",
            "style": "IPY_MODEL_12713567368348afad0dec139c7b653e",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "99e974daf6c844c798afe4eaca7d6362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35d63f322cf14e73aed5f41e549ecd7b",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b09b69cd383d4a5087234241f94b254f",
            "value": 116
          }
        },
        "cbd6f33314614dfc960f9fd8fb54087f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75f940e77fb642ef9ce35972761911c4",
            "placeholder": "​",
            "style": "IPY_MODEL_9da81c461cee4047b9ac0500e73cd9fe",
            "value": " 116/116 [00:00&lt;00:00, 11.2kB/s]"
          }
        },
        "c6348de1a79c44fc96d674ce4d4d0c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d163af4c2c4f71bd6357d5bca7964a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12713567368348afad0dec139c7b653e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35d63f322cf14e73aed5f41e549ecd7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b09b69cd383d4a5087234241f94b254f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75f940e77fb642ef9ce35972761911c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9da81c461cee4047b9ac0500e73cd9fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b958f97061c4c6391ce603d25e94646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1afa6ce3c09d49fab25e23ad1584b44f",
              "IPY_MODEL_9e91495bc2df4c3a8350eadef4830f5d",
              "IPY_MODEL_4d2f23db914a44419f5088cb4fafe2b8"
            ],
            "layout": "IPY_MODEL_444bd13a851f40c0b750eacf059a9156"
          }
        },
        "1afa6ce3c09d49fab25e23ad1584b44f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f122716850647b7b3683acb851af8eb",
            "placeholder": "​",
            "style": "IPY_MODEL_39ac37658af3435190716b58e8a95434",
            "value": "README.md: 100%"
          }
        },
        "9e91495bc2df4c3a8350eadef4830f5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_394b57b467514d77bf172dda56f0e044",
            "max": 10454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_889a95b9dbff436c9afe4310c3b70fb8",
            "value": 10454
          }
        },
        "4d2f23db914a44419f5088cb4fafe2b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d7917aa28664017aa1562c50b9c6f60",
            "placeholder": "​",
            "style": "IPY_MODEL_05f0df7be3734eeeaf45591781711baf",
            "value": " 10.5k/10.5k [00:00&lt;00:00, 1.02MB/s]"
          }
        },
        "444bd13a851f40c0b750eacf059a9156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f122716850647b7b3683acb851af8eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39ac37658af3435190716b58e8a95434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "394b57b467514d77bf172dda56f0e044": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "889a95b9dbff436c9afe4310c3b70fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d7917aa28664017aa1562c50b9c6f60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05f0df7be3734eeeaf45591781711baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8e22a19169f41559479fe35c903e129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49b43bb044c642469f80623c605467dd",
              "IPY_MODEL_249d21d1b12f4e16be3b231a4caf09e3",
              "IPY_MODEL_da48ec8807614a0c9a6fd93d588a9917"
            ],
            "layout": "IPY_MODEL_799cf6034e8e41a99ffb4d8624cccf9f"
          }
        },
        "49b43bb044c642469f80623c605467dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15fd8798eadb4bf4843b2054b546dc0d",
            "placeholder": "​",
            "style": "IPY_MODEL_79358e5d8e234c45bd6a22005d5cf08c",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "249d21d1b12f4e16be3b231a4caf09e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e46986340594978af47d11b07c199bf",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24aa5805f9144c179cb1099c0afa437e",
            "value": 53
          }
        },
        "da48ec8807614a0c9a6fd93d588a9917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_075ab3734a584c8397d207697926f196",
            "placeholder": "​",
            "style": "IPY_MODEL_b64a23a93d7d492ea8dffd33f0026a38",
            "value": " 53.0/53.0 [00:00&lt;00:00, 5.24kB/s]"
          }
        },
        "799cf6034e8e41a99ffb4d8624cccf9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15fd8798eadb4bf4843b2054b546dc0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79358e5d8e234c45bd6a22005d5cf08c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e46986340594978af47d11b07c199bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24aa5805f9144c179cb1099c0afa437e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "075ab3734a584c8397d207697926f196": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b64a23a93d7d492ea8dffd33f0026a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59975b2ce11b4742a953a2e16bd19499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8be928423b443a299458c4c435f256c",
              "IPY_MODEL_ae40a93e0b7e4e1f8e14358294258267",
              "IPY_MODEL_9b14985e7d5f46938d6587f50618224e"
            ],
            "layout": "IPY_MODEL_b964e1ccd867400d9d24021782e4e28a"
          }
        },
        "f8be928423b443a299458c4c435f256c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d98a8f175bd84565957b30ac2731a435",
            "placeholder": "​",
            "style": "IPY_MODEL_004f945849ca4f89a253fddc5e4e1ccb",
            "value": "config.json: 100%"
          }
        },
        "ae40a93e0b7e4e1f8e14358294258267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ac9be9b047e4a5c8697ee46264e796f",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd78d949763649579fb4263fd9714dfd",
            "value": 612
          }
        },
        "9b14985e7d5f46938d6587f50618224e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78892ca2c42e43f5b2159f52ba71d54f",
            "placeholder": "​",
            "style": "IPY_MODEL_f01a3456b7974bcabd56098e0870e745",
            "value": " 612/612 [00:00&lt;00:00, 44.4kB/s]"
          }
        },
        "b964e1ccd867400d9d24021782e4e28a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d98a8f175bd84565957b30ac2731a435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "004f945849ca4f89a253fddc5e4e1ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ac9be9b047e4a5c8697ee46264e796f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd78d949763649579fb4263fd9714dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78892ca2c42e43f5b2159f52ba71d54f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f01a3456b7974bcabd56098e0870e745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "422f9721167043af875de535be9272f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1d2f7f44415462390d17e838b1aa4ae",
              "IPY_MODEL_8844c9cfe93748fc82f6630ca9836754",
              "IPY_MODEL_4fad3bc985e04458ad9944775ed35618"
            ],
            "layout": "IPY_MODEL_6de4a140214c4487a522b48e8255c29f"
          }
        },
        "b1d2f7f44415462390d17e838b1aa4ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eddb382ef4b1478bacd01baf432cf8d5",
            "placeholder": "​",
            "style": "IPY_MODEL_d22cedc9bff8468da2adb90b2c966c85",
            "value": "model.safetensors: 100%"
          }
        },
        "8844c9cfe93748fc82f6630ca9836754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4642c72671148959b93977763cab540",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4804fdd26734fb48b81034b9b49ad2b",
            "value": 90868376
          }
        },
        "4fad3bc985e04458ad9944775ed35618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f6f6e73473d4272aa7da6ca83caeaea",
            "placeholder": "​",
            "style": "IPY_MODEL_6a3e503f5cea48a38f9f5edcfe2694bf",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 75.0MB/s]"
          }
        },
        "6de4a140214c4487a522b48e8255c29f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eddb382ef4b1478bacd01baf432cf8d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d22cedc9bff8468da2adb90b2c966c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4642c72671148959b93977763cab540": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4804fdd26734fb48b81034b9b49ad2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f6f6e73473d4272aa7da6ca83caeaea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a3e503f5cea48a38f9f5edcfe2694bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e9ab2f9fd274d6da2154c55412979e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e59973e8d1214c7a95b7a6f9d0cb9846",
              "IPY_MODEL_c94246e9671846f9b0dd38c0da276b25",
              "IPY_MODEL_79c1d0b581ac4eaf92ff900940bfb3c1"
            ],
            "layout": "IPY_MODEL_8265e06f8ae74b8c983c283da7209680"
          }
        },
        "e59973e8d1214c7a95b7a6f9d0cb9846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb9c3317ef314cc89184a87a13ec2830",
            "placeholder": "​",
            "style": "IPY_MODEL_1add1aaa9fd44ac1a0709ed87c9d6181",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c94246e9671846f9b0dd38c0da276b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1038a691352440f29338905f4c411fe7",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d2045a3c6774b0ca9effef27d5a82e7",
            "value": 350
          }
        },
        "79c1d0b581ac4eaf92ff900940bfb3c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_604b13ea22ec4fc0a1b57fbfc9e2e8be",
            "placeholder": "​",
            "style": "IPY_MODEL_cf0a335fa850436eabeb7b5ba7ce9ed7",
            "value": " 350/350 [00:00&lt;00:00, 35.3kB/s]"
          }
        },
        "8265e06f8ae74b8c983c283da7209680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb9c3317ef314cc89184a87a13ec2830": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1add1aaa9fd44ac1a0709ed87c9d6181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1038a691352440f29338905f4c411fe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d2045a3c6774b0ca9effef27d5a82e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "604b13ea22ec4fc0a1b57fbfc9e2e8be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf0a335fa850436eabeb7b5ba7ce9ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c29f44966984a178b74fda46327d3b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8f39e62adc1423b9f92483a16d55d35",
              "IPY_MODEL_54a28ba794e14847a8a0470e05629199",
              "IPY_MODEL_2d5232e2937849e98f8e9d8c98e5b497"
            ],
            "layout": "IPY_MODEL_ca4e3e1d52774bad8e839b77c965c4de"
          }
        },
        "b8f39e62adc1423b9f92483a16d55d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7446700e225477288a36efc2046a300",
            "placeholder": "​",
            "style": "IPY_MODEL_f14014573a574344b8a59029b9c78bfc",
            "value": "vocab.txt: 100%"
          }
        },
        "54a28ba794e14847a8a0470e05629199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_caccbd32adc442298038fcf9a4d8fc87",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7eed0fcc9c84c6aab9fb605c0cd1362",
            "value": 231508
          }
        },
        "2d5232e2937849e98f8e9d8c98e5b497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_088ce609db11405183e7256aee02b0e1",
            "placeholder": "​",
            "style": "IPY_MODEL_7aa6eab482ab40cf99b0762f73e15a0f",
            "value": " 232k/232k [00:00&lt;00:00, 2.44MB/s]"
          }
        },
        "ca4e3e1d52774bad8e839b77c965c4de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7446700e225477288a36efc2046a300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f14014573a574344b8a59029b9c78bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "caccbd32adc442298038fcf9a4d8fc87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7eed0fcc9c84c6aab9fb605c0cd1362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "088ce609db11405183e7256aee02b0e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aa6eab482ab40cf99b0762f73e15a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b02f6a02fad4ceaa96f614bffb86826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3e12dde75fa4fda8e79e7906ab79f2b",
              "IPY_MODEL_506f76cbd713444c95a1402a0e8d5b07",
              "IPY_MODEL_7802ec6e8f7c4fc082d53cd0203daee3"
            ],
            "layout": "IPY_MODEL_feadb7d9a84f40a8a38b071e1e778944"
          }
        },
        "e3e12dde75fa4fda8e79e7906ab79f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cca9d99fb011462c9d9d3f283d302260",
            "placeholder": "​",
            "style": "IPY_MODEL_be0bf657e0d74035b97808b058b5ab77",
            "value": "tokenizer.json: 100%"
          }
        },
        "506f76cbd713444c95a1402a0e8d5b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fef2348b1cef481e819e64b9ac80e19e",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_180e97d0014e4126912181f0ccf9a78f",
            "value": 466247
          }
        },
        "7802ec6e8f7c4fc082d53cd0203daee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_394813e5c6e74f88bbd435efaba5fbb8",
            "placeholder": "​",
            "style": "IPY_MODEL_237e59eda1294ab7809d6d8ff488a529",
            "value": " 466k/466k [00:00&lt;00:00, 863kB/s]"
          }
        },
        "feadb7d9a84f40a8a38b071e1e778944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cca9d99fb011462c9d9d3f283d302260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be0bf657e0d74035b97808b058b5ab77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fef2348b1cef481e819e64b9ac80e19e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "180e97d0014e4126912181f0ccf9a78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "394813e5c6e74f88bbd435efaba5fbb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "237e59eda1294ab7809d6d8ff488a529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cbca838c3e746f0a2332a465f45ad9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_142a380256c84c368a8ecb5d1905b37c",
              "IPY_MODEL_3fd8b59ab81843848b306f8d34623ccb",
              "IPY_MODEL_b6014b646dff4c8d8cd80eb3eeca28f4"
            ],
            "layout": "IPY_MODEL_774e3eb27cd0434fbf21753b681196ed"
          }
        },
        "142a380256c84c368a8ecb5d1905b37c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8e2520616634830a4bfdf7afda635d8",
            "placeholder": "​",
            "style": "IPY_MODEL_959d7def5bb847e2947ea1deedd2dfe6",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "3fd8b59ab81843848b306f8d34623ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fba7deec704341ebae4623904f2a661f",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1cf41ec1e3a45b5aed2256bd363275a",
            "value": 112
          }
        },
        "b6014b646dff4c8d8cd80eb3eeca28f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c217b2774b347788a8b744ccaa6f6c4",
            "placeholder": "​",
            "style": "IPY_MODEL_6e8b0a840c7547cf8a8daafe885e7542",
            "value": " 112/112 [00:00&lt;00:00, 6.72kB/s]"
          }
        },
        "774e3eb27cd0434fbf21753b681196ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8e2520616634830a4bfdf7afda635d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "959d7def5bb847e2947ea1deedd2dfe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fba7deec704341ebae4623904f2a661f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1cf41ec1e3a45b5aed2256bd363275a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c217b2774b347788a8b744ccaa6f6c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e8b0a840c7547cf8a8daafe885e7542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6c48ac4e0c5451c94fa3c8ec41a1e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_149bb04e1f444f94898b48f38167c9b5",
              "IPY_MODEL_52161732f8d84164b4678e9ec6585653",
              "IPY_MODEL_f3bb0a6153944692a2c26f040ae7458c"
            ],
            "layout": "IPY_MODEL_74d864efb2404e47a077cc2d56c5f5f5"
          }
        },
        "149bb04e1f444f94898b48f38167c9b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5969fa5c5e794b948575e5d468d9b397",
            "placeholder": "​",
            "style": "IPY_MODEL_68c6f3d4b5aa4f4caa5514f7d389df7c",
            "value": "config.json: 100%"
          }
        },
        "52161732f8d84164b4678e9ec6585653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b6bf8cf4f644b848f26c71f55cfc225",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1f8064486544f62a7c315320caae3c5",
            "value": 190
          }
        },
        "f3bb0a6153944692a2c26f040ae7458c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44cc8f363e704eb1a559a0ae8a06c317",
            "placeholder": "​",
            "style": "IPY_MODEL_6009a533065d4a3bb48a9507f9a81082",
            "value": " 190/190 [00:00&lt;00:00, 8.64kB/s]"
          }
        },
        "74d864efb2404e47a077cc2d56c5f5f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5969fa5c5e794b948575e5d468d9b397": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68c6f3d4b5aa4f4caa5514f7d389df7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b6bf8cf4f644b848f26c71f55cfc225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1f8064486544f62a7c315320caae3c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44cc8f363e704eb1a559a0ae8a06c317": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6009a533065d4a3bb48a9507f9a81082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81b987227ed74014bca9536b85938af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e8b8b72cc1c44168a7f462ede185687",
              "IPY_MODEL_dc5582fb320b45f08413467b7675d5a0",
              "IPY_MODEL_8e281757c5f748e2ba5f128195f485f5"
            ],
            "layout": "IPY_MODEL_3aef0723206b4558837be3a010ba4887"
          }
        },
        "7e8b8b72cc1c44168a7f462ede185687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_345e213f3ec94cf49611fca1ad04d8f7",
            "placeholder": "​",
            "style": "IPY_MODEL_a0a16bfbab824622b229e151b3caadae",
            "value": "Batches: 100%"
          }
        },
        "dc5582fb320b45f08413467b7675d5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b94fad9a3e014228997fb29de5cba26e",
            "max": 128,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f569e30338364cc5b026361cd21bb912",
            "value": 128
          }
        },
        "8e281757c5f748e2ba5f128195f485f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40c8f34b3f1d4e24be527ca16ccfb2ab",
            "placeholder": "​",
            "style": "IPY_MODEL_06e951e7f6db4628aa91f35249f50ad8",
            "value": " 128/128 [00:08&lt;00:00, 33.49it/s]"
          }
        },
        "3aef0723206b4558837be3a010ba4887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "345e213f3ec94cf49611fca1ad04d8f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0a16bfbab824622b229e151b3caadae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b94fad9a3e014228997fb29de5cba26e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f569e30338364cc5b026361cd21bb912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40c8f34b3f1d4e24be527ca16ccfb2ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06e951e7f6db4628aa91f35249f50ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d961bde90b54480995c3b98304215a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_878f693acb1d4f43b28193bc0aa65a01",
              "IPY_MODEL_4da23039fbd4448b8f4e136f2f0715b7",
              "IPY_MODEL_63cc15138d784ad7b594e2e460e85667"
            ],
            "layout": "IPY_MODEL_9b39069a1bfe4d92b7a6ec20ca597e3d"
          }
        },
        "878f693acb1d4f43b28193bc0aa65a01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ef7af453c424aeca85db3466c2df7de",
            "placeholder": "​",
            "style": "IPY_MODEL_1852b0df60b741b2a70dd6d1f34bb1b0",
            "value": "Batches: 100%"
          }
        },
        "4da23039fbd4448b8f4e136f2f0715b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_095c97d9f00f4bd39d1bfbfa58fe98a6",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4381d401f5a44660851ab8d7f27e6e75",
            "value": 21
          }
        },
        "63cc15138d784ad7b594e2e460e85667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2ef382713ce47d8af79f4d3f1ff8308",
            "placeholder": "​",
            "style": "IPY_MODEL_7efaa07c08014df6aa2ecc0c62e6c916",
            "value": " 21/21 [00:00&lt;00:00, 108.07it/s]"
          }
        },
        "9b39069a1bfe4d92b7a6ec20ca597e3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ef7af453c424aeca85db3466c2df7de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1852b0df60b741b2a70dd6d1f34bb1b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "095c97d9f00f4bd39d1bfbfa58fe98a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4381d401f5a44660851ab8d7f27e6e75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2ef382713ce47d8af79f4d3f1ff8308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7efaa07c08014df6aa2ecc0c62e6c916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}